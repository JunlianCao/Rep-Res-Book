---
title: "Reproducible Research with R and RStudio (Third Edition)"
author: "Christopher Gandrud"
date: "`r Sys.Date()`"
documentclass: krantz
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
colorlinks: yes
lot: yes
lof: yes
site: bookdown::bookdown_site
chapter_name: "Chapter "
description: "Reproducible Research with R and RStudio, Third Edition brings together the skills and tools needed for doing and presenting computational research. Using straightforward examples, the book takyes you through an entire reproducible research workflow. This practical workflow enables you to gather and analyze data as well as dynamically present results in print and on the web."
github-repo: christophergandrud/Rep-Res-Book
graphics: yes
#cover-image: images/cover.jpg
---

```{r setup, include=FALSE}
options(
  htmltools.dir.version = FALSE, formatR.indent = 2, width = 55, digits = 4
)
```

# Preface {-}

## My motivation {-}

This book has its genesis in my PhD research at the London School of Economics. I started the degree with questions about the 2008/09 financial crisis and planned to spend most of my time researching capital adequacy requirements. But I quickly realized that I would actually spend a large proportion of my time learning the day-to-day tasks of data gathering, analysis, and results presentation. After plodding through for a while with Word, Excel, and Stata, my breaking point came while reentering results into a regression table after I had tweaked one of my statistical models, yet again. Surely there was a better way to *do* research that would allow me to spend more time answering my research questions. Making research reproducible for others also means making it better organized and efficient for yourself. My search for a better way led me straight to the tools for reproducible computational research.

The reproducible research community is very active, knowledgeable, and helpful. Nonetheless, I often encountered holes in this collective knowledge, or at least had no resource organize it all together as a whole. That is my intention for this book: to bring together the skills I have picked up for actually doing and presenting computational research. Hopefully, the book, along with making reproducible research more widely used, will save researchers hours of googling, so they can spend more time addressing their research questions.

## Changes to the Third Edition {-}

**To WRITE**

-   The book is created using *bookdown* [@R-bookdown], a format that builds on *rmarkdown* to compile books into many different formats.

## Changes to the Second Edition {-}

The tools of reproducible research have developed rapidly since the first edition of this book was published just two years ago. The second edition has been updated to incorporate the most important of these advancements, including discussions of:

-   The *rmarkdown* package, which allows you to create reproducible research documents in PDF, HTML, and Microsoft Word formats using the simple and intuitive Markdown syntax.

-   Improvements and changes to RStudio's interface and capabilities, such as its new tools for handling R Markdown documents.

-   Expanded *knitr* R code chunk capabilities.

-   The `kable()` function in the *knitr* package and the *texreg* package for dynamically creating tables to present your data and statistical results.

-   An improved discussion of file organization allowing you to take full advantage of relative file paths so that your documents are more easily reproducible across computers and systems.

-   The *dplyr*, *magrittr*, and *tidyr* packages for fast data manipulation.

-   Numerous changes to R syntax in user-created packages.

-   Changes to GitHub's and Dropbox's interfaces.

## Acknowledgments {-}

I would not have been able to write this book without many people's advice and support. Foremost is John Kimmel, acquisitions editor at Chapman and Hall. He approached me in Spring 2012 with the general idea and opportunity for this book. Other editors at Chapman and Hall and Taylor and Francis have greatly contributed to this project, including Marcus Fontaine. I would also like to thank all of the book's reviewers whose helpful comments have greatly improved it. The first edition's reviewers include:

-   Jeromy Anglim, Deakin University
-   Karl Broman, University of Wisconsin, Madison
-   Jake Bowers, University of Illinois, Urbana-Champaign
-   Corey Chivers, McGill University
-   Mark M. Fredrickson, University of Illinois, Urbana-Champaign
-   Benjamin Lauderdale, London School of Economics
-   Ramnath Vaidyanathan, McGill University

and there have been many other annonymous reviewers who have provided great feedback over the years.

The developer and blogging community has also been incredibly important for making this book possible. Foremost among these people is Yihui Xie. He is the main developer behind the *knitr* package, co-developer of *rmarkdown*, and also an avid blog writer and commenter. Without him the ability to do reproducible research would be much harder and the blogging community that spreads knowledge about how to do these things would be poorer. Other great contributors to the reproducible research community include Carl Boettiger, Karl Broman, Markus Gesmann (who developed *googleVis*), Rob Hyndman, and Hadley Wickham (who has developed numerous very useful R packages). Thank you also to Victoria Stodden and Michael Malecki for helpful suggestions. And, of course, thank you to everyone at RStudio (especially JJ Allaire) for creating an increasingly useful program for reproducible research.

The second edition has benefited immensely from first edition readers' comments and suggestions. For a list of their valuable contributions, please see the book's GitHub Issues page <https://GitHub.com/christophergandrud/Rep-Res-Book/issues> and the first edition's Errata page <http://christophergandrud.GitHub.io/RepResR-RStudio/errata.htm>.

My students at Yonsei University were an important part of making the first edition. One of the reasons that I got interested in using many of the tools covered in this book, like using **knitr} in slideshows, was to improve a course I taught there: Introduction to Social Science Data Analysis. I tested many of the explanations and examples in this book on my students. Their feedback has been very helpful for making the book clearer and more useful. Their experience with using these tools on Microsoft Windows computers was also important for improving the book's Windows documentation. Similarly, my students at the Hertie School of Governance inspired and tested key sections of the second edition.

The vibrant community at Stack Overflow <http://stackoverflow.com/> and Stack Exchange <http://stackexchange.com/> are always very helpful for finding answers to problems that plague any computational researcher. Importantly, the sites make it easy for others to find the answers to questions that have already been asked.

Kristina Gandrud, has been immensely supportive and patient with me throughout the writing of this book (and pretty much my entire academic career). Certainly this is not the proper forum for musing about marital relations, but I'll do a musing anyways. Having a person who supports your interests, even if they don't completely share them, is immensely helpful for a researcher. It keeps you going.

<!--chapter:end:index.Rmd-->

# Stylistic Convensions {-}

I use the following conventions throughout this book:

-   **Abstract variables**: Abstract variables, i.e. variables that do not
represent specific objects in an example, are in `ALL CAPS TYPEWRITER TEXT`.

-   **Clickable buttons**: Clickable Buttons are in `typewriter text`.

-   **Code**: All code is in `typewriter text`.

-   **Filenames and directories**: Filenames and directories more generally are
printed in *italics*. I use CamelBack for file and directory names.

-   **File extensions**: Like filenames, file extensions are *italicized*.

-   **Individual variable values**: Individual variable values mentioned in the
text are in *italics*.

-   **Objects**: Objects are printed in *italics*. I use CamelBack for object names.

-   **Object columns**: Data frame object columns are printed in *italics*.

-   **Function names** are followed by parentheses (e.g., `stats::lm()`)

-   **Packages**: **R** packages are printed in *italics*.

-   **Windows and RStudio panes**: Open windows and RStudio panes are written in
*italics*.

-   **Variable names**: Variable names are printed in **bold**. I use CamelBack
for individual variable names.

<!--chapter:end:01-stylistic-convensions.Rmd-->

# Additional Resources {-}

Additional resources that supplement the examples in this book can be freely downloaded and experimented with. These resources include longer examples discussed in individual chapters and a complete short reproducible research project.

## Chapter Examples {-}

Longer examples discussed in individual chapters, including files to dynamically download data, code for creating figures, and markup files for creating presentation documents, can be accessed at: <https://github.com/christophergandrud/Rep-Res-Examples>. Please see Chapter \@ref(Storing) for more information on downloading files from GitHub, where the examples are stored.\index{GitHub}

## Short Example Project {-}

To download a full (though very short) example of a reproducible research project created using the tools covered in this book go to: <https://github.com/christophergandrud/Rep-Res-ExampleProject1>. Please follow the replication instructions in the main *README.md* file to fully replicate the project. It is probably a good idea to hold off looking at this complete example in detail until after you have become acquainted with the individual tools it uses. Become acquainted with the tools by reading through this book and working with the individual chapter examples.

The following two figures give you a sense of how the example's files are organized. Figure \@ref(fig:ExampProjeFiles) shows how the files are organized in the file system. Figure \@ref(fig:ExampProjDiagram) illustrates how the main files are dynamically tied together. In the *Data* directory we have files to gather raw data from the [@worldbank2013] on fertilizer consumption and from [@pemstein2010] on countries' levels of democracy. They are tied to the data through the `WDI()`\index{WDI()} and `download.file()` functions.\index{R function!download.file()} A *Makefile*\index{Makefile} can run *Gather1.R* and *Gather2.R* to gather and clean the data. It runs *MergeData.R* to merge the data into one data file called *MainData.csv*. It also automatically generates a variable description file and a *README.md*\index{README file} recording the session info.\index{R!session info}

The *Analysis* folder contains two files that create figures presenting this data. They are tied to *MainData.csv* with the `read.csv()` function.\index{R function!read.csv} These files are run by the presentation documents when they are knitted. The presentation documents tie to the analysis documents with *knitr* and the `source()` function.\index{R function!source()}

Though a simple example, hopefully these files will give you a complete sense of how a reproducible research project can be organized. Please feel free to experiment with different ways of organizing the files and tying them together to make your research really reproducible.

```{r ExampProjeFiles, engine = "tikz", fig.cap = "Short Example Project File Tree", cache=TRUE, echo=FALSE, fig.ext=if (knitr:::is_latex_output()) 'pdf' else 'png'}
\usetikzlibrary{trees}

% Set node styles
\tikzstyle{DirBox} = [draw=black,
                      rectangle,
                      minimum width=5em,
                      very thick,
                      font=\small]

\tikzstyle{every node} = [draw=gray,
                          thin,
                          anchor=west,
                          font=\small]

% Begin tikz picture
\begin{tikzpicture}[%
  grow via three points={one child at (0.5,-0.7) and
  two children at (0.5,-0.7) and (0.5,-1.4)},
  edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}]
  % Root Directory
  \node (root) at (5, 10) [DirBox]{Root};

  % Project Directory
  \node (project) at (4, 8.5) [DirBox]{Rep-Res-ExampleProject1}
        child {node {{\small{Paper.Rnw}}}}
        child {node {{\small{Slideshow.Rnw}}}}
        child {node {{\small{Website.Rnw}}}}
        child {node {{\small{Main.bib}}}}
            ;

  % Data Directory
  \node (data) at (0, 4.5) [DirBox]{Data}
      child {node {{\small{MainData.csv}}}}
      child {node {{\small{Makefile}}}}
      child {node {{\small{MergeData.R}}}}
      child {node {{\small{Gather1.R}}}}
      child {node {{\small{Gather2.R}}}}
      child {node {{\small{MainData\_VariableDescriptions.md}}}}
      child {node {{\small{README.Rmd}}}}
        ;

  % Analysis subdirectores/files
  \node (analysis) at (1.5, 7) [DirBox]{Analysis}
      child {node {{\small{GoogleVisMap.R}}}}
      child {node {{\small{ScatterUDSFert.R}}}}
        ;

  % README file
  \node (readme) at (9.5, 7) {README.md};

  % Connect boxes that are not explicit children
  \draw (root) -- (project);
  \draw (project) -| (analysis);
  \draw (analysis) -| (data);
  \draw (project) -| (readme);

\end{tikzpicture}
```

```{r ExampProjDiagram, engine = "tikz", fig.cap = "Short Example Main File Ties", cache=TRUE, echo=FALSE, fig.ext=if (knitr:::is_latex_output()) 'pdf' else 'png'}
\usetikzlibrary{trees}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{shapes,arrows}

\definecolor{Blue}{HTML}{7BCCC4}
\definecolor{LiteBlue}{HTML}{A8DDB5}
\definecolor{DarkBlue}{HTML}{08589E}

\definecolor{GrayLine}{HTML}{BDBDBD}

% Set node styles
%% File nodes
\tikzstyle{File} = [draw=Blue,
                    rectangle,
                    text width=6.3em,
                    font=\scriptsize]

% Raw Data nodes
\tikzstyle{RawData} = [draw=LiteBlue,
                       %fill=LiteBlue,
                       decorate,
                       decoration={random steps,
                                   segment length=2pt,
                                   amplitude=2pt},
                       inner sep=0.25cm,
                       font=\scriptsize]

% Separator line style
\tikzstyle{sepline} = [draw,
                        very thick,
                        color=GrayLine]

% Link command nodes
\tikzstyle{Links} = [draw=none,
                          text width=6em,
                          text=DarkBlue,
                          font=\small]

% Begin tikz picture
\begin{tikzpicture}

    % Nodes
    \node (Data1) at (-3.5, 7) [RawData]{Raw WDI Data};
    \node (Gather1) at (-3, 6) [File]{Gather1.R};

    \node (Data2) at (-3.5, 5) [RawData]{Raw UDS Data};
    \node (Gather2) at (-3, 4) [File]{Gather2.R};

    \node (MergeData) at (0.5, 5) [File]{Makefile \\ MergeData.R};
    \node (DataFile) at (0.5, 4) [File]{MainData.csv};

    \node (Scatter) at (3.8, 4.5) [File]{ScatterUDSFert.R};
    \node (GoogleVis) at (3.8, 3.5) [File]{GoogleVisMap.R};

    \node (ArticleK) at (7, 5) [File]{Article.Rnw};
    \node (SlideshowK) at (7, 4) [File]{Slideshow.Rnw};
    \node (WebsiteK) at (7, 3) [File]{Website.Rmd};

    \node (Article) at (10, 5) [File]{Article.pdf};
    \node (Slideshow) at (10, 4) [File]{Slideshow.pdf};
    \node (Website) at (10, 3) [File]{Website.html};

    % Lines
    \draw [->] (Data1) -- (Gather1);
    \draw [->] (Data2) -- (Gather2);
    \draw [->] (Gather1) -- (MergeData);
    \draw [->] (Gather2) -- (MergeData);
    \draw [->] (MergeData) -- (DataFile);

    \draw [->] (DataFile) -- (Scatter);
    \draw [->] (DataFile) -- (GoogleVis);

    \draw [->] (Scatter) -- (ArticleK);
    \draw [->] (Scatter) -- (SlideshowK);
    \draw [->] (GoogleVis) -- (WebsiteK);

    \draw [->] (ArticleK) -- (Article);
    \draw [->] (SlideshowK) -- (Slideshow);
    \draw [->] (WebsiteK) -- (Website);


    \path [sepline] (-3.5, 0.75) -- (11, 0.75);

    % Link command nodes

    \node (importData) at (-1, -1) [Links]{\texttt{download.file()} \\ \texttt{Make} \\ \texttt{merge()}\\ \texttt{WDI()} };

    \node (Figs) at (3, -1) [Links]{\texttt{read.csv()}};

    \node (knitr) at (7.5, -1) [Links]{ {\emph{knitr}} \\ \texttt{source()}};

\end{tikzpicture}
```

## Updates {-}

Many of the reproducible research tools discussed in this book are improving rapidly. Because of this, I will regularly post updates to the content covered in the book at: <https://github.com/christophergandrud/Rep-Res-Book>.

## Corrections {-}

If you notice any corrections that should be made to fix typos, broken URLs, and so on, you can report them at: <https://github.com/christophergandrud/Rep-Res-Book/issues>. I'll post notifications of changes to an Errata page at: <http://christophergandrud.GitHub.io/RepResR-RStudio/errata.htm>.

<!--chapter:end:02-additional_resources.Rmd-->

\mainmatter

# (PART) Getting Started {-}

# Introducing Reproducible Research{#Intro}

Research is often presented in very selective containers: slideshows,
journal articles, books, or maybe even websites. These presentation
documents announce a project's findings and try to convince us that the
results are correct [@mesirov2010]. It's important to remember that
these documents are not the research. Especially in the computational
and statistical sciences, these documents are the "advertising". The
research is the "full software environment, code, and data that produced
the results" [@buckheit1995; @donoho2010 385]. When we separate the
research from its advertisement we are making it difficult for others to
verify the findings by reproducing them.

This book gives you the tools to dynamically combine your research with
the presentation of your findings. The first tool is a workflow for
reproducible research that weaves the principles of reproducibility
throughout your entire research project, from data gathering to the
statistical analysis, and the presentation of results. You will also
learn how to use a number of computer tools that make this workflow
possible. These tools include:

-   the **R** statistical language that will allow you to gather data
    and analyze it;

-   the **LaTeX** and **Markdown** markup languages that you can use to
    create documents--slideshows, articles, books, and webpages--for
    presenting your findings;

-   the *knitr* and *rmarkdown* **packages** for R and other tools,
    including **command-line programs** like GNU Make and Git
    version control, for dynamically tying your data gathering,
    analysis, and presentation documents together so that they can be
    easily reproduced;

-   **RStudio**, a program that brings all of these tools together in
    one place.

## What Is Reproducible Research?

Though there is some debate over what are the necessary and sufficient
conditions for a replication [@makel2014 2], research results are
generally considered[^chapter1_1_1] *replicable* if there is sufficient information
available for independent researchers to make the same findings using
the same procedures with new data.[^chapter1_1] For research that relies on
experiments, this can mean a researcher not involved in the original
research being able to rerun the experiment, including sampling, and
validate that the new results are comparable to the original ones. In
computational and quantitative empirical sciences, results are
replicable if independent researchers can recreate findings by following
the procedures originally used to gather the data and run the computer
code. Of course, it is sometimes difficult to replicate the original
data set because of issues such as limited resources to gather new data
or because the original study already sampled the full universe of
cases. So as a next-best standard we can aim for "*really reproducible
research*" [@peng2011 1226].[^chapter1_2] In computational sciences[^chapter1_3]
this means:

> the data and code used to make a finding are available and they are sufficient for an independent researcher to recreate the finding.

In practice, research needs to be *easy* for independent researchers to
reproduce [@ball2012]. If a study is difficult to reproduce it's more
likely that no one will reproduce it. If someone does attempt to
reproduce this research, it will be difficult for them to tell if any
errors they find were in the original research or problems they
introduced during the reproduction. In this book you will learn how to
avoid these problems.

In particular you will learn tools for dynamically "*knitting*"[^chapter1_4] the
data and the source code together with your presentation documents.
Combined with well-organized source files and clearly and completely
commented code, independent researchers will be able to understand how
you obtained your results. This will make your computational research
easily reproducible.

## Why Should Research Be Reproducible?

Reproducible research is one of the main components of science. If
that's not enough reason for you to make your research reproducible,
consider that the tools of reproducible research also have direct
benefits for you as a researcher.

### For science

Replicability has been a key part of scientific inquiry from perhaps the
1200s [@bacon1267; @nosek2012]. It has even been called the "demarcation
between science and non-science" [@braude1979 2]. Why is replication so
important for scientific inquiry?

#### Standard to judge scientific claims {-}

*Replication* opens claims to scrutiny, allowing us to keep what works
and discard what doesn't. Science, according to the American Physical
Society, "is the systematic enterprise of gathering knowledge
...organizing and condensing that knowledge into testable laws and
theories". The "ultimate standard" for evaluating scientific claims is
whether or not the claims can be replicated [@peng2011; @kelly2006].
Research findings cannot even really be considered "genuine
contributions to human knowledge" until they have been verified
through replication [@stodden2009 38]. Replication "requires the
complete and open exchange of data, procedures, and materials".
Scientific conclusions that are not replicable should be abandoned or
modified "when confronted with more complete or reliable
...evidence".[^chapter1_5]

*Reproducibility enhances replicability*. If other researchers are able
to clearly understand how a finding was originally made, then they will
be better able to conduct comparable research in meaningful attempts to
replicate the original findings. Sometimes strict replicability is not
feasible, for example, when it is only possible to gather one data set
on a population of interest. In these cases reproducibility is a
"minimum standard" for judging scientific claims [@peng2011].

It is important to note that though reproducibility is a minimum
standard for judging scientific claims, "a study can be reproducible and
still be wrong" [@peng2014]. For example, a statistically significant
finding in one study may remain statistically significant when
reproduced using the original data/code, but when researchers try to
replicate it using new data and even methods, they are unable to find a
similar result. The original finding could simply have been noise, even
though it is fully reproducible.

#### Avoiding effort duplication & encouraging cumulative knowledge development {-}

Not only is reproducibility important for evaluating scientific claims,
it can also contribute to the cumulative growth of scientific knowledge
[@kelly2006; @king1995]. Reproducible research cuts down on the amount
of time scientists have to spend gathering data or developing procedures
that have already been collected or figured out. Because researchers do
not have to discover on their own things that have already been done,
they can more quickly build on established findings and develop new
knowledge.

### For you

Working to make your research reproducible does require extra upfront
effort. For example, you need to put effort into learning the tools of
reproducible research by doing things such as reading this book. But
beyond the clear benefits for science, why should you make this effort?
Using reproducible research tools can make your research process more
effective and (hopefully) ultimately easier.

#### Better work habits {-}

Making a project reproducible from the start encourages you to use
better work habits. It can spur you to more effectively plan and
organize your research. It should push you to bring your data and source
code up to a higher level of quality than you might if you "thought 'no
one was looking'" [@donoho2010 386]. This forces you to root out
errors--a ubiquitous part of computational research--earlier in the
research process [@donoho2010 385]. Clear documentation also makes it
easier to find errors.[^chapter1_6]

Reproducible research needs to be stored so that other researchers can
actually access the data and source code. By taking steps to make your
research accessible for others you are also making it easier for
yourself to find your data and methods when you revise your work or
begin new a project. You are avoiding personal effort duplication,
allowing you to cumulatively build on your own work more effectively.

#### Better teamwork {-}

The steps you take to make sure an independent researcher can figure out
what you have done also make it easier for your collaborators to
understand your work and build on it. This applies not only to current
collaborators, but also future collaborators. Bringing new members of a
research team up to speed on a cumulatively growing research project is
faster if they can easily understand what has been done already
[@donoho2010 386].

#### Changes are easier {-}

A third person may or may not actually reproduce your research even if
you make it easy for them to do so. But, *you will almost certainly
reproduce parts or even all of your own research*. No actual research
process is completely linear. You almost never gather data, run
analyses, and present your results without going backwards to add
variables, make changes to your statistical models, create new graphs,
alter results tables in light of new findings, and so on. You will
probably try to make these changes long after you last worked on the
project and long since you remembered the details of how you did it.
Whether your changes are because of journal reviewers' and conference
participants' comments or you discover that new and better data has been
made available since beginning the project, designing your research to
be reproducible from the start makes it much easier to change things
later on.

Dynamic reproducible documents in particular can make changing things
much easier. Changes made to one part of a research project have a way
of cascading through the other parts. For example, adding a new variable
to a largely completed analysis requires gathering new data and merging
it with existing data sets. If you used data imputation or matching
methods you may need to rerun these models. You then have to update your
main statistical analyses, and recreate the tables and graphs you used
to present the results. Adding a new variable essentially forces you to
reproduce large portions of your research. If when you started the
project you used tools that make it easier for others to reproduce your
research, you also made it easier to reproduce the work yourself. You
will have taken steps to have a "better relationship with your
future self" [@bowers2011 2].

#### Higher research impact {-}

Reproducible research is more likely to be useful for other researchers
than non-reproducible research. Useful research is cited more frequently
[@donoho2002; @piwowar2007; @vandewalle2012]. Research that is fully
reproducible contains more information, i.e. more reasons to use and
cite it, than presentation documents merely showing findings.
Independent researchers may use the reproducible data or code to look at
other, often unanticipated, questions. When they use your work for a new
purpose they will (should) cite your work. Because of this, Vandewalle
et al. even argue that "the goal of reproducible research is to have
more impact with our research" [-@vandewalle2007 1253].

A reason researchers often avoid making their research fully
reproducible is that they are afraid other people will use their data
and code to compete with them. I'll let Donoho et al. address this one:

> *True. But competition means that strangers will read your papers, try
> to learn from them, cite them, and try to do even better. If you
> prefer obscurity, why are you publishing?* [-@donoho2009 16]

## Who Should Read This Book?

This book is intended primarily for researchers who want to use a
systematic workflow that encourages reproducibility as well as practical
state-of-the-art computational tools to put this workflow into practice.
These people include professional researchers, upper-level
undergraduate, and graduate students working on computational
data-driven projects. Hopefully, editors at academic publishers will
also find the book useful for improving their ability to evaluate and
edit reproducible research.

The more researchers that use the tools of reproducibility the better.
So I include enough information in the book for people who have very
limited experience with these tools, including limited experience with
R, LaTeX, and Markdown. They will be able to start incorporating
reproducible research tools into their workflow right away. The book
will also be helpful for people who already have general experience
using technologies such as R and LaTeX, but would like to know how to
tie them together for reproducible research.

### Academic researchers

Hopefully so far in this chapter I've convinced you that reproducible
research has benefits for you as a member of the scientific community
and personally as a computational researcher. This book is intended to
be a practical guide for how to actually make your research
reproducible. Even if you already use tools such as R and LaTeX you may
not be leveraging their full potential. This book will teach you useful
ways to get the most out of them as part of a reproducible research
workflow.

### Students

Upper-level undergraduate and graduate students conducting original
computational research should make their research reproducible for the
same reasons that professional researchers should. Forcing yourself to
clearly document the steps you took will also encourage you to think
more clearly about what you are doing and reinforce what you are
learning. It will hopefully give you a greater appreciation of research
accountability and integrity early in your career [@barr2012; @ball2012
183].

Even if you don't have extensive experience with computer languages,
this book will teach you specific habits and tools that you can use
throughout your student research and hopefully your careers. Learning
these things earlier will save you considerable time and effort later.

### Instructors

When instructors incorporate the tools of reproducible research into
their assignments they not only build students' understanding of
research best practice, but are also better able to evaluate and provide
meaningful feedback on students' work [@ball2012 183]. This book
provides a resource that you can use with students to put
reproducibility into practice.

If you are teaching computational courses, you may also benefit from
making your lecture material dynamically reproducible. Your slides will
be easier to update for the same reasons that it is easier to update
research. Making the methods you used to create the material available
to students will give them more information. Clearly documenting how you
created lecture material can also pass information on to future
instructors.

### Editors

Beyond a lack of reproducible research skills among researchers, an
impediment to actually creating reproducible research is a lack of
infrastructure to publish it [@peng2011]. Hopefully, this book will be
useful for editors at academic publishers who want to be better at
evaluating reproducible research, editing it, and developing systems to
make it more widely available. The journal *Biostatistics* is a good
example of a publication that is encouraging (actually requiring)
reproducible research. From 2009 the journal has had an editor for
reproducibility that ensures replication files are available and that
results can be replicated using these files [@peng2009]. The more
editors there are with the skills to work with reproducible research the
more likely it is that researchers will do it.

### Private sector researchers

Researchers in the private sector may or may not want to make their work
easily reproducible outside of their organization. However, that does
not mean that significant benefits cannot be gained from using the
methods of reproducible research.

Even if a company has only one person doing research, they benefit from using reproducible research methods. Just with academic research this person actually does have a collaborator: their future self. As discussed above, reproducible research makes this collaboration easier.

Companies with more than one researcher do (or likely should) act as a research
community, even if public reproducibility
is ruled out to guard proprietary information.[^chapter1_7] Making your research
reproducible to members of your organization can spread valuable
information about how analyses were done and data was collected. This
will help build your organization's knowledge and avoid effort
duplication. Just as a lack of reproducibility hinders the spread of
information in the scientific community, it can hinder it inside of a
private organization. Using the sort of dynamic automated processes run
with clearly documented source code we will learn in this book can also
help create robust data analysis methods that help your organization
avoid errors that may come from cutting-and-pasting data across
spreadsheets.[^chapter1_8]

The tools of reproducible research covered in this book enable you
to create professional standardized reports that can be easily updated
or changed when new information is available. In particular, you will
learn how to create batch reports based on quantitative data.

## The Tools of Reproducible Research

This book will teach you the tools you need to make your research highly
reproducible. Reproducible research involves two broad sets of tools.
The first is a **reproducible research environment** that includes the
statistical tools you need to run your analyses as well as "the ability
to automatically track the provenance of data, analyses, and results and
to package them (or pointers to persistent versions of them) for
redistribution". The second set of tools is a **reproducible research
publisher**, which prepares dynamic documents for presenting results and
is easily linked to the reproducible research environment [@mesirov2010
415].

In this book we will focus on learning how to use the widely available
and highly flexible reproducible research environment--R/RStudio
[@rlanguage; @rstudiocite].[^chapter1_9] R/RStudio can be linked to numerous
reproducible research publishers such as LaTeX and Markdown with Yihui
Xie's *knitr* package [-@R-knitr] or the related *rmarkdown* package
[@R-rmarkdown]. The main tools covered in this book include:

-   **R**: a programming language primarily for statistics and graphics.
    It can also be useful for data gathering and creating presentation
    documents.

-   ***knitr* and *rmarkdown***: related R packages for literate
    programming. They allow you to combine your statistical analysis and
    the presentation of the results into one document. They work with R
    and a number of other languages such as Bash, Python, and Ruby.

-   **Markup languages**: instructions for how to format a presentation
    document. In this book we cover LaTeX, Markdown, and a little HTML.

-   **RStudio**: an integrated developer environment (IDE) for R that
    tightly combines R, *knitr*, *rmarkdown*, and markup languages.

-   **Cloud storage & versioning**: Services such as Dropbox and
    Git/GitHub that can store data, code, and presentation files, save
    previous versions of these files, and make this information widely
    available.

-   **Unix-like shell programs**: These tools are useful for working
    with large research projects.[^chapter1_10] They also allow us to use
    command-line tools including GNU Make for compiling projects and
    Pandoc, a program useful for converting documents from one markup
    language to another.

### Why Use R, *knitr*/*rmarkdown*, and RStudio for Reproducible Research?

#### Why R? {-}

Why use a statistical programming language like R for reproducible
research? R has a very active development community that is constantly
expanding what it is capable of. As we will see in this book, R enables
researchers across a wide range of disciplines to gather data and run
statistical analyses. Using the *knitr* or *rmarkdown* package, you can
connect your R-based analyses to presentation documents created with
markup languages such as LaTeX and Markdown. This allows you to
dynamically and reproducibly present results in articles, slideshows,
and webpages.

The way you interact with R has benefits for reproducible research. In
general you interact with R (or any other programming and markup
language) by explicitly writing down your steps as source code. This
promotes reproducibility more than your typical interactions with
Graphical User Interface (GUI) programs like SPSS[^chapter1_11] and Microsoft
Word. When you write R code and embed it in presentation documents
created using markup languages, you are forced to explicitly state the
steps you took to do your research. When you do research by clicking
through drop-down menus in GUI programs, your steps are lost, or at
least documenting them requires considerable extra effort. Also it is
generally more difficult to dynamically embed your analysis in
presentation documents created by GUI word processing programs in a way
that will be accessible to other researchers both now and in the future.
I'll come back to these points in Chapter \@ref(GettingStartedRR).

#### Why knitr and rmarkdown? {-}

Literate programming is a crucial part of reproducible quantitative
research.[^chapter1_12] Being able to directly link your analyses, your results,
and the code you used to produce the results makes tracing your steps
much easier. There are many different literate programming tools for a
number of different programming languages.[^chapter1_13] Previously, one of the
most common tools for researchers using R and the LaTeX markup language
was *Sweave* [@leisch2002]. The packages I am going to focus on in this
book are newer and have more capabilities. They are called *knitr* and
*rmarkdown*. Why are we going to use these tools in this book and not
*Sweave* or some other tool?

The simple answer is that they are more capable than *Sweave*. Both
*knitr* and *rmarkdown* can work with markup languages other than LaTeX
including Markdown and HTML. *rmarkdown* can even output Microsoft Word
documents. They can work with programming languages other than R. They
highlight R code in presentation documents making it easier for your
readers to follow.[^chapter1_14] They give you better control over the inclusion
of graphics and can cache code chunks, i.e. save the output for later.
*knitr* has the ability to understand *Sweave*-like syntax, so it will
be easy to convert backwards to *Sweave* if you want to.[^chapter1_15] You also
have the choice to use much simpler and more straightforward syntax with
*knitr* and *rmarkdown*.

*knitr* and *rmarkdown* have broadly similar capabilities and syntax.
They both are literate programming tools that can produce presentation
documents from multiple markup languages. They have almost identical
syntax when used in Markdown. Their main difference is that they take
different approaches to creating presentation documents. *knitr*
documents must be written using the markup language associated with the
desired output. For example, with *knitr*, LaTeX must be used to create
PDF output documents and Markdown or HTML must be used to create
webpages. *rmarkdown* builds directly on *knitr*, the key difference
being that it uses the straightforward Markdown markup language to
generate PDF, HTML, and MS Word documents.[^chapter1_16]

Because you write with the simple Markdown syntax, *rmarkdown* is
generally easier to use. It has the advantage of being able to take the
same markup document and output multiple types of presentation
documents. Nonetheless, for complex documents like books and long
articles or work that requires custom formatting, *knitr* LaTeX is often
preferable and extremely flexible, though the syntax is more
complicated.

#### Why RStudio? {-}

Why use the RStudio integrated development environment for reproducible
research? R by itself has the capabilities necessary to gather data,
analyze it, and, with a little help from *knitr*/*rmarkdown* and markup
languages, present results in a way that is highly reproducible. RStudio
allows you to do all of these things, but simplifies many of them and
allows you to navigate through them more easily. It also is a happy
medium between R's text-based interface and a pure GUI.

Not only does RStudio do many of the things that R can do but more
easily, it is also a very good standalone editor for writing documents
with LaTeX and Markdown. For LaTeX documents it can, for example, insert
frequently used commands like `\section{}` for numbered sections (see
Chapter \@ref(LatexChapter)).[^chapter1_17] There are many LaTeX editors available,
both open source and paid. But RStudio is currently the best program for
creating reproducible LaTeX and Markdown documents. It has full syntax
highlighting. Its syntax highlighting can even distinguish between R
code and markup commands in the same document. It can spell check LaTeX
and Markdown documents. It handles *knitr*/*rmarkdown* code chunks
beautifully (see Chapter \@ref(GettingStartedRKnitr)).

Finally, RStudio not only has tight integration with various markup
languages, it also has capabilities for using other tools such as C++,
CSS, JavaScript, Python, and a few other programming languages. It is closely
integrated with the version control programs Git and SVN. Both of these
programs allow you to keep track of the changes you make to your
documents (see Chapter \@ref(Storing)). This is important for reproducible research since
version control programs can document many of your research steps. It
also has a built-in ability to make HTML slideshows from
*knitr*/*rmarkdown* documents. Basically, RStudio makes it easy to
create and navigate through complex reproducible research documents.

## Installing the main software {#InstallR}

Before you read this book you should install the main software. All of
the software programs covered in this book are open source and can be
easily downloaded for free. They are available for Windows, Mac, and
Linux operating systems. They should run well on most modern computers.

You should install R before installing RStudio. You can download the
programs from the following websites:

-   **R**: <https://www.r-project.org/>,

-   **RStudio Desktop (Open Source License)**:
    <https://www.rstudio.com/products/rstudio/download/>.

The webpages for downloading these programs have comprehensive information
on how to install them. Please refer to those pages for more
information.

After installing R and RStudio you will probably also want to install a
number of user-written packages that are covered in this book. To
install all of these user-written packages, please this chapter's Appendix.

### Installing markup languages {#InstallMarkup}

You will need to install the R package *rmarkdown* [@R-rmarkdown]\index{R package!rmarkdown} to turn your markdown documents into polished output that can be presented (e.g. as a website or PDF). To do this in R use:

```{r rmarkdown-install, eval=FALSE}
install.packages("rmarkdown")
```

If you plan to render your RMarkdown documents from the console without RStudio you will need to install Pandoc.\index{Pandoc} For instructions see Pandoc's download page: <https://pandoc.org/installing.html>.

If you want to create LaTeX (PDF) documents you can install a TeX
distribution.[^chapter1_18] The simplest way to get all of the LaTeX capabilities you will need for this book is to use the *tinytex*\index{R package!markdown} [@R-tinytex] R package:

```{r tinytex-install, eval=FALSE}
install.packages('tinytex')
tinytex::install_tinytex()
```
If you want a full LaTeX distribution see <http://www.latex-project.org/ftp.html> for installation information.

### GNU Make

If you are using a Linux computer you already have GNU
Make \@ref(InstallMake) installed.[^chapter1_19]
Mac users will need to install the command-line developer tools. There
are two ways to do this. One is go to the App Store and download Xcode
(it's free). Once Xcode is installed, install command-line tools, which
you will find by opening Xcode then clicking on `Preference`
`Downloads`. However, Xcode is a very large download and you only need
the command-line tools for Make. To install just the command-line tools,
open the Terminal and try to run Make by typing `make` and hitting
return. A box should appear asking you if you want to install the
command-line developer tools. Click `Install`. Windows users will have
Make installed if they have already installed *Rtools* (see this Chapter's Appendix). Mac
and Windows users will need to install this software not only so that
GNU Make runs properly, but also so that other command-line tools work
well.

### Other Tools

We will discuss other tools such as Git that can be a useful part of a
reproducible research workflow. Installation instructions for these
tools will be discussed below.

## Book Overview {#OtherBooks}

The purpose of this book is to give you the tools that you will need to
do reproducible research with R and RStudio. This book describes a
workflow for reproducible research primarily using R and RStudio. It is
designed to give you the necessary tools to use this workflow for your
own research. It is not designed to be a complete reference for R,
RStudio, *knitr*/*rmarkdown*, Git, or any other program that is a part
of this workflow. Instead it shows you how these tools can fit together
to make your research more reproducible. To get the most out of these
individual programs I will along the way point you to other resources
that cover these programs in more detail.

To that end, I can recommend a number of resources that cover more of
the nitty-gritty:

-   Michael J. Crawley's [-@crawley2013] encyclopaedic R book,
    appropriately titled ***The R Book***, published by Wiley.

-   Hadley Whickham [-@whickham2014book] has a great new book out from
    Chapman and Hall on ***Advanced R***.

-   Yihui Xie's [-@xie2018] book ***R Markdown: The Definitive Guide***,
    published by Chapman and Hall, is needless to say the definitive guide on
    R Markdown syntax. It's a good complement
    to this book's generally more research project--level focus.

-   Cathy O'Neil and Rachel Schutt [-@oneil2013] give a great
    introduction the field of data science generally in ***Doing Data
    Science***, published by O'Reilly Media Inc.

-   For many real-world examples of reproducible research in action see
    Kitzes et al [-@kitzes2018] collection of case studies
    ***The Practice of Reproducible Research***.

-   For an excellent introduction to the command-line in Linux and Mac,
    see William E. Shotts Jr.'s [-@shottsjr2012] book ***The Linux
    Command-line: A Complete Introduction*** also published by No Starch
    Press. It is also helpful for Windows users running PowerShell (see
    Chapter \@ref(DirectoriesChapter)). Sean Kross' [-@kross2018] ***The Unix
    Workbench*** is also a great freely available online introduction to the topic.

-   The RStudio website (<http://www.rstudio.com/ide/docs/>) has a
    number of useful tutorials on how to use *knitr* with LaTeX and
    Markdown. They also have very good documentation for *rmarkdown* at
    <https://rmarkdown.rstudio.com/>.

That being said, my goal is for this book to be *self-sufficient*. A
reader without a detailed understanding of these programs will be able
to understand and use the commands and procedures I cover in this book.
While learning how to use R and the other programs I personally often
encountered illustrative examples that included commands, variables, and
other things that were not well explained in the texts that I was
reading. This caused me to waste many hours trying to figure out, for
example, what the `$` is used for (preview: it's the component selector,
see Section \@ref(ComponentSelect). I hope to save you from this wasted time
by either providing a brief explanation of possibly frustrating and
mysterious things and/or pointing you in the direction of good
explanations.

### How to read this book

This book gives you a workflow. It has a beginning, middle, and end. So,
unlike a reference book, it can and should be read linearly as it takes
you through an empirical research processes from an empty folder to a
completed set of documents that reproducibly showcase your findings.

That being said, readers with more experience using tools like R or
LaTeX may want to skip over the nitty-gritty parts of the book that
describe how to manipulate data frames or compile LaTeX documents into
PDFs. Please feel free to skip these sections.

#### More-experienced R users {-}

If you are an experienced R user you may want to skip over the first
section of Chapter
\@ref(GettingStartedRKnitr): Getting Started with R, RStudio, and
*knitr*/*rmarkdown*. But don't skip over the whole chapter. The latter
parts contain important information on the *knitr*/*rmarkdown* packages.
If you are experienced with R data manipulation you may also want to
skip all of Chapter \@ref(DataClean).

#### More-experienced LaTeX users {-}

If you are familiar with LaTeX you might want to skip the first part of
Chapter \@ref(LatexChapter). The second part may be useful as it includes
information on how to dynamically create BibTeX bibliographies with
*knitr* and how to include *knitr* output in a Beamer slideshow.

#### Less-experienced LaTeX/Markdown users {-}

If you do not have experience with LaTeX or Markdown you may benefit
from reading, or at least skimming, the introductory chapters on these
top topics (chapters \@ref(LatexChapter) and \@ref(MarkdownChapter)) before
reading Part III.

### Reproduce this book

This book practices what it preaches. It can be reproduced. I wrote the
book using the programs and methods that I describe. Full documentation
and source files can be found at the book's GitHub repository. Feel free
to read and even use (within reason and with attribution, of course) the
book's source code. You can find it at:
<https://github.com/christophergandrud/Rep-Res-Book>. This is especially
useful if you want to know how to do something in the book that I don't
directly cover in the text.

If you notice any errors or places where the book can be improved please
report them on the book's GitHub Issues page:
<https://github.com/christophergandrud/Rep-Res-Bookissues>. Corrections
will be posted at:
<http://christophergandrud.GitHub.io/RepResR-RStudio/errata.htm>.

### Contents overview

The book is broken into four parts. The first part (chapters
\@ref(GettingStartedRR),
\@ref(GettingStartedRKnitr), and \@ref(DirectoriesChapter)) gives an overview of the reproducible
research workflow as well as the general computer skills that you'll
need to use this workflow. Each of the next three parts of the book
guides you through the specific skills you will need for each part of
the reproducible research process. Part two (chapters
\@ref(Storing), \@ref(DataGather), and \@ref(DataClean))
covers the data gathering and file storage process. The third part
(chapters \@ref(StatsModel), \@ref(TablesChapter), and \@ref(FiguresChapter))
teaches you how to dynamically incorporate
your statistical analysis, results figures, and tables into your
presentation documents. The final part (chapters \@ref(LatexChapter), \@ref(LargeDocs),
and \@ref(MarkdownChapter)) covers how to create reproducible
presentation documents including LaTeX articles, books, slideshows, and
batch reports as well as Markdown webpages and slideshows.


## Appendix: Additional R Setup {-}

Some setup is required to reproduce this book. Here are key R packages you should consider installing and specific instructions for Windows and Linux users.

### R Packages {-}

In this book I discuss how to use a number of user-written R packages for reproducible research. Many of these packages are not included in the default R installation. They need to be installed separately.

\index{R!packages|(}

**Note:** in general you should aim to minimize the number of packages that your research depends on. Doing so will lessen the possibility that your code will ``break'' when a package is updated. This book depends on relatively many packages because of its special and unusual purpose of illustrating a variety of tools that you can use for reproducible research.

To install key user-written packages discussed in this book, copy the following code and paste it into your R console:

```{r package_install, results='hide'}
# Packages to install
pkg_to_install <- c("brew", "bookdown", "dplyr", "here", "knitr", "rio", 
                    "rmarkdown", "xfun")


# Check if the packages are installed, if not install them
lapply(
    pkg_to_install,
    function(pkg) {
        if (system.file(package = pkg) == "") {
            install.packages(pkg,
                repos = "http://cran.us.r-project.org"
            )
        }
    }
)
```

Note that I specified a US based R Project CRAN "mirror"\index{CRAN!mirror} to download the packages from.^[CRAN stands for the Comprehensive R Archive Network.] There are many others to choose from. See: <https://cran.r-project.org/mirrors.html>.

The *xfun* package [@R-xfun]\index{xfun} contains a function called `pkg_attach2()`. When supplied with a vector of package names like those in `pkg_to_install` above, will install all non-installed packages. `p_load()` from the *pacman* package [@R-pacman] works in a similar way. These functions are much less verbose than the example above, but they do require the user to install the package separately before `pkg_attach2()` or `p_load()` can be used. The example above relies only on functions available in the basic **R** installation.

\index{R!packages|(}

### Special issues {-}

You may need to install ImageMagick <https://www.imagemagick.org/script/index.php>\index{ImageMagick} compile the book from source. 

\index{Windows|(}

If you are using Windows, you will also need to install *Rtools*.\index{Rtools} You can install *Rtools* from: <http://cran.r-project.org/bin/windows/Rtools/>.\label{RtoolsDownload} Please use the recommended installation to ensure that your system PATH\index{PATH} is set up correctly. Otherwise your computer will not know where the tools are. Alternatively, use the `install.Rtools()` function from the *installr* [@galili2018]\index{installr)} package to install it.

\index{Windows|(}

\index{Linux|(}

On Linux you will need to install the *RCurl* [@R-RCurl]\index{RCurl} package separately. Use your 
Terminal\index{Terminal} to install these packages with the following (or similar depending on your system) code:

```{sh, eval=FALSE}
apt-get update

apt-get install libcurl4-gnutls-dev
apt-get install r-cran-rcurl-
```

\index{Linux|(}

[^chapter1_1_1]: @rokem2018 [3-4] note that some disciplines, e.g. computing
    machinery and meteorology, give "replicable" and "reproducible" the exact
    opposite meanings from they way they are used in this book and many other
    disciplines such as biology, economics, and epidemiology.

[^chapter1_1]: This is close to what [@lykken1968] calls "operational
    replication".

[^chapter1_2]: The really reproducible computational research originates
    in the 1980s and early 1990s with Jon Claerbout and the
    Stanford Exploration Project
    [@fomel2009; @donoho2009]. Further seminal advances were made by
    Jonathan B. Buckheit and David L. Donoho who created the Wavelab
    library of MATLAB routines for their research on wavelets in the
    mid-1990s [@buckheit1995].

[^chapter1_3]: Reproducibility is important for both quantitative and qualitative
    research [@king1994]. Nonetheless, we will focus mainly on on
    methods for reproducibility in quantitative computational research.

[^chapter1_4]: Much of the reproducible computational research and literate
    programming literatures have traditionally used the term "weave" to
    describe the process of combining source code and presentation
    documents [see @knuth1992 101]. In the R community weave is usually
    used to describe the combination of source code and LaTeX documents.
    The term "knit" reflects the vocabulary of the *knitr* R package
    (knit + R). It is used more generally to describe weaving with a
    variety of markup languages. The term is used by RStudio if you are
    using the *rmarkdown* package, which is similar to *knitr*. We also
    cover the *rmarkdown* package in this book. Because of this, I use
    the term knit rather than weave in this book.

[^chapter1_5]: See the American Physical Society's website at
    <http://www.aps.org/policy/statements/99_6.cfm>. See also
    [@fomel2009].

[^chapter1_6]: Of course, it's important to keep in mind that reproducibility is
    "neither necessary nor sufficient to prevent mistakes"
    [@stodden2009b].

[^chapter1_7]: There are ways to enable some public reproducibility without
    revealing confidential information. See [@vandewalle2007] for a
    discussion of one approach.

[^chapter1_8]: See this post by David Smith about how the J.P. Morgan "London
    Whale" problem may have been prevented with the type of processes
    covered in this book:
    <http://blog.revolutionanalytics.com/2013/02/did-an-excel-error-bring-down-the-london-whale.html>
    (posted 11 February 2013).

[^chapter1_9]: The book was created with R version and developer builds of
    RStudio version 0.99.370.

[^chapter1_10]: In this book I cover the Bash shell for Linux and Mac as well as
    Windows PowerShell.

[^chapter1_11]: I know you can write scripts in statistical programs like SPSS,
    but doing so is not encouraged by the program's interface and you
    often have to learn multiple languages for writing scripts that run
    analyses, create graphics, and deal with matrices.

[^chapter1_12]: Donald Knuth coined the term literate programming in the 1970s to
    refer to a source file that could be both run by a computer and
    "woven" with a formatted presentation document [@knuth1992].

[^chapter1_13]: A very interesting tool that is worth taking a look at for the
    Python programming language is HTML Notebooks created with Jupyter.
    For more details see <http://jupyter.org/>. We will also discuss these in more detail in Section \@ref(JupyterIntro).

[^chapter1_14]: Syntax highlighting uses different colors and fonts to
    distinguish different types of text.

[^chapter1_15]: Note that the Sweave-style syntax is not identical to actual
    *Sweave* syntax. See Yihui Xie's discussion of the differences
    between the two at: <http://yihui.name/knitr/demo/sweave/>. *knitr*
    has a function (`Sweave2knitr`) for converting *Sweave* to *knitr*
    syntax.

[^chapter1_16]: It does this by relying on a tool called Pandoc [@pandoc2014].
\index{Pandoc}

[^chapter1_17]: If you are more comfortable with a what-you-see-is-what-you-get
    (WYSIWYG) word processor like Microsoft Word, you might be
    interested in exploring Lyx. It is a WYSIWYG-like LaTeX editor that
    works with *knitr*. It doesn't work with the other markup languages
    covered in this book. For more information see:
    <https://www.lyx.org/>. I give some brief information on using Lyx
    with *knitr* in Chapter 3's Appendix.

[^chapter1_18]: LaTeX is is really a set of macros for the TeX typesetting
    system. It is included in all major TeX distributions.

[^chapter1_19]: To verify this, open the Terminal and type: `make –version` (I
    used version 3.81 for this book). This should output details about
    the current version of Make installed on your computer.

<!--chapter:end:03-introduction.Rmd-->

# Getting Started with Reproducible Research {#GettingStartedRR}

Researchers often start thinking about making their work reproducible
near the end of the research process when they write up their results or
maybe even later when a journal requires their data and code be made
available for publication. Or maybe even later when another researcher
asks if they can use the data from a published article to reproduce the
findings. By then there may be numerous versions of the data set and
records of the analyses stored across multiple folders on the
researcher's computers. It can be difficult and time consuming to sift
through these files to create an accurate account of how the results
were reached. Waiting until near the end of the research process to
start thinking about reproducibility can lead to incomplete
documentation that does not give an accurate account of how findings
were made. Focusing on reproducibility from the beginning of the process
and continuing to follow a few simple guidelines throughout your
research can help you avoid these problems. Remember "reproducibility is
not an afterthought–it is something that must be built-into the project
from the beginning" [@donoho2010 386].

This chapter first gives you a brief overview of the reproducible
research process: a workflow for reproducible research. Then it covers
some of the key guidelines that can help make your research more
reproducible.

## The Big Picture: A Workflow for Reproducible Research

The three basic stages of a typical computational empirical research
project are:

-   data gathering,

-   data analysis,

-   results presentation.

Each stage is part of the reproducible research workflow covered in this
book. Tools for reproducibly gathering data are covered in Part II. Part
III teaches tools for tying the data we gathered to our statistical
analyses and presenting the results with tables and figures. Part IV
discusses how to tie these findings into a variety of documents you can
use to advertise your findings.

Instead of starting to use the individual tools of reproducible research
as soon as you learn them, I recommend briefly stepping back and
considering how the stages of reproducible research *tie* together.
This will make your workflow more coherent from the beginning
and save you a lot of backtracking later on. Figure \@ref(fig:WorkflowTies)
illustrates the workflow. Notice that most of the arrows connecting the
workflow's parts point in both directions, indicating that you should
always be thinking about how to make it easier to go backwards through
your research, i.e. reproduce it, as well as forwards.

Around the edges of the figure are some of the functions you will learn
to make it easier to go forwards and backwards through the process.
These functions tie your research together. For example, you can use
API-based R packages to gather data from the internet. You can use R's
`merge()` function to combine data gathered from different sources into one
data set. The `getURL()` function from R's *RCurl* package [@R-RCurl] and
the `read.table()` function in base R or the much more versatile `import()` 
function from the *rio* package [@R-rio]\index{rio} can be used to bring this data set into
your statistical analyses. The *knitr* or *rmarkdown* package then
ties your analyses into your presentation documents. This includes the
code you used, the figures you created, and, with the help of tools such
as the `kable()` function in the *knitr* package, tables of results. You
can even tie multiple presentation documents together. For example, you
can access the same figure for use in a LaTeX article and a
Markdown-created website with the `includegraphics` and `![]()`
functions, respectively. This helps you maintain a consistent
presentation of results across multiple document types. We'll cover
these functions in detail throughout the book. See Table
\@ref(TableTieFunctions) for a brief but more complete overview of the main
*tie functions*.

```{r WorkflowTies, engine = "tikz", fig.cap = "Example Workflow and a Selection of Functions to Tie It Together", cache=TRUE, echo=FALSE, fig.ext=if (knitr:::is_latex_output()) 'pdf' else 'png'}
\usetikzlibrary{decorations.pathmorphing}

\definecolor{Blue}{HTML}{7BCCC4}
\definecolor{LiteBlue}{HTML}{A8DDB5}
\definecolor{DarkBlue}{HTML}{08589E}

\definecolor{GrayLine}{HTML}{BDBDBD}

% Set node styles
%% Workflow stage nodes
\tikzstyle{Stage} = [draw=Blue,
                     %fill=Blue,
                     rectangle,
                     text width=7em,
                     inner sep=0.5cm,
                     font=\small]

% Raw Data nodes
\tikzstyle{RawData} = [draw=LiteBlue,
                       %fill=LiteBlue,
                       decorate,
                       decoration={random steps,
                                   segment length=2pt,
                                   amplitude=2pt},
                       inner sep=0.25cm,
                       font=\scriptsize]

% Separator line style
\tikzstyle{sepline} = [draw,
                        very thick,
                        color=GrayLine]

% Link function nodes
\tikzstyle{Links} = [draw=none,
                          text width=6em,
                          text=DarkBlue,
                          font=\footnotesize]

% Begin tikz picture
\begin{tikzpicture}

    % Raw Data Nodes
    \node (Data1) at (-3, 7) [RawData]{Raw Data};
    \node (Data2) at (-3, 5) [RawData]{Raw Data};
    \node (Data3) at (-3, 3) [RawData]{Raw Data};

    % Workflow stage nodes
    \node (DataGather) at (0.5, 5) [Stage, text width= 6em]{Data Gather};
    \node (Analysis) at (5.5, 5) [Stage, text width= 4em]{Analysis};
    \node (Presentation1) at (9, 8) [Stage]{LaTeX Book, \\ Article, \& \\ Slideshow \\ Presentations};
    \node (Presentation2) at (9, 2.5) [Stage]{Markdown/ \\ HTML Website \\ Presentations};

    % Lines
    \draw [->, very thick] (Data1) -- (DataGather);
    \draw [->, very thick] (Data2) -- (DataGather);
    \draw [->, very thick] (Data3) -- (DataGather);
    \draw [<->, very thick] (DataGather) -- (Analysis);
    \draw [<->, very thick] (Analysis) -- (Presentation1);
    \draw [<->, very thick] (Analysis) -- (Presentation2);

    \draw [<->, very thick] (Presentation1) -- (Presentation2);

    \path [sepline] (-3.5, 0.75) -- (11, 0.75);
    \path [sepline] (11.5, 9) -- (11.5, 1.5);

    % Link function nodes

    \node (pres) at (13, 5) [Links]{{\emph{knitr}} \\ \texttt{input} \\ \texttt{include} \\ \texttt{includegraphics} \\ Pandoc \\ \texttt{![]()}};
    \node (knitr) at (7.5, -1) [Links]{ {\emph{knitr}} \\ \emph{rmarkdown} \\ \texttt{source} \\ \texttt{source\_url} \\ \texttt{kable} \\ \texttt{print(xtable())} \\ \texttt{texreg} };
    \node (readData) at (3, -1) [Links]{\texttt{import} \\ \texttt{read.table} \\ \texttt{getURL} };

    \node (importData) at (-1, -1.3) [Links]{ \texttt{Make} \\ \texttt{download.file} \\ \texttt{read.table} \\ \texttt{import} \\ \texttt{merge}\\ \texttt{getURL} \\ API-based packages };


\end{tikzpicture}
```

### Reproducible theory

An important part of the research process that I do not discuss in this
book is theoretical stage. Ideally, if you are using a deductive
research design, the bulk of this work will precede and guide the data
gathering and analysis stages. Just because I don't cover this stage of
the research process doesn't mean that theory building can't and
shouldn't be reproducible. It can in fact be "the easiest part to make
reproducible" [@vandewalle2007 1254]. Quotes and paraphrases from
previous works in the literature obviously need to be fully cited so
that others can verify that they accurately reflect the source material.
For mathematically based theory, clear and complete descriptions of the
proofs should be given.

Though I don't actively cover theory replication in depth in this book,
I do touch on some of the ways to incorporate proofs and citations into
your presentation documents. These tools are covered in Part IV.

## Practical Tips for Reproducible Research

Before we start learning the details of the reproducible research
workflow with R and RStudio, it's useful to cover a few broad tips that
will help you organize your research process and put these skills in
perspective. The tips are:

1.  Document everything!

2.  Everything is a (text) file.

3.  All files should be human readable.

4.  Explicitly tie your files together.

5.  Have a plan to organize, store, and make your files available.

Using these tips will help make your computational research really
reproducible.

### Document everything!

In order to reproduce your research, others must be able to know what
you did. You have to tell them what you did by documenting as much of
your research process as possible. Ideally, you should tell your readers
how you gathered your data, analyzed it, and presented the results.
Documenting everything is the key to reproducible research and lies
behind all of the other tips in this chapter and tools you will learn
throughout the book.

#### Document your R session info {- #SessionInfoHow}

Before discussing the other tips it's important to learn a key part of
documenting with R. You should *record your session info*. Many things
in R have stayed the same since it was introduced in the early 1990s.
This makes it easy for future researchers to recreate what was done in
the past. However, things can change from one version of R to another
and especially from one version of an R package to another. Also, the
way R functions and how R packages are handled can vary across different
operating systems, so it's important to note what system you used.
Finally, you may have R set to load packages by default (see Section
\@ref(Packages) for information about packages). These packages might be
necessary to run your code, but other people might not know what
packages and what versions of the packages were loaded from just looking
at your source code. The `sessionInfo()` function in R prints a record of
all of these things. The information from the session I used to create
this book is:

```{r Ch2SessionInfoPlain, size='tiny', echo=TRUE, tidy=TRUE}
# Print R session info
sessionInfo()
```

Chapter \@ref(DirectoriesChapter) gives specific details about how to
create files with dynamically included session information. If you use
non-R tools you should also record what versions of these tools you
used.

### Everything is a (text) file

Your documentation is stored in files that include data, analysis code,
the write-up of results, and explanations of these files (e.g. data set
codebooks, session info files, and so on). Ideally, you should use the
simplest file format possible to store this information. Usually the
simplest file format is the humble, but versatile, text file.[^chapter2_1]

Text files are extremely nimble. They can hold your data in, for
example, comma-separated values () format. They can contain your
analysis code in files. And they can be the basis for your presentations
as markup documents like or , for LaTeX and Markdown files,
respectively. All of these files can be opened by any program that can
read text files.

One reason reproducible research is best stored in text files is that
this helps *future-proof* your research. Other file formats, like
those used by Microsoft Word (`.docx`) or Excel (`.xlsx`), change
regularly and may not be compatible with future versions of these
programs. Text files, on the other hand, can be opened by a very wide
range of currently existing programs and, more likely than not, future
ones as well. Even if future researchers do not have R or a LaTeX
distribution, they will still be able to open your text files and, aided
by frequent comments (see below), be able to understand how you
conducted your research [@bowers2011 3].

Text files are also very easy to search and manipulate with a wide range
of programs–such as R and RStudio–that can find and replace text
characters as well as merge and separate files. Finally, text files are
easy to version and changes can be tracked using programs such as Git
(see Chapter \@ref(Storing)).

#### Learn from the text file: keep it simple {-}

Text files are simple. Their simplicitly increases the probability of baseline usefulness in the future to researchers who will reproduce our work. We can extend the logic of the simple text file to all of the tools we use: keep it simple. Avoid adding dependencies you don't need to actually gather your data, analyze it, and present the results. For example, I have been tempted to make my presentation slides look nicer with new fonts. I was later burned when I wanted to make minor changes to slides a year after I first presented them (and a day before teaching an upcoming class) only to find that the custom fonts were no longer available. This broke my slides and forced me to spend considerable time reworking writing my source documents. If I, the creator of the slides, found this time consuming and annoying, imagine how an outside researcher would find it.

### All files should be human readable

Treat all of your research files as if someone who has not worked on the
project will, in the future, try to understand them. Computer code is a
way of communicating with the computer. It is ‘machine readable' in that
the computer is able to use it to understand what you want to do.[^chapter2_2]
However, there is a very good chance that other people (or you six
months in the future) will not understand what you were telling the
computer. So, you need to make all of your files ‘human readable'. To
make them human readable, you should comment on your code with the goal
of communicating its design and purpose [@wilson2012]. With this in mind
it is a good idea to *comment frequently* [@bowers2011 3] and
*format your code using a style guide* [@nagler1995]. For especially
important pieces of code you should use *literate programming*–where
the source code and the presentation text describing its design and
purpose appear in the same document. Doing this will make it very clear
to others how you accomplished a piece of research.

#### Commenting {-}

In R, everything on a line after a hash character––(also known as
number, pound, or sharp) is ignored by R, but is readable to people who
open the file. The hash character is a comment declaration character.
You can use the to place comments telling other people what you are
doing. Here are some examples:

```{r Ch2CommentHash}
# A complete comment line
2 + 2 # A comment after R code
```

On the first line the (hash) is placed at the very beginning, so the
entire line is treated as a comment. On the second line the is placed
after the simple equation `2 + 2`. R runs the equation and finds the
answer , but it ignores all of the words after the hash.

Different languages have different comment declaration characters. In
LaTeX everything after the percent sign is treated as a comment, and in
Markdown/HTML comments are placed inside of . The hash character is used
for comment declaration in command-line shell scripts.

Nagler [-@nagler1995 491] gives some advice on when and how to use
comments:

-   write a comment before a block of code describing what the code
    does,

-   comment on any line of code that is ambiguous.

In this book I follow these guidelines when displaying code. Nagler also
suggests that all of your source code files should begin with a comment
header. *At the least* the header should include:

-   a description of what the file does,

-   the date it was last updated,

-   the name of the file's creator and any contributors.

You may also want to include other information in the header such as
what files it depends on, what output files it produces, what version of
the programming language you are using, sources that may have influenced
the code, and how the code is licensed. Here is an example of a minimal
file header for an R source code file that creates the third figure in
an article titled ‘My Article':

```{r Ch2CommentHeader, echo=TRUE, tidy=FALSE}
############################
# R Source code file used to create Figure 3 in My 'Article'
# Created by Christopher Gandrud
# MIT License
############################
```

Feel free to use things like the long series of hash marks above and
below the header, white space, and indentations to make your comments
more readable.

#### Style guides {-}

In natural language writing you don't necessarily have to follow a style
guide. People could probably figure out what you are trying to say, but
it is a lot easier for your readers if you use consistent rules. The
same is true when writing computer code. It's good to follow consistent
rules for formatting your code so that it's easier for you and others to
understand.

There are a number of R style guides. Most of them are similar to the
Google R Style Guide.[^chapter2_3] Hadley Wickham also has a nicely presented R
style guide.[^chapter2_4] You may want to use the *styler* [@R-styler]\index{styler}
package to automatically reformat your code so that it is easier to
read.

#### Literate programming {-}

For particularly important pieces of research code it may be useful to
not only comment on the source file, but also display code in
presentation text. For example, you may want to include key parts of the
code you used for your main statistical models and an explanation of
this code in an appendix following your article. This is commonly
referred to as literate programming [@knuth1992].

### Explicitly tie your files together

If everything is just a text file, then research projects can be thought
of as individual text files that have a relationship with one another.
They are tied together. A data file is used as input for an analysis
file. The results of an analysis are shown and discussed in a markup
file that is used to create a PDF document. Researchers often do not
explicitly document the relationships between files that they used in
their research. For example, the results of an analysis–a table or
figure–may be copied and pasted into a presentation document. It can be
very difficult for future researchers to trace the table or figure back
to a particular statistical model and a particular data set without
clear documentation. Therefore, it is important to make the links
between your files explicit.

Tie functions are the most dynamic way to explicitly link your files
together. These functions instruct the computer program you are using to
use information from another file. In Table \@ref(TableTieFunctions) I have
compiled a selection of key tie functions you will learn how to use in
this book. We'll discuss many more, but these are some of the most
important.

### Have a plan to organize, store, and make your files available

Finally, in order for independent researchers to reproduce your work,
they need to be able access the files that instruct them how to do this.
Files also need to be organized so that independent researchers can
figure out how they fit together. So, from the beginning of your
research process you should have a plan for organizing your files and a
way to make them accessible.

One rule of thumb for organizing your research in files is to limit the
amount of content any one file has. Files that contain many different
operations can be very difficult to navigate, even if they have detailed
comments. For example, it would be very difficult to find any particular
operation in a file that contained the code used to gather the data, run
all of the statistical models, and create the results figures and
tables. If you have a hard time finding things in a file you created,
think of the difficulties independent researchers will have!

Because we have so many ways to link files together, there is really no
need to lump many different operations into one file. So, we can make
our files modular. One source code file should be used to complete one
or just a few tasks. Breaking your operations into discrete parts will
also make it easier for you and others to find errors [@nagler1995 490].

Chapter \@ref(DirectoriesChapter) discusses file organization in much more
detail. Chapter \@ref(Storing) teaches you a number of ways to make your
files accessible through the cloud computing services like GitHub.

\begin{table}
    \caption{A Selection of Functions/Packages/Programs for Tying Together Your Research Files}
    \label{TableTieFunctions}
    \vspace{0.3cm}
    {\footnotesize{
    \begin{tabular}{p{2.5cm} c p{5.25cm} p{2cm}}
        \hline
        Function/Package/ Program & Language & Description & Chapters Discussed \\[0.3cm]
        \hline \hline
        {\emph{knitr}} & R & R package with commands for tying analysis code into presentation documents including those written in LaTeX and Markdown. & \hfill Throughout \\[0.25cm]
        \emph{rmarkdown} & R & R package that builds on \emph{knitr}. It allows you to use Markdown to output to HTML, PDFs compiled with LaTeX or Microsoft Word. & \hfill Throughout \\[0.25cm]
        {\tt{download.file}} & R & Downloads a file from the internet. & \hfill\ref{DataGather} \\[0.25cm]
        {\tt{read.table}} & R & Reads a table into R. You can use this to import a plain-text file formatted data into R. & \hfill\ref{DataGather} \\[0.25cm]
        {\tt{read.csv}} & R & Same as \texttt{read.table} with default arguments set to import \texttt{.csv} formatted data files. & \hfill\ref{DataGather} \\[0.25cm]
        {\tt{import}} & R & Reads a table stored locally or on the internet into R. You can use it to import a wide variety of plain-text data formats into R from secure (https) URLs. & \hfill\ref{DataGather} \\[0.25cm]
        API-based packages & R & Various packages use APIs to gather data from the internet. & \hfill\ref{DataGather} \\[0.25cm]
        {\tt{merge}} & R & Merges together data frames. & \hfill\ref{DataClean} \\[0.25cm]
        {\tt{source}} & R & Runs an R source code file. & \hfill\ref{StatsModel} \\[0.25cm]
        {\tt{source\_url}} & R & From the {\emph{devtools}} package. Runs an R source code file from a secure ({\tt{https}}) url like those used by GitHub. & \hfill\ref{StatsModel} \\[0.25cm]
        {\tt{kable}} & R & Creates tables from data frames that can be rendered using Markdown or LaTeX. & \hfill\ref{TablesChapter} \\[0.25cm]
        {\tt{toLaTeX}} & R & Converts R objects to LaTeX. & \hfill\ref{GettingStartedRR} \\[0.25cm]
        {\tt{input}} & LaTeX & Includes LaTeX files inside of other LaTeX files. & \hfill\ref{LargeDocs} \\[0.25cm]
        {\tt{include}} & LaTeX & Similar to {\tt{input}}, but puts page breaks on either side of the included text. Usually it is used for including chapters. & \hfill\ref{LargeDocs} \\[0.25cm]
        {\tt{includegraphics}} & LaTeX & Inserts a figure into a LaTeX document. & \hfill\ref{FiguresChapter} \\[0.25cm]
        \texttt{![]()} & Markdown & Inserts a figure into a Markdown document. & \hfill\ref{MarkdownChapter} \\  [0.25cm]
        Pandoc & shell & A shell program for converting files from one markup language to another. Allows you to tie presentation documents together. & \hfill\ref{LargeDocs} \& \ref{MarkdownChapter} \\[0.25cm]
        Make & shell & A shell program for automatically building many files at the same time. & \hfill\ref{DataGather} \\[0.25cm]
        \hline
    \end{tabular}
    }}
\end{table}

[^chapter2_1]: Plain text files are usually given the file extension `.txt`.
    Depending on the size of your data set it may not be feasible to
    store it as a text file. Nonetheless, text files can still be used
    for analysis code and presentation files.

[^chapter2_2]: Of course, if the computer does not understand it will usually
    give an error message.

[^chapter2_3]: See:
    <http://google-styleguide.googlecode.com/svn/trunk/google-r-style.html>.

[^chapter2_4]: You can find it at <http://adv-r.had.co.nz/Style.html>.

<!--chapter:end:04-getting-started.Rmd-->

# Getting Started with R, RStudio, and knitr/rmarkdown {#GettingStartedRKnitr}

If you have rarely or never used R before, the first section of this
chapter gives you enough information to be able to get started and
understand the R code I use throughout the book. For more detailed
introductions on how to use R please refer to the resources mentioned
in Chapter \@ref(Intro) (Section \@ref(OtherBooks)). Experienced R users might
want to skip the first section.

In the second section I'll give a brief
overview of RStudio. I highlight the key features of the main RStudio
panel (what appears when you open RStudio) and some of its key features
for reproducible research. Finally, I discuss the basics of the
*knitr* and *rmarkdown* packages, how to use them in R, and how
they are integrated into RStudio.

## Using R: The Basics

To get you started with reproducible research, we'll cover some very
basic R syntax-the rules for talking to R. I cover key parts of the R
language including:

-   objects & assignment,

-   component selection,

-   functions,

-   arguments,

-   the workspace and history,

-   packages.

Before discussing each of these in detail, let's open R and look
around.[^chapter3_1] When you open the R GUI program by clicking on the R icon
you should get a window that looks something like Figure
\@ref(fig:RBlankMain).[^chapter3_2] This window is the **R
console**. Below the start up information-information about
what version of R you are using, license details, and so on-you should
see a `>` (greater-than sign). This prompt is where you enter R
code.[^chapter3_3] To run R code that you have typed after the prompt, press the
`Return` or `Enter` key.
Now that we have a new R session open we can get started.

```{r RBlankMain, fig.cap="R Console at Startup", echo=FALSE, out.height="50%"}
knitr::include_graphics("images/chapter_3/BlankRConsole.png")
```

### Objects {#Objects}

If you've read a description of the R language before, you will probably have seen it
referred to as an 'object-oriented language'. What are objects? Objects
are like the R language's nouns. They are things, like a vector of
numbers, a data set, a word, a table of results from some analysis, and
so on. Saying that R is object-oriented means that R is focused on doing
actions to objects. We will talk about the actions-functions-later in this
section.[^chapter3_4] Now let's create a few objects.

#### Numeric & string objects {- #ObjectNames}

Objects can have a number of different types. Let's make two simple
objects. The first is a numeric-type object. The other is a character
object.

We can choose almost any name we want for our
objects as long as it begins with an alphabetic character and does not
contain spaces.[^chapter3_5] Just because there are relatively few hard
restrictions on object names, doesn't
mean that you should name your object anything.
Your code will be much easier to read if object
names are short and meaningful. Give each object a
unique name to avoid confusion and conflicts. For example, if you reuse an object
names in an R session you could easily accidentally overwrite it.

Let's begin working with numeric objects by creating a new object called
*number* with the number 10 in it.
To put something into the object we use the assignment operator[^chapter3_6]
(`<-`).\index{<-}:

```{r Ch3NumericObject, echo=TRUE}
number <- 10
```

To see the contents of our object, type its name into the R console.

```{r Ch3NumberSee, echo=TRUE}
number
```

Let's briefly breakdown this output. `10` is clearly the contents of
*number*. The double hash (`##`) is included here to tell
you that this is output rather than R code.[^chapter3_7] If you run functions
in your R console, you will not get the double hash in your output.
Finally, `[1]` gives the position in the object that the number 10 is on. Our object only
has one position.

Creating an object with words and other characters-a character object-is
very similar. The only difference is that you enclose the character
string (letters in a word for example) inside of single or double
quotation marks (`''`, or `""`).[^chapter3_8] Let's create an object called *words*
containing the character string "Hello World":

```{r Ch3CharacterObject, echo=TRUE}
words <- "Hello World"
```

An object's type is important to keep in mind. It determines what we
can do to the object. For example, you cannot take the mean of a character
object like the *words* object:

```{r Ch3ClassError, echo=TRUE}
mean(words)
```

Trying to find the mean of our *words* object gives us a
warning message and returns the value `r mean(words)`: not applicable. You can also
think of `NA` as meaning "missing". To find out an object's type, use the `class()`
function.\index{R function!class} For example:

```{r Ch3ClassCommand, echo=TRUE}
class(words)
```

#### Vector & data frame objects {-}

So far we have only looked at objects with a single number or character
string.[^chapter3_9] Clearly we often want to use objects that have many strings
and numbers. In R these are usually data frame-type objects and are
roughly equivalent to the data structures you would be familiar with
from using a program such as Microsoft Excel. We will be using data
frames extensively throughout the book. Before looking at data frames it
is useful to first look at the simpler objects that make up data frames.
These are called vectors. Vectors are R's "workhorse" [@matloff2011].
Knowing how to use vectors will be especially helpful when you cleanup
raw data in Chapter \@ref(DataClean) and make tables in Chapter
\@ref(TablesChapter).[^chapter3_10]

#### Vectors {-}

Vectors are the "fundamental data type" in R [@matloff2011]. They are
simply an ordered group of numbers, character strings, and so on.[^chapter3_11]
It may be useful to think of most data in R as composed of
vectors. For example, data frames\index{data.frame} are basically collections
of vectors of the same length-i.e. they have the same number of rows-attached
together to form columns.

Let's create a simple numeric vector containing the numbers 2.8, 2, and
14.8. To do this we will use the `c()` (combine)\index{R function!combine}
function and separate the numbers with commas (`,`):

```{r Ch3numeric_vectoror, echo=TRUE}
numeric_vector <- c(2.8, 2, 14.8)

# Show numeric_vector's contents
numeric_vector
```

Vectors of character strings are created in a similar way. The only
major difference is that each character string is enclosed in quotation
marks like this:

```{r Ch3CharcterVector, echo=TRUE}
character_vector <- c("Albania", "Botswana", "Cambodia")

# Show character_vector's contents
character_vector
```

#### Matrices {-}

To give you a preview of what we are going to do when we start working
with real data sets, let's combine the two vectors
*numeric_vector* and *character_vector* into a new
object with the `cbind()` function. This function binds the two vectors
together side-by-side as columns.[^chapter3_12]\index{R function!cbind}

```{r Ch3cbind, echo=TRUE}
string_num_matrix <- cbind(character_vector, numeric_vector)

# Show string_num_matrix's contents
string_num_matrix
```

By binding these two objects together we've created a new matrix
object.[^chapter3_13] You can see that the numbers in the
*numeric_vector* column are between quotation marks. Matrices,
like vectors, can only have one data type, so R has converted the numbers to strings.

#### Data frames {-}

If we want to have an object with rows and columns and allow the columns
to contain data with different types, we need to use data frames. Let's
use the `data.frame` function to combine the *numeric_vector*
and *character_vector* objects.\index{R function!data.frame}

```{r Ch3dataframe, echo=TRUE, tidy=FALSE}
string_num_df <- data.frame(character_vector, numeric_vector)

# Display contents of string_num_df data frame
string_num_df
```

In this output, you can see the data frame's *names* attribute.[^chapter3_14] It is the column names. You can use the `names()` function\index{R function!names} to see any data frame's names:[^chapter3_15]

```{r Ch10Names, echo=TRUE}
names(string_num_df)
```

You will also notice that the first column of the data set has no name
and is a series of numbers. This is the *row.names* attribute. Data frame
rows can be given any name as long as each row name is unique. We can
use the `row.names()` function to set the row names from a vector. For
example,

```{r Ch3ReassignRowNames, echo=TRUE}
# Reassign row.names
row.names(string_num_df) <- c("First", "Second", "Third")

# Display new row.names
row.names(string_num_df)
```

You can see in this example how `row.names()` can also be used
to print the row names.[^chapter3_16] The *row.names* attribute does not behave
like a regular data frame column. You cannot, for example, include it as
a variable in a regression. You can use the `row.names()` function to
assign the *row.names* values to a regular column (for an example see
Section \@ref(RowNamesTidy)).

You will notice in the output for *string_num_df* that the strings in
the **character_vector** column are not in quotation marks. This does
not mean that they are now numeric data. To prove this, try to
find the mean of **character_vector** by running it through the `mean()`
function:

```{r Ch3CharcterVectorMean, echo=TRUE}
mean(string_num_df$character_vector)
```

#### Component selection {- #ComponentSelect}

The last bit of code we just saw will probably be confusing. Why do we have a dollar sign (`$`) between the name of our data frame object name and the `character_vector` variable? The dollar sign is called the component selector.\index{R!component selector}\index{R!\$, component selector} It's also sometimes called the element name operator. Either way, it extracts a part--component--of an object. In the previous example it extracted the **character_vector** column from the *string_num_df* so that it could be fed to
the `mean()` function.

We can use the component selector to create new objects with parts of other objects. Imagine that we have *string_num_df* and want an object with only the information in the numbers column. Let's use the following code:

```{r Ch3CompSelect, echo=TRUE}
# Extract a numeric vector from string_num_df
numeric_extract <- string_num_df$numeric_vector

# Display contents of numeric_extract
numeric_extract
```

Knowing how to use the component selector will be especially useful when
we discuss making tables for presentation documents in Chapter
\@ref(TablesChapter).

#### `attach()`  and `with()` {-}

Using the component selector can create long repetitive code if you want
to select many components. You have to write the object name, a dollar
sign, and the component name every time you want to select a component.
You can streamline your code by using functions such as `attach()`\index{R function!attach} and
`with()`\index{R function!with}.

`attach()` attaches a database to R's search path.[^chapter3_17] R will
then search the database for variables you specify. You don't need to
use the component selector to tell R again to look in a particular data
frame after you have attached it. For example, let's attach the *cars*
data that comes with R. It has two variables, **speed** and
**dist**.[^chapter3_18]

```{r Ch3Attach, echo=TRUE}
# Attach cars to search path
attach(cars)

# Display speed
head(speed)

# Display dist
head(dist)
```

We used the `head()`\index{R function!head} function to see just the first few values of each
variable.

Now that we are done working with the *cars* data set, we should `detach()`\index{R function!detach} it. Not doing so could confuse R later in our session.

```{r Ch3Detach, echo=TRUE}
# Detach cars
detach(cars)
```

A safer alternative to `attach()` is `with()`. It more clearly delineates when to draw from inside a particular object. For example, we can find the mean of *numeric_vector* `with()` the *string_num_df* data frame:

```{r Ch3With, echo=TRUE, tidy=FALSE}
with(string_num_df, {
        mean(numeric_vector)
    }
)
```

You can see that in the `with()` call the data frame object goes first
and then the `mean()` function[^chapter3_19] goes second in curly brackets (`{}`).

In this book I avoid using the `attach()` and `with()`
functions. Instead I use the component selector. Though it creates longer
code, I find that code written with the component selector is less ambiguous
It's always clear which object we are selecting a component
from.

#### Subscripts {-}

Another way to select parts of an object is to use subscripts. You have
already seen subscripts in the output from our examples so far. They are
denoted with square braces (`[]`). We can use subscripts to select not
only columns from data frames but also rows and individual values. As we
began to see in some of the previous output, each part of a data frame
has an address captured by its row and column number. We can tell R to
find a part of an object by putting the row number/name, column
number/name, or both in square braces. The first part denotes the rows
and separated by a comma (`,`) are the columns.

To give you an idea of how this works let's use the *cars*
data set again. Use `head()` to get a sense of what this data looks like.

```{r Ch3HeadSwiss, echo=TRUE}
head(cars)
```

We can see a data frame with information on various cars' speeds
(**speed**) and stopping distances (**dist**). If we want to select only
the third through seventh rows we can use the following subscript
function call:

```{r Ch3FirstSeventhRows, echo=TRUE}
cars[3:7, ]
```

The colon (`:`) creates a sequence of whole numbers from 3 to 7. To
select the fourth row of the **dist** column we can type:

```{r Ch3FourthSecond, echo=TRUE}
cars[4, 2]
```

An equivalent way to do this is:

```{r Ch3FourthDist, echo=TRUE}
cars[4, "dist"]
```

Finally, we can even include a vector of column names to select:

```{r Ch3FourthBoth, echo=TRUE}
cars[4, c("speed", "dist")]
```

### Functions {#FunctionsCommands}

If objects are the nouns of the R language, functions
are the verbs. They do things to objects. Let's use the `mean` function
as an example. This function takes the mean of a numeric vector object.
Remember our *numeric_vector* object from before:

```{r Shownumeric_vector, echo=TRUE}
numeric_vector
```

To find the mean of this object simply type:

```{r numeric_vector_mean, echo=TRUE}
mean(x = numeric_vector)
```

We use the assignment operator to place a function's output into an
object. For example:

```{r numeric_vector_meanAssign, echo=TRUE}
numeric_vector_mean <- mean(x = numeric_vector)
```

Notice that we typed the function's name then enclosed the object name in
parentheses immediately afterwards. This is the basic syntax that all
functions use, i.e. `FUNCTION(ARGUMENTS)`. Even if you don't want to explicitly
include an argument, *you still need to type the parentheses after the function*.[^chapter3_21a]

#### Arguments {-}

Arguments modify what functions do. In our most recent example we gave
the `mean` function one argument (`x = numeric_vector`) telling it that we
wanted to find the mean of *numeric_vector*. Arguments use the
`ARGUMENT_LABEL = VALUE` syntax.[^chapter3_21] In this case **x** is the argument
label.

To find all of the arguments that a function can accept, look at the
**Arguments** section of the function's help
file. To access the help file type: `?FUNCTION`.\index{R function!?} For example:

```{r Ch3HelpMean, echo=TRUE, eval=FALSE, tidy=FALSE}
?mean
```

The help file will also tell you the default values that the arguments
are set to. You do not need to explicitly set an argument if
you want to use its default value.

You do need to be fairly precise with the syntax for your argument's
values. Values for logical arguments must written as `TRUE` or
`FALSE`.[^chapter3_22] Arguments that accept character strings require quotation
marks.

Let's see how to use multiple arguments with the `round()`\index{R function!round} function. This
function rounds a vector of numbers. We can use the `digits` argument to
specify how many decimal places we want the numbers rounded to. To round
the object *numeric_vector_mean* to one decimal place type:

```{r Ch3Round, echo=TRUE}
round(x = numeric_vector_mean, digits = 1)
```

Note that *arguments are always separated by commas*.

Some arguments do not need to be explicitly labeled. For example, we
could write:

```{r Ch3ArgeNoLabel, echo=TRUE}
# Find mean of numeric_vector
mean(numeric_vector)
```

R will do its best to figure out what you want and will only give up
when it can't. This will generate an error message. However, to avoid
any misunderstandings between yourself and R, it is good practice to
label your argument values. This will also make your code easier for
other people to read, i.e. it will be more reproducible.

You can stack functions inside of arguments. For example, have R find the
mean of *numeric_vector* and round it to one decimal place:

```{r Ch3StackedArgs, echo=TRUE}
round(mean(numeric_vector), digits = 1)
```

Stacking functions inside of each other can create code that is
difficult to read. Another option that potentially makes more easily
understandable code is piping\index{pipe} using the pipe function (`%>%`)\index{R function!\%>\%} that you
can access from the *magrittr* [@R-magrittr]\index{R package!magrittr} or *dplyr* [@R-dplyr]\index{R package!dplyr} packages. The basic idea behind the pipe function is that the output of one function is set as the first argument of the next. For example, to find the mean of **numeric_vector** and then round it to one decimal place use:

```{r Ch3Pipe, echo=TRUE}
# Load magrittr package
library(magrittr)

# Find mean of numeric_vector and round to 1 decimal place
mean(numeric_vector) %>%
    round(digits = 1)
```

### The workspace & history

All of the objects you create become part of your workspace,
alternatively known as the current working environment. Use the `ls()`\index{R function!ls}
function to list all of the objects in your current workspace.[^chapter3_23]

```{r Ch3LS, echo=TRUE}
ls()
```

You can remove specific objects from the workspace using the `rm()`\index{R function!rm}
function. For example, to remove the `character_vector` and `words` objects
type:

```{r Ch3RM, echo=TRUE, eval=FALSE}
rm(character_vector, words)
```

To save the entire workspace into a binary-not plain-text-RData file use
`save.image()`.\index{R function!save.image} The main argument of
`save.image()` is the location and name of the file in which you want to
save the workspace. If you don't specify the file path it will be saved
into your current working directory (see Chapter \@ref(DirectoriesChapter)
for information on files paths and working directories). To
save the current workspace in a file called *workspace_2018-12-22.RData* in
the current working directory type:

```{r Ch3Workspace, echo=TRUE, eval=FALSE}
save.image(file = "workspace_2018-10-28.RData")
```

Use `load()`\index{R function!load} to load a saved workspace back into R:

```{r Ch3LoadWS, echo=TRUE, eval=FALSE}
load(file = "workspace_2018-10-28.RData")
```

You should generally avoid having R automatically save your workspace
when you quit and reload it when you start R again. Instead, when you
return to a project, rerun the source code files. This avoids
any complications caused when you use an object in your workspace that
is left over from running an older version of the source code.[^chapter3_24] In
general I also recommend against saving data in binary RData formatted
files if feasible. They are not text files they are not human readable and
are much less future-proof.

One of the few times when saving your workspace is  useful is when
it includes an object that was computationally difficult and took a long
time to create. In this case you can save only the large object with
`save()`.[^chapter3_25]\@ref(RSave)\index{R function!save}
For example, if we have a very large
object called *model_output* we can save it to a file called *model_output.RData* like
this:

```{r Ch3Comp, echo=TRUE, eval=FALSE}
save(model_output, file = "model_output.RData")
```

### R history {#RHistory}

When you execute code in the R console it becomes part of your history. To see
the most recent functions in your history use the `history()` function.\index{R function!history} You
can also use the up and down arrows on your keyboard when your cursor is
in the R console to scroll through your history.

### Global R options {#ROptions}

In R you can set global options with `options()`.\index{R function!options} This lets
you set how R runs and outputs functions through an entire R session. For
example, to have output rounded to one decimal place, set the `digits`
argument:

```{r Ch3Options, echo=TRUE, eval=FALSE}
options(digits = 1)
```

### Installing new packages and loading functions {#Packages}

Functions are stored in R packages. The functions we have used so far were
loaded automatically by default. One of the great things about R is the
many user-created packages[^chapter3_26] that expand the number of
functions we can use. To install functions that do not come with the basic
R installation you need to install the add-on packages that
contain them. To do this, use the `install.packages()`\index{R function!install.packages} function. By default this function downloads and installs the packages from the Comprehensive R Archive Network (CRAN).\index{CRAN}

When you install a package, you will likely be given a list
of "mirrors" from which you can download the package. Select the
mirror closest to you.

Once you have installed a package you need to load when you want to
use its functions. Use the `library()` function\index{R function!library}
to load a package.[^chapter3_27] For example,
the following code loads the popular *ggplot2* plotting package:

```{r Ch3Library, echo=TRUE, warning=FALSE, message=FALSE}
library(ggplot2)
```

Please note that for the examples in this book I only specify what
package a function is from if it is not loaded by default when you start
an R session.

Finally, if you want to make sure R uses a function from a specific
package you can use the double-colon operator (`::`). For example, to
make sure that we use the `qplot` function from the *ggplot2* package we
type:

```{r Ch3ColonOperator, echo=TRUE, eval=FALSE}
ggplot2::qplot(. . .)
```

Using the double-colon ensures
that R will use the function from the particular package you want and
makes it clear to a source code reader what package a function comes
from. If you use the double-colon, you don't need to
include `library()` beforehand. Note that it does not load all of the functions in the package, just the one you ask for.

## Using RStudio

As I mentioned in Chapter \@ref(Intro), RStudio is an integrated
development environment for R. It provides a centralized and
well-organized place to do almost anything you want to do with R. As we
will see later in this chapter, it is especially well integrated with
literate programming tools for reproducible research. Right now let's
take a quick tour of the basic RStudio window.

#### The default window {-}

When you first open RStudio you should see a default window that looks
like Figure \@ref(fig:BlankMain). In this figure you see three window panes.
The large one on the left is the *Console/Terminal/Jobs* pane. The *Console* pane is an R console and functions exactly the same as the console discussed so far in this chapter. *Terminal* is a command-line terminal that you can use to use to run command-line tools like those we discuss in Chapter \@ref(DirectoriesChapter). The *Jobs* pane allows you to run R scripts in the background. This is very useful if you have computationally time consuming jobs that you would like to run while also doing other work in RStudio. 

Other panes include the *Environment/History/Connections* panes, in the upper
right-hand corner. The *Environment* pane shows you all of the objects
in your workspace and some of their characteristics, like how many
observations a data frame has. You can click on an object in this pane
to see its contents. This is especially useful for quickly looking at a
data set in much the same way that you can visually scan a Microsoft
Excel spreadsheet. The *History* pane records all of the functions you
have run. It also allows you to rerun code and insert it into a source
code file. The *Connections* pane allows you to manage connections to databases
such as an SQL server.\index{SQL}

```{r BlankMain, echo=FALSE, fig.cap="RStudio at Startup", out.width="100%"}
knitr::include_graphics("images/chapter_3/RStudioStartup.png")
```

In the lower right-hand corner you will see the
*Files/Plots/Packages/ Help/Viewer* panes. We will discuss
the *Files* pane in more detail in Chapter \@ref(DirectoriesChapter).
Basically, it allows you to navigate and organize your files. The *Plots*
pane is where figures you create in R appear. This pane allows you to
see all of the figures you have created in a session using the right and
left arrow icons. It also lets you save the figures in a variety of
formats. The *Packages* pane shows the packages you have installed,
allows you to load individual packages by clicking on the dialog box
next to them, access their help files (just click on the package name),
update the packages, and even install new packages. The *Help* pane
shows you help files. You can search for help files and search within
help files using this pane. Finally, the *Viewer* pane allows you to
view local web content like JavaScript graphics and Shiny apps.

#### The Source pane {-}

There is an important pane that does not show up when you open RStudio
for the first time. This is the *Source* pane. The *Source*
pane is where you create, edit, and run your source code files. It also
functions as an editor for your markup files. It is the center of
reproducible research in RStudio.

Let's first look at how to use the *Source* pane with regular R files.
We will then cover how it works with *knitr*/*rmarkdown* in
more detail in the next section.

R source code files have the file extension `.R`. When you create a new
source code document, RStudio will open a new *Source* pane. Do this by
going to the menu bar and clicking on `File` `New`. In the `New`
drop-down menu you have the option to create a variety of different
source code documents. Select the `R Script` option. You should now see
a new pane with a bar across the top that looks like
Figure \@ref(fig:TopBarFigs). To run the R code you have in your source code
file highlight it[^chapter3_28] and click the `Run` icon on the top bar. This
sends the code to the console where it is run. The icon to the right of
`Run` runs the code above where you have highlighted. The
`Source` icon next to this runs all of the code in the file using R's
`source` function. When you click on the last icon on the right (it has a series of stacked lines) you will get a navigable table of contents for your file; very useful for working
with longer documents, especially markup documents.

```{r TopBarFigs, echo=FALSE, fig.cap="RStudio Source Code Pane Top Bar", out.width="100%"}
knitr::include_graphics("images/chapter_3/RSourceBar.png")
```

## Using *knitr* and *rmarkdown*: The basics

To get started with *knitr* and *rmarkdown* in R or RStudio
we need to learn some of the basic concepts and syntax. The concepts are
the same regardless of the markup language we are knitting R code with,
but much of the syntax varies by markup language. *rmarkdown* relies on
*knitr* and a utility called *Pandoc* to create many different types of
presentation documents (HTML, PDF, or MS Word) from one document written
largely using *knitr*'s R Markdown syntax.

### What *knitr* does

Let's take a quick, abstract look at what the *knitr* package does. As
I've mentioned, *knitr* ties together your presentation of results with
the creation of those results. The *knitr* process takes three steps
(see Figure \@ref(fig:KnitProcess)). First we create a knittable markup
document. This contains both the analysis code and the presentation
document's markup--the text and rules for how to format the text. *knitr*
then *knits*: i.e. it runs the analysis code and converts the output
into the markup language you are using according to the rules that you
tell it to use. It inserts the marked-up results into a document that
only contains markup for the presentation document. You *compile* this
markup document as you would if you hadn't used *knitr* into your final
PDF document or webpage presenting your results.

### What *rmarkdown* does {#rmardownHeader}

The *rmarkdown* package implements a variation on this process that
utilizes a program called Pandoc to create presentation documents in
multiple formats from an a knittable document written in Markdown. The
main difference between pure *knitr* markdown and *rmarkdown* documents
is the inclusion of a header specifying how you want to render the
document with Pandoc.[^chapter3_29]

The header is written in YAML.[^chapter3_30] The YAML header can include
information such as the document's title, author, whether or not to
include a table of contents, and a link to a BibTeX bibliography file.
YAML is a straightforward data format that organizes information in a
simple hierarchy. The header begins and ends with three dashes (`---`).
Information keys-like "title" and "author"-are separated from their
associated "values" by a colon (`:`). Sub-values of a hierarchy are
denoted by being placed on a new line and indented.[^chapter3_31] Here is a basic
*rmarkdown* header that indicates the document's title, author, date,
and that it will be turned into a PDF document (via LaTeX).

```{yaml, eval=FALSE}
---
title: "A Basic PDF Presentation Document"
author: "Christopher Gandrud"
date: "2018-10-28"
output: pdf_document:
    toc: true
—--
```

The title, author, and date, will be placed at the beginning of the
output document. The final line (`toc: true`) creates a table of
contents near the beginning of the PDF document when we knit it. We will
discuss more header options in Chapter \@ref(MarkdownChapter).

RStudio can automatically create a basic header for the type of output
document that you want when you open a new *rmarkdown* file. Simply
select `File` then `R Markdown…`. A window will appear that looks like
Figure \@ref(fig:rmarkdownWindow). In this window select the type of output document
you want to create and click `Ok`.

In addition to the header, *rmarkdown* differs from basic *knitr* files in that you
can include Pandoc syntax in your R Markdown document. This can be
useful for bibliographies as we will discuss in Chapter
\@ref(MarkdownChapter). Nonetheless, remember that apart from the
header and ability to include Pandoc syntax, at the simplest level
*rmarkdown* documents are *knitr* documents written in R Markdown
syntax. Importantly, they have the same code chunk syntax we will see
shortly.

```{r rmarkdownWindow, fig.cap="The New R Markdown Options Window", echo=FALSE, out.width="100%"}
knitr::include_graphics("images/chapter_3/newRMarkdown.png")
```

### File extensions

When you save a knittable file, use a file extension that indicates (a)
that it is knittable and (b) what markup language it is using. You can
use a number of file extensions for R Markdown files including: `.Rmd`
and `.Rmarkdown`.[^chapter3_32] LaTeX documents that include *knitr*
code chunks are generally called R Sweave files and have the file
extension `.Rnw`. This terminology is a little confusing.[^chapter3_33] It is a
holdover from *knitr*'s main literate programming
predecessor *Sweave*. Note that *rmarkdown* documents can compile to
LaTeX PDF documents and support pretty much the full capabilities of LaTeX.
Because markdown is generally easier to write than raw LaTeX, `.Rnw` markup
is much less commonly used. For example, for the third edition of this book
I converted it from `.Rnw` to `.Rmd`.

```{r KnitProcess, fig.cap="*knitr*/*rmarkdown* Process", engine = "tikz", cache=TRUE, echo=FALSE, fig.ext=if (knitr:::is_latex_output()) 'pdf' else 'png'}
% Define colors for figure
%% Color palette (GnBU) chosen using ColorBrewer 2.0
%% See: http://colorbrewer2.org/
%% Not used in the print version
\definecolor{Blue}{HTML}{7BCCC4}
\definecolor{LiteBlue}{HTML}{A8DDB5}
\definecolor{DarkBlue}{HTML}{08589E}

\definecolor{GrayLine}{HTML}{BDBDBD}

% Set node styles
%% Workflow stage nodes
\tikzstyle{Docs} = [draw=Blue,
                     rectangle,
                     inner sep=0.3cm,
                     font=\small]

% Begin tikz picture
\begin{tikzpicture}

    \node(knit) at (2, 1.75) {{\emph{\textbf{Knit}}}};
    \node(compile) at (6, 1.75) {{\emph{\textbf{Compile}}}};

    % Document nodes
    \node (knittable) at (0, 0) [Docs, text width= 6em]{Knittable Document \\ (Markup + Code Chunks)};
    \node (Markup) at (4, 0) [Docs, text width= 6em]{Markup Only Document};
    \node (Presentation) at (8, 0) [Docs, text width = 6em]{Presentation Document};

    % .Rnw LaTeX Example
    \node(LaTeX) at (1, -2.5) {\textbf{\emph{knitr} LaTeX Example}};
    \node (Rnw) at (0, -3.5) [Docs, text width= 6em]{\emph{Paper.Rnw}};
    \node (tex) at (4, -3.5) [Docs, text width= 6em]{\emph{Paper.tex}};
    \node (pdf) at (8, -3.5) [Docs, text width = 6em]{\emph{Paper.pdf}};

    % Markdown to HTML Example
    \node(Markdown) at (2, -5) {\textbf{\emph{knitr}/\emph{rmarkdown} Markdown Example}};
    \node (Rmd) at (0, -6) [Docs, text width= 6em]{\emph{Website.Rmd}};
    \node (md) at (4, -6) [Docs, text width= 6em]{\emph{Website.md}};
    \node (html) at (8, -6) [Docs, text width = 6em]{\emph{Website.html}};

    % Lines
    \draw [->, very thick] (knittable) -- (Markup);
    \draw [->, very thick] (Markup) -- (Presentation);

    \draw [->, very thick] (Rnw) -- (tex);
    \draw [->, very thick] (tex) -- (pdf);

    \draw [->, very thick] (Rmd) -- (md);
    \draw [->, very thick] (md) -- (html);

\end{tikzpicture}
```


### Code chunks

Use code chunks to include knittable R code into your markup presentation documents.
Code chunk syntax differs depending on the
markup language we are using to write our documents. Let's see the
syntax for R Markdown and R LaTeX files. If you are unfamiliar with
basic LaTeX or Markdown syntax you might want to skim chapters
\@ref(LatexChapter) and \@ref(MarkdownChapter) to familiarize yourself with it
before reading this section.

#### R Markdown {- #RMarkdownChunkBasic}

In R Markdown files we begin a code chunk by writing the head:
` ```{r} `. A code chunk is closed-ended-simply with:
` ``` `. For example:

````markdown
`r ''````{r}
# Example of an R Markdown code chunk
string_num_matrix <- cbind(character_vector, numeric_vector)
```
````

The R Markdown code chunk syntax is exactly the same for files you
compile with *knitr* or *rmarkdown*.

#### R LaTeX (.`Rnw`) {-}

Code chunks are delimited in non-*rmarkdown* R LaTeX
documents in a way that emulates the long-established
*Sweave* syntax.[^chapter3_34] Sweave-style code chunks begin with the following head:
`<<>>=`. The code chunk is closed with an at sign (`@`).

```{sh, eval=FALSE}
<< >>=
string_num_matrix <- cbind(character_vector, numeric_vector)
@
```

#### Code chunk labels {-}

Each chunk has a label. When a code chunk creates a plot or the output
is cached-stored for future use-*knitr* uses the chunk
label for the new file's name. If you do not explicitly give the chunk a
label it will be assigned one like: `unnamed-chunk-1`.

To explicitly assign chunk labels in R Markdown documents, place the
label name inside of the braces after the `r`. If we wanted to use the, admittedly not descriptive, label `ex_label` we type:

````markdown
`r ''````{r ex_label}
# Example chunk label
```
````

The same general format applies to the two types of LaTeX chunks. In
Sweave-style chunks we type: `<<ex_label>>=`.
Try not to use spaces or periods in your
label names. Also remember that chunk labels *must* be unique.

#### Code chunk options

There are many times when we want to change how our code chunks are
knitted and presented. Maybe we only want to show the code and not the
results or perhaps we don't want to show the code at all but just a
figure that it produces. Maybe we want the figure to be formatted on a
page in a certain way. To make these changes and many others we can
specify code chunk options.

Like chunk labels, you specify options in the chunk head. Place them
after the chunk label, separated by a comma. Chunk options are written
following pretty much the same rules as regular R function arguments.
They have a similar `OPTION_LABEL=VALUE` structure as arguments. The
option values must be written in the same way that argument values are.
Character strings need to be inside of quotation marks. The logical
`TRUE` and `FALSE` operators cannot be written `"true"` and
`"false"`. For example, imagine we have a Markdown code chunk called
`ex_label`. If we want to run the code chunk, but
not show the code in the final presentation document, we can use the
option `echo=FALSE`.

````markdown
`r ''````{r ex_label, echo=FALSE}
string_num_matrix <- cbind(character_vector, numeric_vector)
```
````

Note that all labels and code chunk options must be on the same line.
Options are separated by commas. The syntax for *knitr*
options is the same regardless of the markup language.

Throughout this book we will look at a number of different code chunk
options. Many of the chunk options we will use in this book are listed
in Table \@ref(ChunkOptionsTable). For the full list of
*knitr* options see the *knitr* chunk options
page maintained by *knitr*'s creator Yihui Xie:
<http://yihui.name/knitr/options>.

\begin{table}
  \caption{A Selection of {\emph{knitr}} Code Chunk Options}
  \begin{center}
  \label{ChunkOptionsTable}
  \begin{tabular}{l c p{6cm}}
    \hline
    Chunk Option Label & Type & Description \\[0.25cm] \hline\hline
    \texttt{cache} & Logical & Whether or not to save results from the code chunk in a cache database. Note: cached chunks are only run when they are changed. \\[0.25cm]
    \texttt{cache.vars} & Character Vector & Specify the variable names to save in the cache database. \\[0.25cm]
    \texttt{eval} & Logical & Whether or not to run the chunk. \\[0.25cm]
    \texttt{echo} & Logical & Whether or not to include the code in the presentation document. \\[0.25cm]
    \texttt{error} & Logical & Whether or not to include error messages. \\[0.25cm]
    \texttt{engine} & Character & Set the programming language for {\emph{knitr}} to evaluate the code chunk with. \\[0.25cm]
    \texttt{fig.align} & Character & Align figures. (Note: does not work with R Markdown documents.) \\[0.25cm]
    \texttt{fig.path} & Character & Set the directory where figures will be saved. \\[0.25cm]
    \texttt{include} & Logical & When \texttt{include=FALSE} the chunk is evaluated, but the results are not included in the presentation document. \\[0.25cm]
    \texttt{message} & Logical & Whether or not to include R messages. \\[0.25cm]
    \texttt{out.height} & Numeric & Set figures' heights in the presentation document. \\[0.25cm]
    \texttt{out.width} & Numeric & Set figures' widths in the presentation document. \\[0.25cm]
    \texttt{results} & Character & How to include results in the presentation document. \\[0.25cm]
    \texttt{tidy} & Logical & Whether or not to have \emph{knitr} format printed code chunks. \\[0.25cm]
    \texttt{warning} & Logical & Whether or not to include warnings. \\[0.25cm]
    \hline
  \end{tabular}
  \end{center}
  {\scriptsize{These Functions are discussed in more detail in Chapter \ref{StatsModel}.}}
\end{table}

### Global chunk options {#GlobalChunkOptions}

So far we have only looked at how to set local options in
*knitr* code chunks, i.e. options for only one specific
chunk. If we want an option to apply to all of the chunks in our
document we can set global chunk options. Options are 'global' in the
sense that they apply to the entire document. Setting global chunk
options helps us create documents that are formatted consistently
without having to repetitively specify the same option every time we
create a new code chunk. For example, rather than using the `fig.align='center'` option in each code chunk that creates a figure we can center align all figures in a document by setting the option globally.

To set a global option, first create a new code chunk at the beginning
of your document.[^chapter3_35] You will probably want to set the option `include=FALSE` so that *knitr* doesn't include the code in your presentation
document. Inside the code chunk use `opts_chunk$set`. You can set any chunk option as an
argument to `opts_chunk$set`. The option will be applied across your document, unless
you set a different local option.

Here is an example of how you can center align all of the figures in *rmarkdown* in a chunk placed near the beginning of the document:

````markdown
`r ''````{r set_global, include=FALSE}
# Center align all knitr generated figures
knitr::opts_chunk$set(fig.align='center')
```
````

If you want to use 'opts_chunk' in a document rendered with
*rmarkdown* you will need to either explicitly call it as in the example using the double colon or load the *knitr* package before calling `opts_chunk`.

### *knitr* package options

*knitr* package options affect how the package itself runs.
For example, the `progress` option can be set as either `TRUE` or `FALSE` [^chapter3_36] depending on whether or not you want a progress bar to be displayed when you knit a
code chunk. You can use `base.dir` to set the directory where you want all of your
figures to be saved (see Chapter \@ref(DirectoriesChapter)) or the `child.path` option
to specify where child documents are located (see Chapter \@ref(LargeDocs)).

You set package options in a similar way as global chunk options with `opts_knitr$set`.
For example, include this code at the beginning of a document to turn
off the progress bar when it is knitted:

### Hooks

You can also set hooks. Hooks come in two types: chunk hooks and output
hooks. Chunk hooks run a function before or after a code chunk. Output
hooks change how the raw output is formatted. I don't cover hooks in
much detail in this book. For more information on hooks, please see
Yihui Xie's webpage: <http://yihui.name/knitr/hooks>.

### *knitr*, *rmarkdown*, & RStudio

RStudio is highly integrated with *knitr*/*rmarkdown* and
the markup languages that they work with. RStudio is probably the easiest tool
for creating and compiling *knitr*/*rmarkdown*. Most of the
RStudio/*knitr*/*rmarkdown* features are accessed in the
*Source* pane. The *Source* pane's appearance and capabilities change
depending on the type of file you have open in it. RStudio uses a file's
extension and, if it is an *rmarkdown* document, its header, to
determine what type of file you have open.[^chapter3_37] We have already seen
some of the features the *Source* pane has for R source code files.
Let's now look at how to use *knitr* and *rmarkdown* with R
source code files as well as the markup formats we cover in this book: R
Markdown and R LaTeX.

#### Compiling R source code Notebooks {- #PublishRPubs}

If you want a quick well-formatted account of the code that you ran and
the results that you got you can use RStudio's "Compile Notebook"
capabilities. RStudio uses *rmarkdown* to create a standalone file
presenting your source code and results. It will include all of the code
from an R source file as well as the output. This can be useful for quickly presenting the steps you took to do an analysis. You can see an example
RStudio Notebook in Figure \@ref(fig:NotebookExample).

If you want to create a Notebook from an open R source code file simply
click the `Compile Notebook` icon
(![image](images/chapter_3/CompileNotebook.png)) in the
*Source* pane's top bar.[^chapter3_38] Then in the window that pops up select the
output type you would like (HTML, PDF or MS Word) and click the
`Compile` button. For this example I selected HTML. In Figure
\@ref(fig:NotebookExample) you can see near the top center right a small globe
icon next to the word "Publish". Clicking this allows you to publish
your Notebook to RPubs (<http://www.rpubs.com/>). RPubs is a site for
sharing your Notebooks over the internet. You can publish not only
Notebooks, but also any *rmarkdown* Markdown
document you compile in RStudio.

```{r NotebookExample, fig.cap="RStudio Notebook Example", echo=FALSE, out.width="100%"}
#### Include notebook example image ####
knitr::include_graphics("images/chapter_3/NotebookExample.png")
```

In this chapter's appendix we discuss interactive Jupyter notebooks.\index{Jupyter} They are popular in the data science and tech industries and use a somewhat different logic from *rmarkdown* notebooks.

```{r SourcePaneRmarkdown, echo=FALSE, fig.cap="RStudio Source Pane for an RMarkdown File", out.width="100%"}
knitr::include_graphics("images/chapter_3/SourcePaneRmarkdown.png")
```

#### R Markdown {- #r-markdown}

Figure \@ref(fig:SourcePaneRmarkdown) is what the *Source* pane looks like when you have an R Markdown file open. You'll notice
the familiar `Run` button for running R code. It now includes a drop-down menu for running code chunks. It includes options like `Run Current Chunk`--i.e. run the chunk
where your cursor is located--`Run Next Chunk`, and `Run All` chunks. In this menu you can select `Insert Chunk` to insert the basic syntax required for a code chunk. You can navigate to a specific chunk using a drop-down menu on the bottom
left-hand side of the *Source* pane. This can be very
useful if you are working with a long document. To knit your file, click
the `Knit` icon on the left side of the *Source* pane's top bar.
If you click on the downward
arrow on the right of this icon you will be given the opportunity to knit the document to HTML, PDF, or, MS Word using *rmarkdown*.
Helpfully the R Markdown *Source* pane's top bar also includes the `ABC` spell check icon.

RStudio can properly highlight both the markup language
syntax and the R code in the *Source* pane. This makes your source code
much easier to read and navigate. RStudio can also fold code chunks.
This makes navigating through long documents, with long code chunks,
much easier. At line 1014 in Figure \@ref(fig:SourcePaneRmarkdown) you can see a
small downward facing arrow, If you were to click this arrow, the code
chunk would collapse to look like line 1021 in Figure
\@ref(fig:SourcePaneRmarkdown). To unfold the chunk, just click on the arrow again.

You may also notice that there is a code folding arrow on line 1015 in Figure
\@ref(fig:SourcePaneRmarkdown). This allows us to fold parts of the code chunk.
To enable this option, create a comment line with at least one hash
before the comment text and at least four after it like this:

```{r CommentFold, echo=TRUE}
#### An RStudio Foldable Comment ####
```

You will be able to fold all of the text after this comment up until the
next similarly formatted comment (or the end of the chunk).

#### R (Sweave) LaTeX {-}

Many of the *Source* pane options for R (`.Rnw) LaTeX files are the same as R Markdown
files, the key differences being that there is a `Compile PDF` icon instead of
`Knit`. Clicking this icon knits the file and creates a PDF file in
your R LaTeX file's directory. There is also a `Format` icon instead of
the question mark icon. This actually inserts LaTeX formatting functions
into your document for things such as section headings and bullet lists.
These functions can be very tedious to type out by hand otherwise.

By default RStudio may be set up to use *Sweave* for compiling LaTeX
documents. To use *knitr* instead of *Sweave* to knit
`.Rnw` files you should click on `Tools` in the RStudio menu bar then
click on `Global Options...`. Once the
**Options** window opens, click on the
`Sweave` button. Select `knitr` from the drop-down menu for "Weave Rnw
files using:". Finally, click `Apply`.[^chapter3_39]

In the `Sweave` options menu you can also set which LaTeX typesetting
engine to use. By default it is set to the more established engine
pdfLaTeX.\index{pdfLaTeX} Another option is XeLaTeX.\index{XeLaTeX} XeLaTeX has the ability to use many more characters than pdfLaTeX as it works with UTF-8 encoded input.\index{UTF-8} It can also use any font on your computer. XeLaTeX is especially useful
compared to pdfLaTeX if you are using characters that are not found in
standard English.

### *knitr* & R

As *knitr* is a regular R package, you can of course, knit
documents in R (or using the console in RStudio). All of the
*knitr* syntax in your markup document is the same as
before, but instead of clicking a or button use the function. To knit a
hypothetical Markdown file *example.Rmd* you first use the
`setwd` function to set the working directory (for more details see
Chapter \@ref(DirectoriesChapter)) to the folder where the
*example.Rmd* file is located. In this example it is
located in the Documents folder.[^chapter3_40]

```{r Ch3RawKnitSetwd, echo=TRUE, eval=FALSE, tidy=FALSE}
setwd("/Documents/")
```

Then you knit the file:

```{r Ch3RawKnit, echo=TRUE, eval=FALSE, tidy=FALSE}
knit(input = "example.Rmd", output = "example.md")
```

You use the same steps for all other knittable document types. Note that
if you do not specify the output file, *knitr* will
determine what the file name and extension should be. In this example it
would come up with the same name and location as we gave it.

In this example, using the `knit` function only creates a Markdown file
and not an HTML file, as clicking `Knit` in RStudio did. Likewise, if you use
on a file you will only end up with a basic LaTeX file and not a
compiled PDF. To convert the Markdown file into HTML you need to further
run the file through the function from the *markdown*
package, i.e.

```{r Ch3MDtoHTML, eval=FALSE, tidy=FALSE, echo=TRUE}
mardownToHTML(file = "example.md", output = "example.html")
```

This is a bit tedious. Luckily, there is a function in the
*knitr* package that combines `markdownToHTML` and `knit`.
It is called `knit2html`. You use it like this:

```{r Ch3RMDtoHTML, echo=TRUE, eval=FALSE, tidy=FALSE}
knit2html(file = "example.Rmd", output = "example.html")
```

If we want to compile a file in R we run it through the function in the
*tools* package. This package will run both LaTeX and
BibTeX to create a PDF with a bibliography (see Chapter \@ref(LatexChapter)
for more details on using BibTeX for bibliographies). Here is a example:

```{r CH3tex2pdf, echo=TRUE, eval=FALSE, tidy=FALSE}
# Load tools package
library(tools)

# Compile pdf
texi2pdf(file = "example.tex")
```

Just like with `knit2html`, you can simplify this process by using the
`knit2pdf` function to compile a PDF file from a `.Rnw` document.

### *rmarkdown* and R {#rmarkdownRender}

Just as *knitr* is an R package that you can run from the console, you
can also run *rmarkdown* from the console. Instead of the `knit`
function use `render`. Imagine that *Example.Rmd* now has an *rmarkdown*
header:

````yaml
---
title: "A Basic PDF Presentation Document"
author: "Christopher Gandrud"
date: "2018-10-28"
output:
    pdf_document:
        toc: true
    html_document:
    toc: false
—--
````

This header specifies how the file can be compiled to either PDF or
HTML. When compiled to PDF it will include a table of contents. When
compiled to HTML it won't. Now we use `render()`:\index{R function!render}

```{r Ch3RenderBasic, eval=FALSE, echo=TRUE}
render("example.Rmd")
```

This call will compile the document to a PDF in the working directory,
because PDF is listed as the first output format in the header. The
document will be called *example.pdf*. Alternatively, to compile the R
Markdown file to HTML use:

```{r Ch3RenderHTML, eval=FALSE, echo=TRUE}
render("example.Rmd", "html_document")
```

We could compile to both formats using:

```{r Ch3RenderBasicAll, eval=FALSE, echo=TRUE}
render("example.Rmd", "all")
```

or

```{r Ch3RenderBasicAltAll, eval=FALSE, echo=TRUE}
render("example.Rmd", c("pdf_document", "html_document"))
```

In all of these cases, `render` will create, but not keep the intermediate *.md* or
*.tex* document. You can have these documents saved by adding `keep_md`
or `keep_tex` to the header. For example:

````yaml
output:
    pdf_document:
        toc: true
        keep_tex: true
    html_document:
      keep_md: true
    toc: false
—--
````

Finally, if you want to output to one format with the default rendering
style, for example, the HTML document, use `html_document: default`.

### Chapter summary {#chapter-summary .unnumbered}

We've covered a lot of ground in this chapter, including R basics, how
to use RStudio, and *knitr*/*rmarkdown* syntax for multiple markup
languages. These tools, especially R and *knitr*/*rmarkdown*, are
fundamental to the reproducible research process we will learn in this
book. They enable us to create dynamic text-based files that record our
research steps in detail. In the next chapter we will look at how to
organize files created with these types of tools into reproducible
research projects.

## Appendix: Jupyter interactive notebooks {- #jupyter}

Jupyter notebooks are a commonly used alternative to R Markdown notebooks and *knitr* generally for displaying and discussing computational analyses. They are especially prevalent in the data science industry.  For example, I never used Jupyter notebooks during my academic life in the quantitative social sciences, but after moving to the tech industry I regularly write and read them. A reason for this is that they  are particularly useful for fast prototyping analyses. They are interactive. You run the code directly in the notebook and see the results printed in the notebook immediately.

Jupyter is often associated with Python, but the name 'Jupyter' actually refers to three languages used in data science **Ju**lia,\index{Julia language} **Py**thon,\index{Python} and **R** and can be used with other languages as well.

This book is clearly focused on R Markdown, but if you would like to explore launching Jupyter from R see the *IRkernel* package [@R-IRkernel]. Though personally I have been using launching Jupyter from Python or Julia, as the installation is more straightforward. In fact for the Python installation is a prerequisite for *IRkernel*. For more details see:

- Python installation instructions: <http://jupyter.org/install.html>,

- Julia installation instructions: <https://github.com/JuliaLang/IJulia.jl>.

#### Controversy {-}

In mid-2019 there was a major controversy (well at least a topic heavily discussed on data science Twitter)\index{Twitter} about Jupyter notebooks. Joel Grus started the controversy by giving a talk at the main Jupyter conference--JupyterCon--called 'I Don't Like Notebooks'.[^jupyter_dont_like]

His critique was multi-pronged, but one that resonated with my strong interest in reproducibility (and personal experience using these notebooks) is that you can execute code in Jupyter notebooks in an arbitrary order. Using R Markdown terminology: you could execute the third code chunk before the second and then make changes to and rerun the second chunk without rerunning the third. This is troubling for reproducibility as it is difficult for a third person (or yourself a few minutes later) to know what order the code was executed in to get the displayed results. Jupyter notebooks do record the order in which code was executed within the same session, but this adds an additional layer of complexity to figuring out results. The order also becomes inconsistent when a notebook is relaunched.

#### R Markdown vs. Jupyter {-}

A big reason that I personally prefer R Markdown over Jupyter is that it provides the 'best of both worlds'. RStudio allows you to interact with R Markdown documents in a very similar way to Jupyter notebooks (see Figure \@ref(fig:RMarkdownInteractive)). To enable fast prototyping, you can interactively run code chunks in any order and immediately see the results in line with the markup. It also channels you towards running the code in order when you knit the document before you share it with others.[^chapter_3_jupyter_r]

```{r RMarkdownInteractive, fig.cap="R Markdown Interactive Behavior Example in RStudio", echo=FALSE, out.width="100%"}
#### Include notebook example image ####
knitr::include_graphics("images/chapter_3/RmarkdownInteractive.png")
```


## Appendix: knitr and Lyx {- #LyxAppendix}

You may be more comfortable using a what-you-see-is-what-you-get
(WYSIWYG) editor, similar to Microsoft Word. Lyx is a WYSIWYG LaTeX
editor that can be used with *knitr*. I don't cover Lyx in detail in
this book, but here is a little information to get you started.

#### Set Up {-}

To set up Lyx so that it can compile `.Rnw` files, click `Document` in
the menu bar then `Settings`. In the left-hand panel the second option
is `Modules`. Click on `Modules` and select `Rnw (knitr)`. Click `Add`
then `Ok`. Now, compile your LaTeX document in the normal Lyx way.

#### Code Chunks {-}

Enter code chunks into TeX Code blocks within your Lyx documents. To
create a new TeX Code block, select `Insert` from the menu bar then
`TeX Code`.

[^chapter3_1]: Please see Chapter \@ref(Intro) for instructions on how to install R.

[^chapter3_2]: This figure and almost all screenshots in this book were taken on
    a computer using the Mac OS 10.14 operating system.

[^chapter3_3]: If you are using a Unix-like system such as Linux Ubuntu or Mac OS
    10, you can also access R via an application called the Terminal. If
    you have installed R on your computer you can type `R` into the Terminal.
    This will begin a new R session. You will know
    you are in a new R session because the same type of start up
    information as in Figure \@ref(fig:RBlankMain) will be printed in your
    Terminal.

[^chapter3_4]: Somewhat confusingly, functions are themselves
    objects. In this chapter I treat them as distinct from other object
    types to avoid confusion.

[^chapter3_5]: @whickham2014book argues that underscores (`_`) should be used
    to separate words in object names to make the names easier to read.
    For example: `health_data` rather than `healthdata`.
    Underscores appear to now be the dominate naming convention in the R community.
    Other conventions include using periods (`.`) or capital
    letters (referred to as CamelBack). For more
    information on R naming conventions see @baath2012.

[^chapter3_6]: The assignment operator is sometimes also referred to as the 'gets
    arrow'.

[^chapter3_7]: The double hash is generated automatically by
    *knitr*. Prepending the output with hashes makes it easier to copy and paste code
    into R from a document created by *knitr*/*rmarkdown* because R
    will ignore everything after a hash.

[^chapter3_8]: Single and double quotation marks are interchangeable in R for
    this purpose. In this book I always use double quotes, except for
    *knitr* code chunk options.

[^chapter3_9]: These might be called scalar objects, though in R scalars are just
    vectors with a length of 1.

[^chapter3_10]: If you want information about other types of R objects such as
    lists and matrices, Chapter 1 of Norman Matloff's [-@matloff2011]
    book is a really good place to look.

[^chapter3_11]: In a vector, every member of the group must be of the same type.
    If you want an ordered group of values with different types you can
    use lists.

[^chapter3_12]: If you want to combine objects as if they were rows of the same
    column(s), use the `rbind()` function.

[^chapter3_13]: Matrices are basically collections of vectors, each represented
    as a column.

[^chapter3_14]: Matrices can also have a names attribute.

[^chapter3_15]: You can also use `names()` to assign names for the entire data
    frame. For example,
    `names(string_num_df) <- c(variable_1, variable_2)`

[^chapter3_16]: Note that this is really only useful for data frames with few
    rows.

[^chapter3_17]: You can see what is in your current search path with the `search`
    function. Just type `search()` into your R console.

[^chapter3_18]: For more information on this data set, type `?cars` into your R
    console.

[^chapter3_19]: Using R terminology, the second "argument" value-the code after
    the comma-of the **with** function is called an "expression", because
    it can contain more than one R function or statement. See Section
    \@ref(arguments) for a more comprehensive discussion of R function
    arguments.

[^chapter3_21a]: If you don't include the parentheses after the function name
    R will return the source code for the function just like when you enter an
    object name into your console returns the contents. This is because in
    R functions are actually also objects!

[^chapter3_21]: Note: you do not have to put spaces between the argument label
    and the equals sign or the equals sign and the value. However,
    having spaces can make your code easier to read.

[^chapter3_22]: They can be abbreviated `T` and `F`.

[^chapter3_23]: Note: your workspace will probably include different objects than
    this example. These are objects created to knit the book.

[^chapter3_24]: For example, imagine you create an object, then change the source
    code you used to create the object. However, there is a syntax error
    in the new version of the source code. The old object won't be
    overwritten and you will be mistakenly using the old object in
    future functions.

[^chapter3_25]: `save.image()` is just a special case of `save()`.

[^chapter3_26]: For the latest list see:
    <http://cran.r-project.org/web/packages/available_packages_by_name.html>.

[^chapter3_27]: You will probably see R packages referred to as "libraries",
    though this is a misnomer.

[^chapter3_28]: If you are only running one line of code, you don't need to
    highlight the code; you can simply put your cursor on that line.

[^chapter3_29]: Note that you can also create an *rmarkdown* document without a
    header. *rmarkdown* will just use the default settings when knitting.

[^chapter3_30]: YAML is a recursive acronym that means "YAML Ain't Markup
    Language".

[^chapter3_31]: It doesn't matter how many spaces you use to indent, as long as
    all indentations have the same number of spaces.

[^chapter3_32]: R Markdown files that you compile with *knitr* or *rmarkdown*
    have the same `.Rmd` file extension.

[^chapter3_33]: The "nw" refers to noweb simple literate programming tool that
    Sweave builds on.

[^chapter3_34]: The syntax has its genesis in a literate programming tool called
    noweb @leisch2002 [@ramseynoweb].

[^chapter3_35]: In Markdown, you can put global chunk options at the very top of
    the document. In `.Rnw` documents they should be placed after the
    `\begin{document}` function (see Chapter \@ref(LatexChapter) for more
    information on how LaTeX documents are structured).

[^chapter3_36]: It's set as `TRUE` by default.

[^chapter3_37]: You can manually set how you want the *Source* pane to act by
    selecting the file type using the drop-down menu in the lower
    right-hand corner of the *Source* pane.

[^chapter3_38]: Alternatively, `File` `Compile Notebook...`

[^chapter3_39]: In the Mac version of RStudio, you can also access the `Options`
    window via `RStudio` `Preferences` in the menu bar.

[^chapter3_40]: Using the directory name is for Mac computers. Please use
    alternative syntax discussed in Chapter \@ref(DirectoriesChapter) on
    other types of systems.

[^jupyter_dont_like]: The presentation is available here: <https://docs.google.com/presentation/d/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI/preview?slide=id.g362da58057_0_1>. For a comprehensive discussion of the 'first notebook war' by Yihui Xie see: <https://yihui.name/en/2018/09/notebook-war/>.

[^chapter_3_jupyter_r]: See Nathan Stephens' 2017 blog post further making the case for R Notebooks: <https://rviews.rstudio.com/2017/03/15/why-i-love-r-notebooks/>.

<!--chapter:end:05-start-R.Rmd-->

# Getting Started with File Management {#DirectoriesChapter}

Careful file management is crucial for reproducible research. Remember
two of the guidelines from Chapter
\@ref(GettingStartedRR):

-   Explicitly tie your files together.

-   Have a plan to organize, store, and make your files available.

Apart from the times when you have an email exchange (or even meet in
person) with someone interested in reproducing your research, the main
information independent researchers have about the procedures is what
they access in files you make available: data files, analysis files, and
presentation files. If these files are well organized and the way they
are tied together is clear, replication will be much easier. File
management is also important for you as a researcher, because if your
files are well organized you will be able to more easily make changes,
benefit from work you have already done, and collaborate with others.

Using tools such as R, *knitr*/*rmarkdown*, and markup languages like
LaTeX requires fairly detailed knowledge of where files are stored in
your computer. Handling files to enable reproducibility may require you
to use command-line tools to access and organize your files. R and
Unix-like shell programs allow you to control files-creating, deleting,
relocating-in powerful and really reproducible ways. By typing these
commands you are documenting every step you take. This is a major
advantage over graphical user interface-type systems where you organize
files by clicking and dragging them with the cursor. However, typed
commands require you to know your files' specific addresses-their file
paths.

In this chapter we discuss how a reproducible research project may be
organized and cover the basics of file path naming conventions in
Unix-like operating systems, such as Mac OS X and Linux, and
Windows. We then learn how to organize them with RStudio Projects.
We'll cover some basic R and Unix-like shell commands for
manipulating files as well as how to navigate through files in RStudio
in the *Files* pane. The skills you will learn in this chapter will be
heavily used in the next chapter (Chapter \@ref(Storing)) and
throughout the book.

In this chapter we work with locally stored files, i.e. files stored on
your computer. In the next chapter we will discuss various ways to store
and access files remotely stored in the cloud.

## File Paths & Naming Conventions

All of the operating systems covered in this book organize files in
hierarchical directories, also known as file trees. To a large extent,
directories can be thought of as the folders you usually see on your
Windows or Mac desktop.[^chapter4_1] They are called hierarchical because
directories are located inside of other directories, as in Figure \@ref(fig:ExampleTree).[^chapter_4_tree_cmd]

### Root directories

A root directory is the first level in a disk, such as a hard drive. It
is the root out of which the file tree 'grows'. All other directories
are sub-directories of the root directory.\index{root directory}

On Windows computers you can have multiple root directories, one for
each storage device or partition of a storage device. The root directory
is given a drive letter assignment. If you use Windows regularly you
will most likely be familiar with `C:\` used to denote the C partition
of the hard drive. This is a root directory. On Unix-like systems,
including Macs and Linux computers, the root directory is simply denoted
by a forward slash (`/`) with nothing before it.

### Sub-directories & parent directories

You will probably not store all of your files in the root directory.
This would get very messy. Instead you will store your files in
sub-directories of the root directory. Inside of these sub-directories may
be further sub-directories and so on. A directory inside of another
directory is referred to as a child directory of a parent
directory.\index{child directory}\index{parent directory}

On Windows computers separate sub-directories are indicated with a back
slash (`\`). For example, if we have a folder called *data* inside of a
folder called *example-project* which is located in the C root directory
it has the address `C:\example-project\data`.[^chapter4_2] When you type Windows
file paths into R you need to use two backslashes rather than one: e.g.
`C:\\example-project\\data`. This is because the `\` is an escape
character in R.[^chapter4_3]\index{escape character} Escape characters tell R to interpret the next character or sequence of characters differently. For example, in Section \@ref(TSVEscape)
you'll see how `\t` can be interpreted by R as a tab rather than the
letter "t". Add another escape character to neutralize the escape
character so that R interprets it as a backslash. In other words, use an
escape character to escape the escape character. Another option for
writing Windows file names in R is to use one forward slash (`/`).

On Unix-like systems, including Mac computers, directories are indicated
with a forward slash (`/`). The file path of the *data* file on a
Unix-like system would be: `/example-project/data`. Remember that a
forward slash with nothing before it indicates the root directory. So
`/example-project/data` has a different meaning than
`example-project/data`. In the former, *example-project* is a sub-directory
of the root. In the latter, *example-project* is a sub-directory of the
current working directory (see below for details about working
directories). This is also true in Windows.

In this chapter I switch between the two file system naming conventions
to expose you to both. In subsequent chapters I use Unix-like
file paths. When you use relative paths (see below), these will work across
operating systems in R. We'll get to relative paths in a moment.

### Working directories

When you use R, markup languages, and many of the other tools covered in
this book, it is important to keep in mind what your current working
directory is. The working directory is the directory where the program
automatically looks for files and other directories, unless you tell it
to look elsewhere. It is also where it will save files. Later in this
chapter we will cover functions for finding and changing the working
directory.\index{working directory}

```{r ExampleTree, engine = "tikz", fig.cap = "Example Research Project File Tree", cache=TRUE, echo=FALSE, fig.ext=if (knitr:::is_latex_output()) 'pdf' else 'png'}
\usetikzlibrary{trees}

% Set node styles
\tikzstyle{DirBox} = [draw=black,
                      rectangle,
                      minimum width=5em,
                      very thick,
                      font=\small]

\tikzstyle{every node} = [draw=gray,
                          thin,
                          anchor=west,
                          font=\small]

% Begin tikz picture
\begin{tikzpicture}[%
  grow via three points={one child at (0.5,-0.7) and
  two children at (0.5,-0.7) and (0.5,-1.4)},
  edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}]
  % Root Directory
  \node (root) at (5, 10) [DirBox]{Root};

  % Project Directory
  \node (project) at (4.5, 8.5) [DirBox]{example-project}
        child {node {{\small{paper.Rmd}}}}
        child {node {{\small{slideshow.Rmd}}}}
        child {node {{\small{website.Rmd}}}}
        child {node {{\small{main.bib}}}}
            ;

  % Data Directory
  \node (data) at (0, 4.5) [DirBox]{data}
      child {node {{\small{main-data.csv}}}}
      child {node {{\small{Makefile}}}}
      child {node {{\small{merge-data.R}}}}
      child {node {{\small{gather-1.R}}}}
      child {node {{\small{gather-2.R}}}}
      child {node {{\small{main-data-variable-descriptions.md}}}}
      child {node {{\small{README.Rmd}}}}
        ;

  % Analysis subdirectores/files
  \node (analysis) at (1.5, 7) [DirBox]{analysis}
      child {node {{\small{analysis-1.R}}}}
      child {node {{\small{analysis-2.R}}}}
        ;

  % README and .Rproj files
  \node (readme) at (9, 7) {README.md};
  \node (rproj) at (10, 6) {example-project.Rproj};

  % Connect boxes that are not explicit children
  \draw (root) -- (project);
  \draw (project) -| (analysis);
  \draw (analysis) -| (data);
  \draw (project) -| (readme);
  \draw (project) -| (rproj);

\end{tikzpicture}
```


### Absolute vs. relative paths

\index{absolute file path}\index{relative file path}

For reproducible research, collaborative research, and even if you ever
change the computer you work on, it is a good idea to use relative
rather than absolute file paths. Absolute file paths give the entire
path of a given file or directory on a specific system. For example,
`/example-project/data` is an absolute path as it specifies the path of
the *data* child directory all the way back to the root directory.
However, if our current working directory is *example-project* and we
want to link to the *data* child directory or a file in it, we don't
need the absolute path. We could simply use `data/`, i.e. the path
relative to the working directory.

It is good practice to use relative paths and organize
your files such that using relative paths is easy. This makes your code
less dependent on the particular file structure of a particular
computer. For example, imagine you use `C:\\example-project\\data` in
your source code to link to the *data* directory. If someone--a
collaborator, a researcher reproducing your work, or even you--then
tries to run the code on a different computer, the code will break if
they are, for instance, using a Unix-like system or have placed
*example-project* in a different partition of their hard drive. This can
be fixed relatively by changing the file path in the
source. However, this is tedious (often not well documented) and
unnecessary if you use relative file paths.

Below we'll see how to RStudio Projects and the *here* [@R-here] package to automatically set working directories so that your relative file paths will transport even more easily across computers.

### Spaces in directory & file names

It is good practice to avoid putting spaces in your file and
directory names. For example, I called the example project parent
directory in Figure \@ref(fig:ExampleTree) "example-project" rather than "Example Project". Spaces in file and directory names can sometimes create problems for computer programs
trying to read the file path. The program may believe that the space
indicates that the path name has ended. To make multi-word names easily
readable without using spaces, adopt a consistent naming convention. 

One approach is to use a convention that contrasts with the R object naming convention you are using. For example, if we adopt the underscore method for R object names used in Chapter \@ref(GettingStartedRKnitr) (e.g. `health_data`) we could use em dashes (`-`) to separate words in file names. For example, `example-source.R`.

## Organizing Your Research Project

Figure \@ref(fig:ExampleTree) gives an example of how the files in a simple
reproducible research project could be organized. The project's parent
directory is called *example-project*. Inside this directory are the
primary knittable documents (*paper.Rmd* *slideshow.Rmd*, and
*website.Rmd*). In addition there is an *analysis* sub-directory with
the R files to run the statistical analyses followed by a further *data*
child directory.

The nested file structure allows you to use relative file paths. The
knittable documents can call *analysis1.R* with the relative path
*analysis/analysis1.R*, which in turn could call a file in the nested *data/*
sub-directory. 

```{r ProjectMenu, fig.cap="An Example RStudio Project Menu", echo=FALSE, fig.align='center', out.height="30%"}
knitr::include_graphics("images/chapter_4/ProjectMenu.png")
```

In addition to the main files and sub-directories in *example-project* you
will notice a files called *README.md* and *example-project.Rproj*. We'll discuss the *example-project.Rproj* file in the next section. The *README.md* file
is a human readable overview of all the files in the project. It should briefly
describe the project including things like its title, author(s), topic,
any copyright information, and so on. It should also indicate how the
folders in the project are organized and give instructions for how to
reproduce the project. The README file should be in the main project
folder-in our example this is called *example-project*-so that it is
easy to find. If you are storing your project as a GitHub repository
(see Chapter \@ref(Storing) and the file is called *README*, its contents will
automatically be displayed on the repository's main page. If the
*README* file is written using Markdown (e.g. *README.md*), it will also
be properly formatted. Figure \@ref(fig:BookRepository) shows an example of this.

It is good practice to dynamically include the system information for
the R session you used to create the project. To do this you can write
your README file with R Markdown. Simply include the `sessionInfo()`
function in a *knitr* code chunk in the R Markdown document. If you knit
this file immediately after knitting your presentation document, it will
record the information for that session.

You can also dynamically include session info in a LaTeX document. To do
this, use the function in a code chunk. The code chunk should have the
option `results='asis'`. The code is:\index{R function!toLatex}\index{R function!sessionInfo}

```{r Ch4SessionInfoLatex, eval=FALSE, echo=TRUE}
toLatex(sessionInfo())
```

## Organizing Research with RStudio Projects {#CreateRStudioProject}

If you are using RStudio, you may want to organize your files as
Projects. You can turn a normal directory into an
RStudio Project by clicking on `File` in the RStudio menu bar and
selecting `New Project…`. A new window will pop-up. Select the option
`Existing Directory`. Find the directory you want to turn into an
RStudio Project by clicking on the `Browse` button. Finally, select
`Create Project`. You will also notice in the Create Project pop-up
window that you can build new project directories and create a project
from a directory already under version control (we'll do this at the end
of Chapter \@ref(Storing). When you create a new project you will see that
RStudio has put a file with the extension `.Rproj` into the directory, like *example-project.Rproj* in Figure \@ref(fig:ExampleTree).

Making your research project directories RStudio Projects is useful for
a number of reasons:

-   The project is listed in RStudio's Project menu where it can be
    opened easily (see Figure \@ref(fig:ProjectMenu)).

-   When you open the project in RStudio it automatically sets the
    working directory to the project's directory and can load the
    source code files you were last working on.

-   You can set project specific options like whether PDF presentation
    documents should be compiled with *Sweave* or *knitr*.

-   When you close the project your R workspace and history are saved in
    the project directory if you want (though avoid saving your workspace as this could make reproducibility harder).

-   It helps you version control your files.

-   You can build your Project--run the files in a specific way--with
    makefiles.

-   Gives you an easy-to-use interface for managing the R packages that
    your project depends on.

We will look at many of these points in more detail in the next few
chapters.

## R File Manipulation Functions

R has a range of functions for handling and navigating through files.
Including these functions in your source code files allows you to more
easily replicate your actions.

#### `getwd()` {-}

To find your current working directory use the `getwd()` function:\index{R function!getwd}

```{r Ch4Getwd, echo=TRUE}
getwd()
```

The example here shows you the current working directory that was used
while knitting this chapter.

#### `list.files()` {-}

Use the `list.files()` function to see all of the files and sub-directories
in the current working directory. You can list the files in other
directories too by adding the directory path as an argument to the
function.\index{R function!list.files}

Because my current working directory has a lot of files in it, I will shorten the output for illustration by piping\index{pipe}\index{R function!\%>\%} it through `head()`.\index{R function!head}

```{r Ch4ListFiles, echo=TRUE}
library(magrittr)
list.files() %>% head()
```

#### `setwd()` {-}

\index{R function!setwd}

The `setwd()` function is the base R way to set the current working directory. For example, if we are on a Mac or other Unix-like computer we can set the working directory to
the *Analysis* directory in our Example Project (see Figure \@ref(fig:ExampleTree) like this:

````r
setwd("/example-project/analysis/")
````

Now R will automatically look in the *analysis* folder for files and
will save new files into this folder, unless we explicitly tell it to do
otherwise.

When working with a knittable document, setting the working directory
once in a code chunk changes the working directory for all subsequent
code chunks.

However . . .

#### `here::set_here` {- #sethere}

\index{R function!here}

It is not good practice for reproducibility (and just general convenience when using a source code file across multiple computers) to use `setwd()`. You will need to tediously set specific file paths for each system. Instead, use RStudio Projects, which automatically set the working directory to the one with the *.Rproj* file. If you are not using RStudio Projects, include `set_here()` from the *here* package at the top of your source code. This will create a file called *.here* in the current working directory. It functions similarly to *.Rproj* to automatically flag for *here* what should be the current working directory. Remember when you share your source code to also share the *.Rproj*/*.here* file.

#### `root.dir` in Knittable documents {-}

\index{root.dir}

By default the root (or working) directory for all of the code chunks in
a knittable document is the directory where this document is located.
You can reset the directory by feeding a new file path to the `root.dir`
option. We can set this globally[^chapter4_4] for all of the chunks in the
document by including the following code in the document's first chunk.

````r
opts_knit$set(root.dir = "/example-project/analysis")
````

We set the */example-project/analysis* sub-directory as the root
directory for all of the chunks in our presentation document.

**Note:** In general it is preferable to use the default directory and file paths relative to this rather than manually specifying `root.dir()`. Setting an alternate root directory will make reproducibility more difficult.

#### `dir.create()` {-}

\index{R function!dir.create}

Sometimes you may want to create a new directory. You can use the `dir.create` function to do this.[^chapter4_5] For example, to create a *example-project* file
in the root *C* directory on a Windows computer type:

````r
dir.create("C:\\example-project")
````

#### `file.create()` {-}

\index{R function!file.create}

Similarly, you can create a new blank file with the `file.create()`
function. To add a blank R source code file called *source-code.R* to the
*example-project* directory on the *C* drive use:

````r
file.create("C:\\example-project\\source-code.R")
````

#### `cat()` {- #catR}

\index{R function!cat}

If you want to create a new file and put text into it use the `cat()`
(concatenate and print) function. For example, to create a new file in
the current working directory called *example-cat.md* that includes the
text "Reproducible Research with R and RStudio" type:

````r
cat("Reproducible Research with R and RStudio",
    file = "example-cat.md")
````

In this example we created a Markdown formatted file by using the `.md`
file extension. We could, of course, change the file extension to `.R`
to set it as an R source code file, `.Rnw` to create a *knitr* LaTeX
file, and so on.

You can use `cat()` to print the contents of one or more objects to a
file. **Warning:** The `cat()` function will overwrite existing files with
the new contents. To add the text to existing files use the
`append = TRUE` argument.

````r
cat("More Text", file = "example-cat.md", append = TRUE)
````

#### `unlink()` {-}

\index{R function!unlink}

You can use the `unlink` function to delete files and directories.

````r
unlink("C:\\example-project\\source-code.R")
````

**Warning:** the `unlink()` function permanently deletes files, so be very
careful using it.

#### `file.rename()` {-}

\index{R function!file.rename}

You can use the `file.rename()` to, obviously, rename a file. It can also
be used to move a file from one directory to another. For example,
imagine that we want to move the *example-cat.md* file from the directory
*example-project* to one called *markdown-files* that we already
created.[^chapter4_6]

````r
file.rename(from = "C:\\example-project\\example-cat.md",
            to = "C:\\markdown-files\\example-cat.md")
````

#### `file.copy()` {-}

\index{R function!file.copy}

`file.rename()` fully moves a file from one directory to another. To
copy the file to another directory use the `file.copy()` function. It has
the same syntax as `file.rename()`:

````r
file.copy(from = "C:\\example-project\\example-cat.md",
            to = "C:\\markdown-files\\example-cat.md")
````

## Unix-like Shell Commands for File Management

Though this book is mostly focused on using R for reproducible research
it can be useful to use a Unix-like shell program to manipulate files in
large projects. Unix-like shell programs including Bash on Mac and Linux
and Windows PowerShell give you type-able commands to interact with your
computer's operating system.[^chapter4_7] We will especially return to shell
commands in the next chapter when we discuss Git version control and
makefiles for collecting data in Chapter \@ref(DataGather), as well as the command-line program[^chapter4_8] Pandoc \@ref(LargeDocs) and \@ref(MarkdownChapter)). We don't have enough space to fully
introduce shell programs or even all of the commands for manipulating
files. We are just going to cover some of the basic and most useful
commands for file management. For good introductions for Unix and Mac OS
10 computers see William E. Shotts Jr.'s [-@shottsjr2012] book on the
Linux command-line. For Windows users, Microsoft maintains a tutorial on
Windows PowerShell at
<http://technet.microsoft.com/en-us/library/hh848793>. The commands
discussed in this chapter should work in both Unix-like shells and
Windows PowerShell.

It's important at this point to highlight a key difference between R and
Unix-like shell syntax. In shell commands you don't need to put
parentheses around your arguments. For example, if I want to change my
working directory to my Mac Desktop in a shell using the `cd` command I
simply type:[^chapter4_9]

````bash
cd /Users/cgandrud/Desktop
````

In this example `cgandrud` is my user name.

#### `cd` {-}

\index{shell command!cd}

As we just saw, to change the working directory in the shell just use
the `cd` (change directory) command. Here is an example of changing the
directory in Windows PowerShell to `C:/`:

````bash
cd C:/
````

If you are in a child directory and want to change the working directory
to the previous working directory you were in, simply type:

````bash
cd -
````

If, for example, our current working directory is */User/Me/Desktop* and
we typed `cd` followed by a minus sign (`cd -`) then the working
directory would change to */User/Me*. Note this will not work in
PowerShell.

#### `pwd` {-}

\index{shell command!pwd}

To find your current working directory, use the `pwd` command (present
working directory). This is essentially the same as R's `getwd()` function.

```{r Ch4pwdcmd, engine='sh', cache=TRUE}
pwd
```

#### `ls` {-}

\index{shell command!ls}

The `ls` (list) command works very similarly to R's `list.files()`
function. It shows you what is in the current working directory.

Again, I have a lot of files in my working directory, so I will shorten the output for this example by piping it through the command line's `head` command.\index{shell command!head} The command line pipe is not `%>%` as in R, but instead `|`.\index{shell command!|}

```{r Ch4lscmd, engine='sh', cache=TRUE}
ls | head
```

As we saw earlier, R also has an `ls` command. R's `ls()` function lists
items in the R workspace. The shell's `ls` command lists files and
directories in the working directory.

#### `mkdir` {-}

\index{shell command!mkdir}

Use `mkdir` to create a new directory. For example, if I wanted to
create a directory in my Linux root directory called *new-directory* I
would type:

````shell
mkdir /new-directory
````

#### `echo` {-}

\index{shell command!echo}

There are a number of ways to create new files in Unix-like shells. One
of the simplest is the `echo` command. This command prints its argument to the Terminal. 
For example:

```{r Ch4Echo1, engine='sh', echo=TRUE, cache=TRUE}
echo Reproducible Research with R and RStudio
```

If you add the greater-than symbol (`>`) after the text you want to
print and then a file name, `echo` will create the file (if it doesn't
already exist) in the current working directory and then print the text
into the file.

```{r Ch4Echo2, eval=FALSE, engine='sh', echo=TRUE, cache=TRUE}
echo Reproducible Research with R and RStudio > example-echo.md
```

Using only one greater-than sign will completely erase the
*example-echo.md* file's contents and replace them with
`Reproducible Research with R and RStudio`. To append the text at the end
of an existing file, use two greater-than signs (`>>`).

```{r Ch4Echo3, eval=FALSE, engine='sh', echo=TRUE, cache=TRUE}
echo More text. >> example-echo.md
```

There is also a `cat` shell command. It works slightly differently than
the R version of the command and I don't cover it here.

#### `rm` {-}

\index{shell command!rm}

The command `rm` removes (deletes) files or directories. 

````bash
rm example-echo.md
````

If you want to delete a directory you will need to add the `d` (directory) option. Note that options are like arguments in an R function.\index{shell command!options} For example:

````bash
rm -d example-dir
````

Again, be careful when using this command, because it
permanently deletes the files or directories.

As we saw in Chapter \@ref(GettingStartedRKnitr), R also has an `rm()` function. It is
different because it removes objects from your R workspace rather than
files from your working directory.

#### `mv` {-}

\index{shell command!mv}

To move a file from one directory to another from a shell, use the
`mv` (move) command. For example, to move the file *example-echo.md* from
*example-project* to *markdown-files* use the following code and imagine
both directories are in the root directory:[^chapter4_10]

````bash
mv /example-project/example-echo.md /markdown-files
````

Note that the *markdown-files* directory must already exist, otherwise it
will simply rename the file. So this command is similar to the R function
`file.rename()`.

#### `cp` {-}

\index{shell command!cp}

The `mv` command completely moves a file from one directory to another.
To copy a version of the file to a new directory use the `cp` command.
The syntax is similar to `mv`:

````bash
cp /example-project/ExampleEcho.md /markdown-files
````

#### `system()` (R function) {- #systemRcommand}

\index{R function!system}

You can run shell commands from within R using R's `system()` function. For
example, to run the `echo` command from within R type:

````r
system("echo Text to Add > ExampleEcho.md")
````

## File Navigation in RStudio

The RStudio *Files* pane allows us to navigate our file tree and do some
basic file manipulations. Figure \@ref(fig:FilesPane)
shows us what this pane looks like. The pane allows us to navigate to
specific files and folders and delete and rename files. To select a
folder as the working directory tick the dialog box next to the file
then click the `More` button and select `Set As Working Directory`.
Under the `More` button you will also find
options to `Move` and `Copy` files (see Figure \@ref(fig:FilesPaneMore)).

The *Files* pane is a GUI, so our actions in the *Files* pane are not recorded as such are not as easily reproducible as the commands we learned earlier in this chapter.

```{r FilesPane, fig.cap="The RStudio Files Pane", echo=FALSE, fig.align='center', out.height="30%"}
knitr::include_graphics("images/chapter_4/RStudioFiles.png")
```

```{r FilesPaneMore, fig.cap="More Functionality in the RStudio Files Pane", echo=FALSE, fig.align='center', out.height="10%"}
knitr::include_graphics("images/chapter_4/MoreMore.png")
```

### Chapter summary {-}

In this chapter we've learned how to organize our research files to
enable dynamic replication. This included not only how they can be
ordered in a computer's file system, but also the file path naming
conventions-the addresses-that computers use to locate files. Once we
know how these addresses work we can use R and shell commands to refer
to and manipulate our files. This skill is particularly useful because
it allows us to place code in text-based files to manipulate our project
files in highly reproducible ways. In the next few chapters we will
begin to put these skills in practice when we learn how to store our
files and create data files in reproducible ways.

[^chapter_4_tree_cmd]: The command line utility *tree* is very useful for 
    visualizing your file trees. For more information see: <https://en.wikipedia.org/wiki/Tree_(command)>.\index{shell command!tree}

[^chapter4_1]: To simplify things, I use the terms 'directory' and 'folder'
    interchangeably in this book.

[^chapter4_2]: For more information on Windows file path names see this helpful
    website:
    <http://msdn.microsoft.com/en-us/library/windows/desktop/aa365247(v=vs.85).aspx>

[^chapter4_3]: As we will see in Part IV, it is also a LaTeX and Markdown escape
    character.

[^chapter4_4]: See the discussion of global chunk options in Chapter \@ref(GettingStartedRKnitr),
    Section \@ref(GlobalChunkOptions).

[^chapter4_5]: Note: you will need the correct system permissions to be able to
    do this.

[^chapter4_6]: The `file.rename()` function won't create new directories. To move a
    file to a new directory you will need to create the directory first
    with `dir.create()`.\index{R function!dir.create}

[^chapter4_7]: You can access Bash via the Terminal program on Mac OS 10 and
    Linux computers. It is the default shell on Mac and Linux, so it
    loads automatically when you open the Terminal. Windows PowerShell
    comes installed with Windows.

[^chapter4_8]: A command-line program is just a program you run from a shell.

[^chapter4_9]: Many shell code examples in other sources include the shell
    prompt, like the `$` in Bash or `>` in PowerShell. These are like
    R's `>` prompt. I don't include the prompt in code examples in this
    book because you don't type them.

[^chapter4_10]: If they were not in the root directory we would not place a
    forward slash at the beginning.

<!--chapter:end:06-file-management.Rmd-->

# (PART) Data Gathering and Storage {-}

# Storing, Collaborating, Accessing Files, and Versioning {#Storing}

In addition to being well organized, your research files need to be
accessible for other researchers to be able to reproduce your findings.
A useful way to make your files accessible is to store them on a cloud
storage service[^chapter_5_1] [see @howe2012]. This chapter describes in detail
two different cloud storage services--Dropbox and GitHub--that you can
use to make your research files easily accessible to others. Not only do
these services enable others to reproduce your research, they also have
a number of benefits for your research workflow. Researchers often face
a number of data management issues that, beyond making their research
difficult to reproduce, can make doing the initial research difficult.

First, there is the problem of **storing** data so that it is protected
against computer failure--virus infections, spilling coffee on your
laptop, and so on. Storing data locally--on your computer--or on a flash
drive is generally more prone to loss than on remote servers in the
cloud.

Second, we may work on a project with different computers and mobile
devices. For example, we may use a computer at work to run
computationally intensive analysis, while editing our presentation
document on a tablet computer while riding the train to the office. So,
we need to be able to **access** our files from multiple devices in
different locations. We often need a way for our **collaborators** to
access and edit research files as well.

Finally, we almost never create a data set or write a paper perfectly
all at once. We may make changes and then realize that we liked an
earlier version, or parts of an earlier version better. This is a
particularly important issue in data management where we may transform
our data in unintended ways and want to go back to earlier versions.
Also, when working on a collaborative project, one of the authors may
accidentally delete something in a file that another author needed. To
deal with these issues we need to store our data in a system that has
**version control**. Version control systems keep track of changes we
make to our files and allows us to access previous versions if we want
to.

You can solve all of these problems in a couple of different ways using
free or low cost cloud-based storage formats. In this chapter we will
learn how to use Dropbox and Git/GitHub for research files:

-   storage,

-   accessing,

-   collaboration,

-   version control.

## Saving Data in Reproducible Formats {#TSVEscape}

Before getting into the details of cloud-based data storage for all of
our research files, let's consider what type of formats you should
actually save your data in. A key issue for reproducibility is that
others are able to not only get hold of the exact data you used in your
analysis, but be able to understand and use the data now and in the
future. Some file formats make this easier than others.

In general, for small to moderately-sized data sets[^chapter_5_2] plain-text
formats like comma-separated values (`.csv`) or tab-separated values[^chapter_5_3]
(`.tsv`) are good ways to store your data. These formats simply store a
data set as a text file. A row in the data set is a line in the text
file. Data is separated into columns with commas or tabs, respectively.
These formats are not dependent on a specific program. Any program that
can open text files can open them, including a wide variety of
statistical programs other than R as well as spreadsheet programs like
Microsoft Excel. Using text file formats helps future-proof your
research. Version control systems that track changes to text--like
Git--are also very effective version control systems for these types of
files.

Use the `write.table()` function\index{R function!write.table} to save data in plain-text formats from R.
For example, to save a data frame called *data* as a CSV file called
*main-data.csv* in our example *data* directory (see Figure \@ref(fig:ExampleTree)):

```{r Ch5WriteTable, eval=FALSE, tidy=FALSE}
write.table(Data, "/example-project/Data/DataFiles/MainData.csv",
            sep = ",",
            row.names = FALSE)
```

`row.names = FALSE` prevents R from including the row names in the
output file.[^chapter_5_4] The `sep = ","` argument specifies that we want to use
commas to separate values into columns. For CSV files you can use a
modified version of this command called `write.csv()`.\index{R function!write.csv} This function
makes it so that you don't have to write `sep = ","`.[^chapter_5_5]\index{comma separated file format}

If you want to save your data with values separated by tabs, rather than
commas, simply set the argument `sep = "\t"` and set the file extension
to `.tsv`.\index{tab separated file format}

R is able to save data in a wide variety of other file formats, mostly
through the *foreign* or *rio* [@R-rio] packages (see Chapter \@ref(DataGather)). These formats may be less future-proof than
simple text-formatted data files.

One advantage of many other statistical programs' file formats is that
they include not only the underlying data but also other information
like variable descriptions. If you are using plain-text files to store
your data you will need to include a separate file, preferably in the
same directory as the data file describing the variables and their
sources. In Chapter \@ref(TablesChapter) (Section \@ref(VarDescriptTables)) we will look at how to automate the creation of variable description files.

## Storing Your Files in the Cloud: Dropbox

In this book we'll cover two (largely) free cloud storage services that
allow you to store, access, collaborate on, and version control your
research files. These services are Dropbox and GitHub.[^chapter_5_6] Though they
both meet our basic storage needs, they do so in different ways and
require different levels of effort to set up and maintain.

These two services are certainly not the only way to make your research
files available. Research-oriented services include the Zenodo,[^chapter_5_7]
the Dataverse Project,[^chapter_5_8] figshare,[^chapter_5_9] and RunMyCode.[^chapter_5_10] These
services include good built-in citation systems, unlike Dropbox and
GitHub. They may be a very good place to store research files once the
research is completed or close to completion. Many journals now require key reproducibility files be uploaded to these sites. However, these sites' ability to store, access, collaborate on,
and version control files *during* the main part of the research process
is mixed. Services like Dropbox and GitHub are very capable of being
part of the research workflow from the beginning.

The easiest types of cloud storage for your research are services like
Dropbox[^chapter_5_11] and Google Drive.[^chapter_5_12]\index{Google Drive}\index{Dropbox} These services not only store your
data in the cloud, but also provide ways to share files. They even
include basic version control capabilities. I'm going to focus on
Dropbox because it currently offers a complete set of features that
allow you to store, version, collaborate, and access your data. I will
focus on how to use Dropbox on a computer. Some Dropbox functionality
may be different on mobile devices.

### Storage

When you sign up for Dropbox and install the program[^chapter_5_13] it creates a
directory on your computer's hard drive. When you place new files and
folders in this directory and make changes to them, Dropbox
automatically syncs the directory with a similar folder on a cloud-based
server. Typically when you sign up for the service you'll receive a
limited amount of storage space for free, usually a few gigabytes. This
is probably enough storage space for a number of text file-based
research projects.

### Accessing data {#EnablePublicFolder}

All files stored on Dropbox have a URL address through which they can be
accessed from a computer connected to the internet. To access a DropBox file or directory's URL so that it can be downloaded, right-click on the file
icon in your Dropbox folder on your computer. Then click
`Copy Drobbox Link`. This copies the URL into your clipboard.

You need to make one small change to the link so that it can be programmatically downloaded. By default, the link will point to the Dropbox website page for the file/directory. To be able to programmatically download it, you need to change the last `0` in the URL to a `1`. For example, change:

````
https://www.dropbox.com/s/1xapw69efofpg3b/public.fin.msm.model.csv?dl=0
````

to

```
https://www.dropbox.com/s/1xapw69efofpg3b/public.fin.msm.model.csv?dl=1
```

We changed the download (`dl`) option from false (`dl=0`) to true (`dl=1`). Now you can use the link to download data in your R source code (or wherever).

Once you have the URL you can load the file directly into R using the
`import()`\index{R function!import} function in the *rio* package for
many different data formats or use the `source_url()` \index{R function!source_url} function in the
*devtools* package [@R-devtools] for source code files (see Chapter \@ref(StatsModel)).

Let's download data directly into R from Dropbox. The data set's URL is:
<https://www.dropbox.com/s/1xapw69efofpg3b/public.fin.msm.model.csv?dl=1>.[^chapter_5_15]

```{r Ch5PublicFolderDownload, message=TRUE}
# Download data on Financial Regulators
# stored on Dropbox

# Load rio
library(rio)

# Place the URL into the object fin_url
fin_url <- "https://bit.ly/2xlQ2j5"

# Download data
fin_regulator <- import(fin_url, format = "csv")

# Show variables in fin_regulator
names(fin_regulator)
```

The argument `format = "csv"` tells `import()` what format the file is in. This isn't necessary if the file path is an informative file extension.

### Collaboration

Though others can easily access your data and files with Dropbox URL
links, you cannot save files through the link. You must save files in
the Dropbox folder on your computer or upload them through the website.
If you would like collaborators to be able to modify the research files
you will need to 'share' the Dropbox folder with them. Once you create a Dropbox folder you
can share it with your collaborators by
right-clicking on the folder's name. Then select
`Share`. Enter your collaborator's email address
when prompted and select `Can Edit` from the permissions dropdown menu.
They will be sent an email that will allow them to accept
the share request and, if they don't already have an account, sign up
for Dropbox.

### Version control

Dropbox has a simple version control system. Every time you save a
document a new version is created on Dropbox. To view a previous
version, navigate to the file on the Dropbox website. Then click
on the file. In upper-right there is a menu where you can select `Version history`. This
will take you to a page listing previous versions of the file, who
created the version, and when it was created. A new version of a file is
created every time you save a file and it is synced to the Dropbox cloud
service.

Note that with a free Dropbox account, previous versions of a file are
only stored for **30 days**. To be able to save previous versions for
more than 30 days you will need a paid account.[^chapter_5_16]

## Storing Your Files in the Cloud: GitHub {#GitHubMain}

Dropbox minimally meets our four basic criteria for reproducible data
storage. It is easy to set up and use. GitHub meets the criteria and
more, especially when it comes to version control. It is, however, less
straightforward at first. In this section we will learn enough of the
basics to get you started using GitHub to store, access, collaborate on,
and version control your research.

GitHub is an interface and cloud hosting service built on top of the Git
version control system.[^chapter_5_17] Git does the version control. GitHub stores
the data remotely as well as providing a number of other features, some
of which we look at below. GitHub was not explicitly designed to host
research projects or even data. It was designed to host "socially coded"
computer programs--in what Git calls "repositories"--repos for short--by
making it easy for a number of collaborators to work together to build
computer programs. This seems very far from reproducible research.

Remember that as reproducible researchers, we are building projects out
of interconnected text files. In important ways, this is exactly the
same as building a computer program. Computer programs are also
basically large collections of interconnected text files. Like computer
programmers, we need ways to store, version control, access, and
collaborate on our text files. Because GitHub is very actively used by
people with similar needs (who are also really good programmers), the
interface offers many highly developed and robust features for
reproducible researchers.

GitHub's extensive features and heart in the computer programming
community means that it takes a longer time than Dropbox for novice
users to set up and become familiar with. So we need good reasons to
want to invest the time needed to learn GitHub. Here is a list of
GitHub's advantages over Dropbox for reproducible research that will
hopefully convince you to get started using it:[^chapter_5_18]

#### Storage and access {-}

-   Dropbox simply creates folders stored in the cloud which you can
    share with other people. GitHub makes your projects accessible on a
    fully featured project website (see Figure \@ref(fig:BookRepository)). An example feature is that it
    automatically renders Markdown files called *README.md*[^chapter_5_19] in a
    GitHub directory on the repository's website. This makes it easy for
    independent researchers to find the file and read it.

-   GitHub can create and host a website for your research project that
    you could use to present the results, not just the replication
    files.

#### Collaboration {-}

-   Dropbox allows multiple people to share files and change them.
    GitHub does this and more.

-   GitHub keeps meticulous records of who contributed what to a
    project.

-   Each GitHub repository has an "Issues" area where you can note
    issues and discuss them with your collaborators. Basically, this is
    an interactive to-do list for your research project. It also stores
    the issues so you have a full record.

-   Each repository can also host a wiki that, for example, could
    explain in detail how certain aspects of a research project were
    done.

-   Anyone can suggest changes to files in a public repository. These
    changes can be accepted or declined by the project's authors. The
    changes are recorded by the Git version control system. This could
    be especially useful if an independent researcher notices an error.

#### Version control {-}

-   Dropbox's version control system only lets you see files' names, the
    times they were created, who created them, and revert back to
    specific versions. Git tracks every change you make. The GitHub
    website and GUI programs for Mac and Windows provide nice interfaces
    for examining specific changes in text files.

-   Dropbox creates a new version every time you save a file. This can
    make it difficult to actually find the version you want as the
    versions quickly multiply. Git's version control system only creates
    a new version when you tell it to.

-   All files in Dropbox are version controlled. Git allows you to
    ignore specific files. This is helpful if you have large binary
    files (i.e. not text files) that you do not want to version control
    because doing so will use up considerable storage space.

-   Unless you have a paid account, previous file versions in Dropbox
    disappear after 30 days. GitHub stores previous versions
    indefinitely for all account types.

-   Dropbox does not merge conflicting versions of a file together. This
    can be annoying when you are collaborating on a project and more
    than one author is making changes to documents at the same time. Git
    identifies conflicts and lets you reconcile them.

-   Git is directly integrated into RStudio Projects.[^chapter_5_20]

```{r BasicGitRepo, fig.cap="A Basic Git Repository with Hidden *.git* Folder Revealed", echo=FALSE, fig.align='center', out.width="50%"}
knitr::include_graphics("images/chapter_5/BasicGitRepository.png")
```

### Setting up GitHub: Basic

There are at least three ways to use Git/GitHub on your computer. You
can use the command-line version of Git. It's available for Mac and
Linux (in the Terminal) as well as Windows through Git Bash.[^chapter_5_21] You
can also use the Graphical User Interface GitHub program. Currently,
it's only available for Windows and Mac. RStudio also has GUI-style Git
functionality for RStudio Projects. In this section I focus on how to
use the command-line version, because it will help you understand what
the GUI versions are doing and allow you to better explore more advanced
Git features not covered in this book. In the next section I will
mention how to use Git with RStudio Projects.

The first thing to do to set up Git and GitHub is go to the GitHub
website (<https://github.com/>) and sign up for an account. Second, you
should go to the following website for instructions on setting up
GitHub: <https://help.github.com/articles/set-up-git/>. The instructions
on that website are very comprehensive, so I'll direct you there for the
full setup information. Note that installing the GUI version of GitHub
also installs Git and, on Windows, Git Bash.

### Version control with Git

Git is primarily a version control system, so we will start our
discussion of how to use it by looking at how to version your
repositories.

##### Setting up Git repositories locally

You can setup a Git repo on your computer with the command-line.[^chapter_5_22] I
keep my repositories in a folder called *git_repositories*,[^chapter_5_23] though
you can use Git with almost any directory you like. The
*git_repositories* directory has the root folder as its parent. Imagine
that we want to set up a repository in this directory for a project
called *example_project*. Initially it will have one README file called
*README.md*. To do this, we would first type into the Terminal for Mac
and Linux computers:\index{shell command!mkdir}\index{shell command!cd}\index{shell command!echo}

````bash
# Make new directory 'example-project'
mkdir /git_repositories/example-project

# Change to directory 'example-project'
cd /git_epositories/example-project

# Create new file README.md
echo "# An Example Repository" > README.md
````

So far we have only made the new directory and set it as our working
directory (see Chapter \@ref(DirectoriesChapter)). All of the examples in this section
assume your current working directory is set to the repo. Then, with the
`echo` shell command we created a new file named *README.md* that
includes the text `# An Example Repository`. Note that the code is
basically the same in Windows PowerShell or Git Bash. Also, you don't
have to do these steps in the command-line. You could just create the
new folders and files the same way that you normally do with your mouse
in your GUI operating system.

Now that we have a directory with a file, we can tell Git that we want
to treat the directory *example-project* as a repository and that we want
to track changes made to the file *README.md*. Use Git's `init`
(initialize) command\index{shell command!git init} to set the directory as a repository. See Table \@ref(GitCommandsTable) for the list of Git commands covered in
this chapter.[^chapter_5_24] Use Git's `add` command to add a file to the Git
repository. For example,\index{shell command!git add}

````bash
# Initialize the Git repository
git init

# Add README to the repository
git add README.md
````

You probably noticed that you always need to put `git` before the
command. This tells the shell what program the command is from. When you
initialize a folder as a Git repository, a hidden folder called *.git*
is added to the directory (see Figure \@ref(fig:BasicGitRepo)).
This is where all of your changes are kept. If you want to add all of
the files in the working directory to the Git repository type:

````bash
# Add all files to the repository
git add .
````

When we want Git to track changes made to files added to the repository
we can use the `commit` command. In Git language we are "committing" the
changes to the repository.\index{shell command!git commit}

````bash
# Commit changes
git commit -a -m "First Commit, created README file"
````

Note: the files won't appear on GitHub yet. Later in the chapter we will
learn how to push commits to your remote GitHub repository. The `-a`
(all) option commits changes made to all of the files that have been
added to the repository. You can include a message with the commit using
the `-m` option like: `"First Commit, created README file"`. Messages
help you remember general details about individual commits. This is
helpful when you want to revert to old versions. **Remember:** Git only
tracks changes when you commit them.

Finally, you can use the `status` command for details about your
repository, including uncommitted changes. Generally it's a good idea to
use the `-s` (short) option, so that the output is more readable.\index{shell command!git status}

````bash
# Display status
git status -s
````

  Command        Description
  -------------- ------------------------------------------------------------------------------------------------------------------
  `add`          Add a file to a Git repository.
  `branch`       Create and delete branches.
  `checkout`     Checkout a branch.
  `clone`        Clone a repository (for example, the remote GitHub version) into the current working directory.
  `commit`       Commit changes to a Git repository.
  `fetch`        Download objects from the remote (or another) repository.
  `.gitignore`   Not a Git command, but a file you can add to your repository to specify what files/file types Git should ignore.
  `init`         Initialize a Git repository.
  `log`          Show a repo's commit history.
  `merge`        Merge two or more commits/branches together.
  `pull`         `fetch` data from a remote repository and try to `merge` it with your commits.
  `push`         Add committed changes to a remote Git repository, i.e. GitHub.
  `remote add`   Add a new remote repository to an existing project.
  `rm`           Remove files from Git version tracking.
  `status`       Show the status of a Git repository including uncommitted changes made to files.
  `tag`          Bookmark particularly significant commits.

  : A Selection of Git Commands[]{label="GitCommandsTable"}

Note: when you use these commands in the shell, you will need to precede
them with `git` so the shell knows what program they are from.

```{r BookRepository, fig.cap="Part of this Book's GitHub Repository Webpage", echo=FALSE, fig.align='center', out.width="90%"}
knitr::include_graphics("images/chapter_5/GitHubReadme.png")
```

##### Checkout

It is useful to step back for a second and try to understand what Git is
doing when you commit your changes. In the hidden *.git*, folder Git is
saving all of the information in compressed form from each of your
commits into a sub-folder called *objects*. Commit objects[^chapter_5_25] are
everything from a particular commit. I mean everything. If you delete
all of the files in your repository (except for the *.git* folder) you
can completely recover all of the files from your most recent commit
with the `checkout` command:

```{r Ch5CheckoutBasic, eval=FALSE, engine='sh'}
\# Checkout latest
commit git checkout -- .
```

Note that there is a space between the two dashed lines and the period.
You can also change to any other commit or any committed version of a
particular file with `checkout`. Simply replace the `--` with the commit
reference. Note that the period at the end is still very important to
include after the commit reference. The commit reference is easy to find
and copy from a repository's GitHub webpage (see below for more
information on how to create a GitHub webpage).[^chapter_5_26] For an example of a
GitHub repo webpage, see Figure
[1.2](#BookRepository){reference-type="ref" reference="BookRepository"}.
Click on the link that lists the number of repo commits on the left-hand
side of the repo's webpage. This will show you all of the commits. A
portion of this book's commit history is shown in Figure
[1.3](#BookHistory){reference-type="ref" reference="BookHistory"}. By
clicking on the icon
(![image](Children/Chapter5/images5/BrowseCodeIcon.png)) you can see
what the files at any commit looked like. Next to this button is another
with a series of numbers and letters. This is the commit's SHA-1
hash.[^chapter_5_27] For our purposes, it is the commit's reference number. Click
on the button to the left of the SHA to copy it. You can then paste it
as an argument to your command. This will revert you to that particular
commit. Also include the file name if you want to revert to a particular
version of a particular file.

![Part of this Book's GitHub Repository Commit History
Page[]{label="BookHistory"}](Children/Chapter5/images5/CommitHistory.png){#BookHistory
width="90%"}

##### Tags

SHA-1 hashes are a bit cumbersome to use as references. What was the
hash number for that one commit? To solve this problem you can add
bookmarks, known as "tags", to particularly important commits. Imagine
we just committed our first full draft of a project. We want to tag it
as version 0.1, i.e. "v0.1". To do this use Git's tag command:

```{r Ch5TagMake, eval=FALSE, engine='sh'}
\# Tag most recent commit
v0.1 git tag -a v0.1 -m \"First draft\"
```

The `-a` option adds the tag `v0.1` and `-m` lets us add a message. Now
we can checkout this particular commit by using its tag, i.e.:

```{r Ch5CheckoutTag, eval=FALSE, engine='sh'}
\# Checkout v0.1 git
checkout v0.1
```

This will create a new "branch" with a generic name *(detached from
v0.1)* where you can make changes and commit them. If you plan to
checkout a previous tagged version and make changes to it, it is a good
idea to specifically name the branch using the `-b` argument.[^chapter_5_28] For
example, to give it the name *v0.1Branch* type:

```{r Ch5CheckoutTagNamed, eval=FALSE, engine='sh'}
\# Checkout v0.1
as v0.1Brance git checkout v0.1 -b v0.1Branch
```

What is a branch?

##### Branches

Sometimes you may want to work on an alternative version of your project
and then merge changes made to this version back into the main one. For
example, the main version could be the most stable current copy of your
research, while the alternative version could be a place where you test
out new ideas. Git allows you to create a new *branch* (alternative
version of the repo) which can be merged back into the *master* (main)
branch. To see what branch you are using type:

```{r Ch5CheckBranch, engine='sh'}
\# Show git branch git branch
```

To create a new branch use, simply enough, the `branch` command. For
example, to create a new branch called *Test*:

```{r Ch5NewBranch, eval=FALSE, engine='sh'}
\# Create Test branch git
branch Test
```

You can now use `checkout` to switch to this branch.[^chapter_5_29] Here is a
shortcut for creating and checking out the branch:

```{r Ch5NewBranchShortCut, eval=FALSE, engine='sh'}
\# Create and
checkout Test branch git checkout -b Test
```

The `-b` (branch) option for `checkout` creates the new *Test* branch
before switching to it.

To merge changes you commit in the *Test* branch to the *master*, `add`
and `commit` your changes, `checkout` the *master* branch, then use the
`merge` command.[^chapter_5_30]

```{r ChMergeBrances, eval=FALSE, engine='sh'}
\# Add files git add .

\# Commit changes to Test branch git commit -a -m \"Commit changes to
Test\"

\# Checkout master branch git checkout master

\# Merge master and Test branches git merge Test
```

Note, when you merge a branch you may encounter conflicts in the files
that make it impossible to smoothly merge the files together. Git will
tell you what and where these are; you then need to decide what to keep
and what to delete.

##### Having Git ignore files

There may be files in your repository that you do not want to keep under
version control. Maybe this is because they are very large files or
cached files from *knitr* or other files that are byproducts of
compiling an R LaTeX document (see Chapter
[\[StatsModel\]](#StatsModel){reference-type="ref"
reference="StatsModel"}). To have Git ignore particular files, simply
create a file called *.gitignore*.[^chapter_5_31] You can either put this file in
the repository's parent directory to create a *.gitignore* file for the
whole repository or in a subdirectory to ignore files in that
subdirectory. In the *.gitignore* file, add ignore rules by simply
including the names of the files that you want to have Git ignore. For
example, a *.gitignore* file that is useful for ignoring files that are
the byproduct of compiling an R LaTeX file would look something like
this:

```{r Ch5gitignore, eval=FALSE, engine='sh'}
\# Ignore LaTeX compile
byproduct files \#
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#
\*.aux \*.bbl \*.blg cache/\* figure/\* \*.log \*.pdf \*.gz \*.tex
```

The asterisk (`*`) is a "wildcard" and stands for any character. In
other words, it tells Git to look for files with any name that end with
a specified file extension. This is faster than writing out the full
name of every file you want to ignore individually. It also makes it
easy to copy the rules into new repos. You'll notice the `cache/*` and
`figure/*` rules. These tell Git to ignore all of the files in the
*cache* and *figure* subdirectories. These files are the product of
caching code chunks and creating figures with *knitr*, respectively.

Git will not ignore files that have already been committed to a
repository. To ignore these files you will first need to remove them
from Git with Git's `rm` (remove) command. If you wanted to remove a
file called *example-project.tex* from version tracking type:

```{r Ch5Gitrm, eval=FALSE, engine='sh'}
\# Remove example-project.tex
from Git version tracking git rm --cached example-project.tex
```

Using the `–cached` argument tells Git not to track the file, but not
delete it.

For more information on *.gitignore* files, see GitHub's reference page
on the topic at: <https://help.GitHub.com/articles/ignoring-files>.

### Remote storage on GitHub

So far we've been using repos stored locally. Let's now look at how to
also store a repository remotely on GitHub. You can either create a new
repository on GitHub and download (`clone`) it to your computer or
upload (`push`) an existing repository to a new GitHub remote repo. In
both cases you need to create a new repository on GitHub.

To create a new repository on GitHub go to your main GitHub account
webpage and click the `New repository` button. On the next page that
appears, give the repository a name, brief description, and choose
whether to make it public or private. If you want to store an existing
repository on GitHub give it the same name as the one that already
exists on your computer. If you already have files in your local
repository do not check the boxes for creating *README.md*, *LICENSE*,
and *.gitignore* files. When you then click `Create Repository` you will
be directed to the repository's GitHub
webpage.[^chapter_5_32][\[NewGitHubRepo\]]{#NewGitHubRepo label="NewGitHubRepo"}

##### Clone a new remote repository

If you are working with a new repository and do not have an existing
version on your computer you need to "clone" the GitHub repo to your
computer. The repo's GitHub page contains a button called
`Clone in Desktop`. Clicking this will open GUI GitHub (if it is
installed) and prompt you to specify what directory on your computer you
would like to clone the repository into. You can also use the `clone`
command in the shell. Imagine that the URL for a repo called *Example
Project* is `https://GitHub.com/USERNAME/example-project.git`. To clone
it into the */git_epositories* directory
type:[^chapter_5_33][\[GitClone\]]{#GitClone label="GitClone"}

```{r Ch5Clone, eval=FALSE, engine='sh'}
\# Change working directory
cd /git_epositories/

\# Clone example-project git clone
https://GitHub.com/USERNAME/example-project.git
```

##### Push an existing repository to a new GitHub repo {#RemoteAdd}

If you already have a repository with files in it on your computer and
you want to store them remotely in a new GitHub repo, you need to add
the remote repository and `push` your files to it. Type Git's
`remote add` command. For example, if your repository's GitHub URL is
`https://GitHub.com/USERNAME/example-project.git`, then type:

```{r Ch5GitRemoteAdd, eval=FALSE, engine='sh'}
\# Change working
directory to existing local repo cd /git_epositories/example-project

\# Add a remote (GitHub) repository to an existing repo git remote add
origin https://GitHub.com/USERNAME/example-project.git
```

This will tell your local repository where the remote one is. Finally,
push the repository to GitHub:

```{r Ch5GitPushRemote, eval=FALSE, engine='sh'}
\# Push local
repository to GitHub for the first time git push -u origin master
```

The `-u` (upstream tracking) option adds a tracking reference for the
upstream (GitHub) repository branches.

##### Pushing commits to a GitHub repo

Once you have your local repository connected to GitHub you can add new
commits with the `push` command. For example, if your current working
directory is the Git repo you want to push and you have already
added/committed the changes you want to include in the remote repo,
type:

```{r Ch5Push, eval=FALSE, engine='sh'}
\# Add changes to the GitHub
remote master branch git push origin master
```

The `origin` is simply the remotely stored repository on GitHub and
`master` is the master branch. You can change this to another branch if
you'd like. If you have not set up password caching[^chapter_5_34] you will now be
prompted to give your GitHub user name and password.

You can also push your tags to GitHub. To push all of the tags to GitHub
type:

```{r Ch5PushTags, eval=FALSE, engine='sh'}
git push --tags
```

Now on the repo's GitHub page there will be a `Tags` section that will
allow you to view and download the files in each tagged version of the
repository.

### Accessing on GitHub

##### Downloading into R {#GitDownload}

In general, the process of downloading data directly into R is similar
to what we saw earlier for loading data from Dropbox Public folders. We
can simply use the `source\_data` command. First we need to find our
plain-text data file's *raw* URL. To do this, go to your repository's
GitHub site, navigate to the file you want to load, and click the `Raw`
button on the right just above the file
preview.[\[RawGitHub\]]{#RawGitHub label="RawGitHub"} I have data in
comma-separated values format stored in a GitHub repository.[^chapter_5_35] The
URL for the raw (plain-text) version of the data is
<https://raw.githubusercontent.com/christophergandrud/Disproportionality_Data/master/Disproportionality.csv>.[^chapter_5_36]

```{r Ch5URLAddress, message=TRUE, tidy=FALSE}
\# Place shortened url
into URLAddress UrlAddress \<- \"http://bit.ly/14aSjxB\"

\# Download data DispropData \<- repmis::source\_data(UrlAddress)

\# Show variable names names(DispropData)
```

`source\_data` downloaded the most recent version of the file from the
master branch. As we saw in Section
[\[SepHeadExplain\]](#SepHeadExplain){reference-type="ref"
reference="SepHeadExplain"}, running `source\_data` gives us a line
beginning *`## SHA-1 hash of`* .... **Note:** this SHA-1 hash is
different from the file's Git commit's SHA-1 hash we discussed earlier.
The `source\_data` SHA-1 hash is specific to the *file*, and has nothing
to do with Git. We will look at this hash more in Chapter
[\[DataGather\]](#DataGather){reference-type="ref"
reference="DataGather"} (Section
[\[SecureData6\]](#SecureData6){reference-type="ref"
reference="SecureData6"}).

We can actually use `source\_data` to download a particular version of a
file--from a particular Git commit--directly into R. This makes
reproducing a specific result much easier. To do this you just need to
use a file's raw URL from a particular commit. To find a file's
particular commit raw URL first click on the file on GitHub's website.
Then click the `History` button
(![image](Children/Chapter8/images8/GitHistory.png)). This will take you
to a page listing all of the file's versions. Click on the `Browse Code`
button (![image](Children/Chapter5/images5/BrowseCodeIcon.png)) next to
the version of the file that you want to use. Click on the `Raw` button
to be taken to the text-only version of the file. Finally, copy this
page's URL address and use it with `source\_data`.

For example, I have an old version of the disproportionality data. To
download it I find this particular version of the file's URL and use it
in `source\_data`:

```{r Ch5sourceDataOld, tidy=FALSE}
\# Create object containing the
file's URL OldUrlAddress \<-
paste0(\"https://raw.githubusercontent.com/\", \"christophergandrud/\",
\"Disproportionality\_Data/\", \"1a59d360b36eade3b183d6336a\",
\"2262df4f9555d1/\", \"Disproportionality.csv\")

\# Download old disproportionality data DispropOld \<-
repmis::source\_data(OldUrlAddress)
```

In this example I did not shorten the URL, but instead used the `paste0`
function to paste it together.[^chapter_5_37] You do not have to do this. I did it
here so that the URL would fit on the printed page. Notice that the URL
is the same as before with one exception: instead of `master` after
`Disproportionality\_Data` we have this strange series of number and
letters: `1a59d360b36ea` .... This is the *commit's* SHA-1 hash.

As we will see in Chapter
[\[StatsModel\]](#StatsModel){reference-type="ref"
reference="StatsModel"} (Section
[\[sourceurl\]](#sourceurl){reference-type="ref" reference="sourceurl"})
we can use a very similar process to easily run source code files in R
directly downloaded from GitHub with the `source_url` command.

##### Viewing files

The GitHub web user interface also allows you, your collaborators (see
below) or, if the repo is public, anyone to look at text files from a
web browser. Collaborators can actually also create, modify, and commit
changes in the web user interface. This can be useful for making small
changes, especially from a mobile device without a Git installation.
Anyone with a GitHub account can suggest changes to files in a public
repository on the repo's website. Simply click the `Edit` button
(![image](Children/Chapter5/images5/EditIcon.png)) above the file and
make edits. If the person making the edits is not a designated
collaborator, their edits will be sent to the repository's owner for
approval.[^chapter_5_38] This can be a useful way for independent researchers to
fix errors.

#### Collaboration with GitHub

Repositories can have official collaborators that can make changes to
files in the repo. Public repositories can have unlimited collaborators.
Anyone with a GitHub account can be a collaborator. To add a
collaborator to a repository you created, click on the `Settings` button
on the repository's website (see Figure
[1.2](#BookRepository){reference-type="ref"
reference="BookRepository"}). Then click the `Collaborators` button on
the left-hand side of the page. You will be given a box to enter your
collaborator's GitHub user name. If your collaborator doesn't have a
GitHub account, they will have to create a new one. Once you add someone
as a collaborator they can clone the repository onto their computer as
you did earlier and push changes.

##### Syncing a repository

If you and your collaborators are both making changes to the files in a
repo you might create conflicting changes, i.e. different changes to the
same part of a file. To avoid too many conflicts, it is a good idea to
sync your local repository with the remote repository **before** you
push your commits to GitHub. Use the `pull command` to sync your local
and remote repository. First add and commit your changes, then type:

```{r Ch5Pull, eval=FALSE, engine='sh'}
\# Sync repository git pull
```

If the files you are pulling conflict with your local files you will
probably want to resolve these in the individual files and commit the
changes. When there are merge conflicts, Git adds both versions of a
piece of text to the file. You then open the file and decide which
version to keep and which one to delete. When the conflicts are resolved
and changes committed, push your merged changes up to the remote
repository as we did before.

### Summing up the GitHub workflow

We've covered a lot of ground in this section. Let's sum up the basic
GitHub workflow you will probably follow once your repo is set up.

1.  Add any changes you've made with `git add`.

2.  `commit` the changes.

3.  `pull` your collaborators' changes from the GitHub repo, resolve any
    merge conflicts, and `commit` the changes.

4.  `push` your changes to GitHub.

![Creating RStudio
Projects[]{label="NewRStudioProject"}](Children/Chapter5/images5/GitNewProject.png){#NewRStudioProject}

![Creating RStudio Projects in New
Directories[]{label="NewProjectNewDirectory"}](Children/Chapter5/images5/NewProject_NewDirectory.png){#NewProjectNewDirectory}

RStudio & GitHub
----------------

When you open a Project with a Git repository in RStudio you will see a
new *Git* tab next to *Environment* and *History* (see Figure
[\[GitTab\]](#GitTab){reference-type="ref" reference="GitTab"}). From
here you can do many of the things we covered in the previous section.
Let's look at how to set up and use Git in RStudio Projects.

### Setting up Git/GitHub with Projects

You can Git initialize new RStudio Projects, Git initialize existing
projects, and create RStudio Projects from cloned repos. When you do any
of these things RStudio automatically adds a *.gitignore* file telling
Git to ignore *.Rproj.user*, *.Rhistory*, and *.RData* files.

##### Git with a new project {#NewProjectGit}

To create a new project with Git version control, go to `File` in the
RStudio menu bar. Then click `New Project…`. In the box that appears
(see Figure [1.4](#NewRStudioProject){reference-type="ref"
reference="NewRStudioProject"}) select `New Directory` `Empty Project`.
Enter the Project's name and desired directory. Make sure to check the
dialog box for `Create a git repository` (see Figure
[1.5](#NewProjectNewDirectory){reference-type="ref"
reference="NewProjectNewDirectory"}).

##### Git initialize existing projects

If you have an existing RStudio Project and want to add Git version
control to it, first go to `Tools` in the RStudio menu bar. Then select
`Project Options …`. Select the `Git/SVN` icon. Finally, select `Git`
from the drop-down menu for `Version Control System:`.

##### Clone repository into a new project

Again go to `File` in the RStudio menu bar to create a new project from
a cloned GitHub repository. Then click `New Project…`. Select the
`Version Control` option and then `Git`. Finally, paste the repository's
URL in the field called `Repository URL:`, enter the directory you would
like to locate the cloned repo in, and click `Create Project`.

##### Add existing Project repository to GitHub

You can push an existing Project repository stored on your computer to a
new remote repository on GitHub. To do this, first create a new repo on
GitHub with the same name as your RStudio Project (see Section
[\[NewGitHubRepo\]](#NewGitHubRepo){reference-type="ref"
reference="NewGitHubRepo"}). Then copy the remote repository's URL like
we saw before when we cloned a repository from GitHub (see Section
[\[GitClone\]](#GitClone){reference-type="ref" reference="GitClone"}).
Open a new shell from within RStudio. To do this, click the `Shell`
button in the *Git* tab's `More` drop-down menu. Now follow the same
steps that we used in Section
[1.3.3.0.2](#RemoteAdd){reference-type="ref" reference="RemoteAdd"} to
connect a locally stored repository to GitHub for the first time.

![Adding Changes to the
Repository[]{label="fig:AddingChangesToRepo"}](Children/Chapter5/images5/GitTab.png){#fig:AddingChangesToRepo}

![Adding Changes to the
Repository[]{label="fig:AddingChangesToRepo"}](Children/Chapter5/images5/GitAdd.png){#fig:AddingChangesToRepo}

### Using Git in RStudio Projects

The RStudio *Git* tab allows you to do many of the same things with Git
that we covered in the previous section. In the top panel of Figure
[\[GitTab\]](#GitTab){reference-type="ref" reference="GitTab"} you will
see the *Git* tab for a new RStudio Project called *example-project*. It
has two files that have not been added or committed to Git. To add and
commit the files to the repository, click on the dialog boxes next to
the file names. In the bottom panel of Figure
[\[GitTab\]](#GitTab){reference-type="ref" reference="GitTab"} you can
see that I've created a new R file called *ExampleScript.R* and clicked
the dialog box next to it, along with the other files. The yellow
question marks in the top panel have now become green A's for "add".
Clicking `Commit` opens a new window called **Review Changes** where you
can commit the changes. Simply write a commit message in the box called
*Commit Message* in the **Review Changes** window and click `Commit`. If
you add file names to the *.gitignore* files, they will not show up in
RStudio's *Git* tab.

If you are using a GitHub repo that is associated with a remote
repository on GitHub, you can push and pull it with the `Pull Branches`
and `Push Branch` buttons in Git menu bar (the blue and green arrows,
respectively). You can use the same buttons in the **Review Changes**
window. The *Git* tab also allows you to change branches, revert to
previous commits, add files to `.gitignore`, and view your commit
history. You can always use the `More Shell …` option to open a new
shell with the Project set as the working directory to complete any
other Git task you might want to do.

### Chapter summary {#chapter-summary .unnumbered}

In this chapter we have primarily learned how to store text-based
reproducible research files in ways that allow us and others to access
them easily from many locations, enable collaboration, and keep a record
of previous versions. In the next chapter we will learn how to use
text-based files to reproducibly gather data that we can use in our
statistical analyses.

[^chapter_5_1]: These services store your data on remote servers.

[^chapter_5_2]: I don't cover methods for storing and handling very large data
    sets--with high hundreds of thousands and more observations. For
    information on large data and R, not just storage, one place to look
    is this blog post from RDataMining:
    <http://rdatamining.wordpress.com/2012/05/06/online-resources-for-handling-big-data-and-parallel-computing-in-r/>
    (posted 6 May 2012). One popular service for large file storage is
    Amazon S3 (<http://aws.amazon.com/s3/>). I haven't used this service
    and can't suggest ways to integrate it with R.

[^chapter_5_3]: Sometimes this format is called tab-delimited values.

[^chapter_5_4]: Frequently the row names are just the row numbers which may have
    no substantive meaning.

[^chapter_5_5]: `write.csv` is a 'wrapper' for *write.table*.

[^chapter_5_6]: Dropbox provides a minimum amount of storage for free, above which
    they charge a fee. GitHub lets you create publicly accessible
    repositories--kind of like project folders--for free, but they
    charge for private repositories.

[^chapter_5_7]: <https://zenodo.org/>

[^chapter_5_8]: <http://thedata.org/>

[^chapter_5_9]: <http://figshare.com/>

[^chapter_5_10]: <http://www.runmycode.org/>

[^chapter_5_11]: <http://www.dropbox.com/>

[^chapter_5_12]: <https://drive.google.com/>

[^chapter_5_13]: See <https://www.dropbox.com/downloading> for downloading and
    installation instructions.

[^chapter_5_14]: Note: if you created your Dropbox account after 4 October 2012
    you will not automatically have a *Public* folder. To enable the
    folder on your account see this website:
    <https://www.dropbox.com/help/16/en>. You will need a Pro or Dropbox
    for Business account to enable a new Public folder.

[^chapter_5_15]: This data is from [@Gandrud2012]. I've shortened the URL using
    Bitly (<https://bitly.com/>) so that it will fit on the page.

[^chapter_5_16]: For more details see: <https://www.dropbox.com/en/help/11>.

[^chapter_5_17]: I used Git version 1.7.9.6 for this book.

[^chapter_5_18]: Because many of these features apply to any service that relies
    on Git, much of this list of advantages also applies to alternative
    Git cloud storage services such as Bitbucket
    (<https://bitbucket.org/>).

[^chapter_5_19]: You can use a variety of other markup languages as well. See
    <https://GitHub.com/GitHub/markup>.

[^chapter_5_20]: RStudio also supports the Subversion version control system, but
    I don't cover that here.

[^chapter_5_21]: The interface for Git Bash looks a lot like the Terminal or
    Windows PowerShell.

[^chapter_5_22]: Much of the discussion of the command-line in this section is
    inspired by Nick Farina's blog post on Git (see
    <http://nfarina.com/post/9868516270/git-is-simpler>, posted 7
    September 2012).

[^chapter_5_23]: To follow along with this code you will first need to create a
    folder called *git_epositories* in your root directory. Note also
    that throughout this section I use Unix file path conventions.

[^chapter_5_24]: For a comprehensive guide to Git commands, see
    <http://git-scm.com/>.

[^chapter_5_25]: Other Git objects include trees (sort of like directories), tags
    (bookmarks for important points in a repo's history), and blobs
    (individual files).

[^chapter_5_26]: You can also search your commit history and roll back to a
    previous commit using only the command-line. To see the commit
    history use the `log` command (more details at
    <http://git-scm.com/book/en/Git-Basics-Viewing-the-Commit-History>).
    When a repo has many commits, this can be a very tedious command to
    use, so I highly recommend the GUI version of GitHub or the repo's
    GitHub website.

[^chapter_5_27]: Secure Hash Algorithm

[^chapter_5_28]: If you don't, then the new branch will have a "detached head"
    which will create problems using the branch in the future.

[^chapter_5_29]: To delete the *Test* branch use the `-d` argument, i.e.
    `git branch -d Test`.

[^chapter_5_30]: Any uncommitted changes are merged with a branch when it is
    checked out.

[^chapter_5_31]: Note that like *.git*, *.gitignore* files are hidden.

[^chapter_5_32]: Before the repo has any files in it, the webpage will include
    instructions for how to set it up on your computer.

[^chapter_5_33]: If you are on the repo's webpage the URL to copy is under
    `HTTPS clone URL`.

[^chapter_5_34]: See <https://help.GitHub.com/articles/set-up-git> for more
    details.

[^chapter_5_35]: For full information about the disproportionality data set,
    please see
    <http://christophergandrud.github.io/Disproportionality_Data/>.

[^chapter_5_36]: It has been shortened with Bitly in the example.

[^chapter_5_37]: `paste0` is the same as `paste`, but has the argument `sep = ""`
    so that white space is not placed between the pasted elements.

[^chapter_5_38]: This is called a `pull` request in Git terminology. See the next
    section for more details.

<!--chapter:end:07-storage.Rmd-->

# About the Author {-}

Christopher Gandrud is Head of Platform Steering Zalando SE building where he leads teams building and evaluating large scale automated decision-making systems. He was previously a research fellow at the Institute for Quantitative Social Science, Harvard University developing statistical software and applications for the social and physical sciences. He has also held posts at City, University of London, the Hertie School of Governance, Yonsei University, and the London School of Economics where in 2012 he completed a PhD in quantitative political science. 

<!--chapter:end:98-author.Rmd-->

`r if (knitr:::is_html_output()) '# References {-}'`

```{r include=FALSE}
# Additional packages to cite
pkg_additional <- c(
    .packages(),
    "bookdown", "formatR", "IRkernel", "pacman", "RCurl", 
    "styler", "tinytex", "xml"
)

# Check if the packages are installed, if not install
lapply(pkg_additional,
    function(pkg) {
        if (system.file(package = pkg) == "")
            install.packages(pkg,
                repos = "http://cran.us.r-project.org")
})

# pkg_to_install is created in 00-setup.Rmd
pkg_to_cite <- c(pkg_to_install, pkg_additional)

# generate a BibTeX database automatically for some R packages
knitr::write_bib(pkg_to_cite, 'packages.bib')
```

<!--chapter:end:99-references.Rmd-->

