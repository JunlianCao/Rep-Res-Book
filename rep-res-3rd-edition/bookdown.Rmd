---
title: "Reproducible Research with R and RStudio (Third Edition)"
author: "Christopher Gandrud"
date: "`r Sys.Date()`"
documentclass: krantz
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
colorlinks: yes
lot: yes
lof: yes
site: bookdown::bookdown_site
chapter_name: "Chapter "
description: "Reproducible Research with R and RStudio, Third Edition brings together the skills and tools needed for doing and presenting computational research. Using straightforward examples, the book takyes you through an entire reproducible research workflow. This practical workflow enables you to gather and analyze data as well as dynamically present results in print and on the web."
github-repo: christophergandrud/Rep-Res-Book
graphics: yes
#cover-image: images/cover.jpg
---

```{r setup, include=FALSE}
options(
  htmltools.dir.version = FALSE, formatR.indent = 2, width = 55, digits = 4
)
```

# Preface {-}

## My motivation {-}

This book has its genesis in my PhD research at the London School of Economics. I started the degree with questions about the 2008/09 financial crisis and planned to spend most of my time researching capital adequacy requirements. But I quickly realized that I would actually spend a large proportion of my time learning the day-to-day tasks of data gathering, analysis, and results presentation. After plodding through for a while with Word, Excel, and Stata, my breaking point came while reentering results into a regression table after I had tweaked one of my statistical models, yet again. Surely there was a better way to *do* research that would allow me to spend more time answering my research questions. Making research reproducible for others also means making it better organized and efficient for yourself. My search for a better way led me straight to the tools for reproducible computational research.

The reproducible research community is very active, knowledgeable, and helpful. Nonetheless, I often encountered holes in this collective knowledge, or at least had no resource organize it all together as a whole. That is my intention for this book: to bring together the skills I have picked up for actually doing and presenting computational research. Hopefully, the book, along with making reproducible research more widely used, will save researchers hours of googling, so they can spend more time addressing their research questions.

## Changes to the Third Edition {-}

**To WRITE**

-   The book is created using *bookdown* [@R-bookdown], a format that builds on *rmarkdown* to compile books into many different formats.

## Changes to the Second Edition {-}

The tools of reproducible research have developed rapidly since the first edition of this book was published just two years ago. The second edition has been updated to incorporate the most important of these advancements, including discussions of:

-   The *rmarkdown* package, which allows you to create reproducible research documents in PDF, HTML, and Microsoft Word formats using the simple and intuitive Markdown syntax.

-   Improvements and changes to RStudio's interface and capabilities, such as its new tools for handling R Markdown documents.

-   Expanded *knitr* R code chunk capabilities.

-   The `kable()` function in the *knitr* package and the *texreg* package for dynamically creating tables to present your data and statistical results.

-   An improved discussion of file organization allowing you to take full advantage of relative file paths so that your documents are more easily reproducible across computers and systems.

-   The *dplyr*, *magrittr*, and *tidyr* packages for fast data manipulation.

-   Numerous changes to R syntax in user-created packages.

-   Changes to GitHub's and Dropbox's interfaces.

## Acknowledgments {-}

I would not have been able to write this book without many people's advice and support. Foremost is John Kimmel, acquisitions editor at Chapman and Hall. He approached me in Spring 2012 with the general idea and opportunity for this book. Other editors at Chapman and Hall and Taylor and Francis have greatly contributed to this project, including Marcus Fontaine. I would also like to thank all of the book's reviewers whose helpful comments have greatly improved it. The first edition's reviewers include:

-   Jeromy Anglim, Deakin University
-   Karl Broman, University of Wisconsin, Madison
-   Jake Bowers, University of Illinois, Urbana-Champaign
-   Corey Chivers, McGill University
-   Mark M. Fredrickson, University of Illinois, Urbana-Champaign
-   Benjamin Lauderdale, London School of Economics
-   Ramnath Vaidyanathan, McGill University

and there have been many other annonymous reviewers who have provided great feedback over the years.

The developer and blogging community has also been incredibly important for making this book possible. Foremost among these people is Yihui Xie. He is the main developer behind the *knitr* package, co-developer of *rmarkdown*, and also an avid blog writer and commenter. Without him the ability to do reproducible research would be much harder and the blogging community that spreads knowledge about how to do these things would be poorer. Other great contributors to the reproducible research community include Carl Boettiger, Karl Broman, Markus Gesmann (who developed *googleVis*), Rob Hyndman, and Hadley Wickham (who has developed numerous very useful R packages). Thank you also to Victoria Stodden and Michael Malecki for helpful suggestions. And, of course, thank you to everyone at RStudio (especially JJ Allaire) for creating an increasingly useful program for reproducible research.

The second edition has benefited immensely from first edition readers' comments and suggestions. For a list of their valuable contributions, please see the book's GitHub Issues page <https://GitHub.com/christophergandrud/Rep-Res-Book/issues> and the first edition's Errata page <http://christophergandrud.GitHub.io/RepResR-RStudio/errata.htm>.

My students at Yonsei University were an important part of making the first edition. One of the reasons that I got interested in using many of the tools covered in this book, like using **knitr} in slideshows, was to improve a course I taught there: Introduction to Social Science Data Analysis. I tested many of the explanations and examples in this book on my students. Their feedback has been very helpful for making the book clearer and more useful. Their experience with using these tools on Microsoft Windows computers was also important for improving the book's Windows documentation. Similarly, my students at the Hertie School of Governance inspired and tested key sections of the second edition.

The vibrant community at Stack Overflow <http://stackoverflow.com/> and Stack Exchange <http://stackexchange.com/> are always very helpful for finding answers to problems that plague any computational researcher. Importantly, the sites make it easy for others to find the answers to questions that have already been asked.

Kristina Gandrud, has been immensely supportive and patient with me throughout the writing of this book (and pretty much my entire academic career). Certainly this is not the proper forum for musing about marital relations, but I'll do a musing anyways. Having a person who supports your interests, even if they don't completely share them, is immensely helpful for a researcher. It keeps you going.

<!--chapter:end:index.Rmd-->

# Stylistic Convensions {-}

I use the following conventions throughout this book:

-   **Abstract variables**: Abstract variables, i.e. variables that do not
represent specific objects in an example, are in `ALL CAPS TYPEWRITER TEXT`.

-   **Clickable buttons**: Clickable Buttons are in `typewriter text`.

-   **Code**: All code is in `typewriter text`.

-   **Filenames and directories**: Filenames and directories more generally are
printed in *italics*. I use CamelBack for file and directory names.

-   **File extensions**: Like filenames, file extensions are *italicized*.

-   **Individual variable values**: Individual variable values mentioned in the
text are in *italics*.

-   **Objects**: Objects are printed in *italics*. I use CamelBack for object names.

-   **Object columns**: Data frame object columns are printed in *italics*.

-   **Function names** are followed by parentheses (e.g., `stats::lm()`)

-   **Packages**: **R** packages are printed in *italics*.

-   **Windows and RStudio panes**: Open windows and RStudio panes are written in
*italics*.

-   **Variable names**: Variable names are printed in **bold**. I use CamelBack
for individual variable names.

<!--chapter:end:01-stylistic-convensions.Rmd-->

# Additional Resources {-}

Additional resources that supplement the examples in this book can be freely downloaded and experimented with. These resources include longer examples discussed in individual chapters and a complete short reproducible research project.

## Chapter Examples {-}

Longer examples discussed in individual chapters, including files to dynamically download data, code for creating figures, and markup files for creating presentation documents, can be accessed at: <https://github.com/christophergandrud/Rep-Res-Examples>. Please see Chapter \@ref(Storing) for more information on downloading files from GitHub, where the examples are stored.\index{GitHub}

## Short Example Project {-}

To download a full (though very short) example of a reproducible research project created using the tools covered in this book go to: <https://github.com/christophergandrud/Rep-Res-ExampleProject1>. Please follow the replication instructions in the main *README.md* file to fully replicate the project. It is probably a good idea to hold off looking at this complete example in detail until after you have become acquainted with the individual tools it uses. Become acquainted with the tools by reading through this book and working with the individual chapter examples.

The following two figures give you a sense of how the example's files are organized. Figure \@ref(fig:ExampProjeFiles) shows how the files are organized in the file system. Figure \@ref(fig:ExampProjDiagram) illustrates how the main files are dynamically tied together. In the *Data* directory we have files to gather raw data from the [@worldbank2013] on fertilizer consumption and from [@pemstein2010] on countries' levels of democracy. They are tied to the data through the `WDI()`\index{WDI()} and `download.file()` functions.\index{R function!download.file()} A *Makefile*\index{Makefile} can run *Gather1.R* and *Gather2.R* to gather and clean the data. It runs *MergeData.R* to merge the data into one data file called *MainData.csv*. It also automatically generates a variable description file and a *README.md*\index{README file} recording the session info.\index{R!session info}

The *Analysis* folder contains two files that create figures presenting this data. They are tied to *MainData.csv* with the `read.csv()` function.\index{R function!read.csv} These files are run by the presentation documents when they are knitted. The presentation documents tie to the analysis documents with *knitr* and the `source()` function.\index{R function!source()}

Though a simple example, hopefully these files will give you a complete sense of how a reproducible research project can be organized. Please feel free to experiment with different ways of organizing the files and tying them together to make your research really reproducible.

```{r ExampProjeFiles, engine = "tikz", fig.cap = "Short Example Project File Tree", cache=TRUE, echo=FALSE, fig.ext=if (knitr:::is_latex_output()) 'pdf' else 'png'}
\usetikzlibrary{trees}

% Set node styles
\tikzstyle{DirBox} = [draw=black,
                      rectangle,
                      minimum width=5em,
                      very thick,
                      font=\small]

\tikzstyle{every node} = [draw=gray,
                          thin,
                          anchor=west,
                          font=\small]

% Begin tikz picture
\begin{tikzpicture}[%
  grow via three points={one child at (0.5,-0.7) and
  two children at (0.5,-0.7) and (0.5,-1.4)},
  edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}]
  % Root Directory
  \node (root) at (5, 10) [DirBox]{Root};

  % Project Directory
  \node (project) at (4, 8.5) [DirBox]{Rep-Res-ExampleProject1}
        child {node {{\small{Paper.Rnw}}}}
        child {node {{\small{Slideshow.Rnw}}}}
        child {node {{\small{Website.Rnw}}}}
        child {node {{\small{Main.bib}}}}
            ;

  % Data Directory
  \node (data) at (0, 4.5) [DirBox]{Data}
      child {node {{\small{MainData.csv}}}}
      child {node {{\small{Makefile}}}}
      child {node {{\small{MergeData.R}}}}
      child {node {{\small{Gather1.R}}}}
      child {node {{\small{Gather2.R}}}}
      child {node {{\small{MainData\_VariableDescriptions.md}}}}
      child {node {{\small{README.Rmd}}}}
        ;

  % Analysis subdirectores/files
  \node (analysis) at (1.5, 7) [DirBox]{Analysis}
      child {node {{\small{GoogleVisMap.R}}}}
      child {node {{\small{ScatterUDSFert.R}}}}
        ;

  % README file
  \node (readme) at (9.5, 7) {README.md};

  % Connect boxes that are not explicit children
  \draw (root) -- (project);
  \draw (project) -| (analysis);
  \draw (analysis) -| (data);
  \draw (project) -| (readme);

\end{tikzpicture}
```

```{r ExampProjDiagram, engine = "tikz", fig.cap = "Short Example Main File Ties", cache=TRUE, echo=FALSE, fig.ext=if (knitr:::is_latex_output()) 'pdf' else 'png'}
\usetikzlibrary{trees}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{shapes,arrows}

\definecolor{Blue}{HTML}{7BCCC4}
\definecolor{LiteBlue}{HTML}{A8DDB5}
\definecolor{DarkBlue}{HTML}{08589E}

\definecolor{GrayLine}{HTML}{BDBDBD}

% Set node styles
%% File nodes
\tikzstyle{File} = [draw=Blue,
                    rectangle,
                    text width=6.3em,
                    font=\scriptsize]

% Raw Data nodes
\tikzstyle{RawData} = [draw=LiteBlue,
                       %fill=LiteBlue,
                       decorate,
                       decoration={random steps,
                                   segment length=2pt,
                                   amplitude=2pt},
                       inner sep=0.25cm,
                       font=\scriptsize]

% Separator line style
\tikzstyle{sepline} = [draw,
                        very thick,
                        color=GrayLine]

% Link command nodes
\tikzstyle{Links} = [draw=none,
                          text width=6em,
                          text=DarkBlue,
                          font=\small]

% Begin tikz picture
\begin{tikzpicture}

    % Nodes
    \node (Data1) at (-3.5, 7) [RawData]{Raw WDI Data};
    \node (Gather1) at (-3, 6) [File]{Gather1.R};

    \node (Data2) at (-3.5, 5) [RawData]{Raw UDS Data};
    \node (Gather2) at (-3, 4) [File]{Gather2.R};

    \node (MergeData) at (0.5, 5) [File]{Makefile \\ MergeData.R};
    \node (DataFile) at (0.5, 4) [File]{MainData.csv};

    \node (Scatter) at (3.8, 4.5) [File]{ScatterUDSFert.R};
    \node (GoogleVis) at (3.8, 3.5) [File]{GoogleVisMap.R};

    \node (ArticleK) at (7, 5) [File]{Article.Rnw};
    \node (SlideshowK) at (7, 4) [File]{Slideshow.Rnw};
    \node (WebsiteK) at (7, 3) [File]{Website.Rmd};

    \node (Article) at (10, 5) [File]{Article.pdf};
    \node (Slideshow) at (10, 4) [File]{Slideshow.pdf};
    \node (Website) at (10, 3) [File]{Website.html};

    % Lines
    \draw [->] (Data1) -- (Gather1);
    \draw [->] (Data2) -- (Gather2);
    \draw [->] (Gather1) -- (MergeData);
    \draw [->] (Gather2) -- (MergeData);
    \draw [->] (MergeData) -- (DataFile);

    \draw [->] (DataFile) -- (Scatter);
    \draw [->] (DataFile) -- (GoogleVis);

    \draw [->] (Scatter) -- (ArticleK);
    \draw [->] (Scatter) -- (SlideshowK);
    \draw [->] (GoogleVis) -- (WebsiteK);

    \draw [->] (ArticleK) -- (Article);
    \draw [->] (SlideshowK) -- (Slideshow);
    \draw [->] (WebsiteK) -- (Website);


    \path [sepline] (-3.5, 0.75) -- (11, 0.75);

    % Link command nodes

    \node (importData) at (-1, -1) [Links]{\texttt{download.file()} \\ \texttt{Make} \\ \texttt{merge()}\\ \texttt{WDI()} };

    \node (Figs) at (3, -1) [Links]{\texttt{read.csv()}};

    \node (knitr) at (7.5, -1) [Links]{ {\emph{knitr}} \\ \texttt{source()}};

\end{tikzpicture}
```

## Updates {-}

Many of the reproducible research tools discussed in this book are improving rapidly. Because of this, I will regularly post updates to the content covered in the book at: <https://github.com/christophergandrud/Rep-Res-Book>.

## Corrections {-}

If you notice any corrections that should be made to fix typos, broken URLs, and so on, you can report them at: <https://github.com/christophergandrud/Rep-Res-Book/issues>. I'll post notifications of changes to an Errata page at: <http://christophergandrud.GitHub.io/RepResR-RStudio/errata.htm>.

<!--chapter:end:02-additional_resources.Rmd-->

\mainmatter

# (PART) Getting Started {-}

# Introducing Reproducible Research{#Intro}

Research is often presented in very selective containers: slideshows,
journal articles, books, or maybe even websites. These presentation
documents announce a project's findings and try to convince us that the
results are correct [@mesirov2010]. It's important to remember that
these documents are not the research. Especially in the computational
and statistical sciences, these documents are the "advertising". The
research is the "full software environment, code, and data that produced
the results" [@buckheit1995; @donoho2010 385]. When we separate the
research from its advertisement we are making it difficult for others to
verify the findings by reproducing them.

This book gives you the tools to dynamically combine your research with
the presentation of your findings. The first tool is a workflow for
reproducible research that weaves the principles of reproducibility
throughout your entire research project, from data gathering to the
statistical analysis, and the presentation of results. You will also
learn how to use a number of computer tools that make this workflow
possible. These tools include:

-   the **R** statistical language that will allow you to gather data
    and analyze it;

-   the **LaTeX** and **Markdown** markup languages that you can use to
    create documents--slideshows, articles, books, and webpages--for
    presenting your findings;

-   the *knitr* and *rmarkdown* **packages** for R and other tools,
    including **command-line programs** like GNU Make and Git
    version control, for dynamically tying your data gathering,
    analysis, and presentation documents together so that they can be
    easily reproduced;

-   **RStudio**, a program that brings all of these tools together in
    one place.

## What Is Reproducible Research?

Though there is some debate over what are the necessary and sufficient
conditions for a replication [@makel2014 2], research results are
generally considered[^chapter1_1_1] *replicable* if there is sufficient information
available for independent researchers to make the same findings using
the same procedures with new data.[^chapter1_1] For research that relies on
experiments, this can mean a researcher not involved in the original
research being able to rerun the experiment, including sampling, and
validate that the new results are comparable to the original ones. In
computational and quantitative empirical sciences, results are
replicable if independent researchers can recreate findings by following
the procedures originally used to gather the data and run the computer
code. Of course, it is sometimes difficult to replicate the original
data set because of issues such as limited resources to gather new data
or because the original study already sampled the full universe of
cases. So as a next-best standard we can aim for "*really reproducible
research*" [@peng2011 1226].[^chapter1_2] In computational sciences[^chapter1_3]
this means:

> the data and code used to make a finding are available and they are sufficient for an independent researcher to recreate the finding.

In practice, research needs to be *easy* for independent researchers to
reproduce [@ball2012]. If a study is difficult to reproduce it's more
likely that no one will reproduce it. If someone does attempt to
reproduce this research, it will be difficult for them to tell if any
errors they find were in the original research or problems they
introduced during the reproduction. In this book you will learn how to
avoid these problems.

In particular you will learn tools for dynamically "*knitting*"[^chapter1_4] the
data and the source code together with your presentation documents.
Combined with well-organized source files and clearly and completely
commented code, independent researchers will be able to understand how
you obtained your results. This will make your computational research
easily reproducible.

## Why Should Research Be Reproducible?

Reproducible research is one of the main components of science. If
that's not enough reason for you to make your research reproducible,
consider that the tools of reproducible research also have direct
benefits for you as a researcher.

### For science

Replicability has been a key part of scientific inquiry from perhaps the
1200s [@bacon1267; @nosek2012]. It has even been called the "demarcation
between science and non-science" [@braude1979 2]. Why is replication so
important for scientific inquiry?

#### Standard to judge scientific claims {-}

*Replication* opens claims to scrutiny, allowing us to keep what works
and discard what doesn't. Science, according to the American Physical
Society, "is the systematic enterprise of gathering knowledge
...organizing and condensing that knowledge into testable laws and
theories". The "ultimate standard" for evaluating scientific claims is
whether or not the claims can be replicated [@peng2011; @kelly2006].
Research findings cannot even really be considered "genuine
contributions to human knowledge" until they have been verified
through replication [@stodden2009 38]. Replication "requires the
complete and open exchange of data, procedures, and materials".
Scientific conclusions that are not replicable should be abandoned or
modified "when confronted with more complete or reliable
...evidence".[^chapter1_5]

*Reproducibility enhances replicability*. If other researchers are able
to clearly understand how a finding was originally made, then they will
be better able to conduct comparable research in meaningful attempts to
replicate the original findings. Sometimes strict replicability is not
feasible, for example, when it is only possible to gather one data set
on a population of interest. In these cases reproducibility is a
"minimum standard" for judging scientific claims [@peng2011].

It is important to note that though reproducibility is a minimum
standard for judging scientific claims, "a study can be reproducible and
still be wrong" [@peng2014]. For example, a statistically significant
finding in one study may remain statistically significant when
reproduced using the original data/code, but when researchers try to
replicate it using new data and even methods, they are unable to find a
similar result. The original finding could simply have been noise, even
though it is fully reproducible.

#### Avoiding effort duplication & encouraging cumulative knowledge development {-}

Not only is reproducibility important for evaluating scientific claims,
it can also contribute to the cumulative growth of scientific knowledge
[@kelly2006; @king1995]. Reproducible research cuts down on the amount
of time scientists have to spend gathering data or developing procedures
that have already been collected or figured out. Because researchers do
not have to discover on their own things that have already been done,
they can more quickly build on established findings and develop new
knowledge.

### For you

Working to make your research reproducible does require extra upfront
effort. For example, you need to put effort into learning the tools of
reproducible research by doing things such as reading this book. But
beyond the clear benefits for science, why should you make this effort?
Using reproducible research tools can make your research process more
effective and (hopefully) ultimately easier.

#### Better work habits {-}

Making a project reproducible from the start encourages you to use
better work habits. It can spur you to more effectively plan and
organize your research. It should push you to bring your data and source
code up to a higher level of quality than you might if you "thought 'no
one was looking'" [@donoho2010 386]. This forces you to root out
errors--a ubiquitous part of computational research--earlier in the
research process [@donoho2010 385]. Clear documentation also makes it
easier to find errors.[^chapter1_6]

Reproducible research needs to be stored so that other researchers can
actually access the data and source code. By taking steps to make your
research accessible for others you are also making it easier for
yourself to find your data and methods when you revise your work or
begin new a project. You are avoiding personal effort duplication,
allowing you to cumulatively build on your own work more effectively.

#### Better teamwork {-}

The steps you take to make sure an independent researcher can figure out
what you have done also make it easier for your collaborators to
understand your work and build on it. This applies not only to current
collaborators, but also future collaborators. Bringing new members of a
research team up to speed on a cumulatively growing research project is
faster if they can easily understand what has been done already
[@donoho2010 386].

#### Changes are easier {-}

A third person may or may not actually reproduce your research even if
you make it easy for them to do so. But, *you will almost certainly
reproduce parts or even all of your own research*. No actual research
process is completely linear. You almost never gather data, run
analyses, and present your results without going backwards to add
variables, make changes to your statistical models, create new graphs,
alter results tables in light of new findings, and so on. You will
probably try to make these changes long after you last worked on the
project and long since you remembered the details of how you did it.
Whether your changes are because of journal reviewers' and conference
participants' comments or you discover that new and better data has been
made available since beginning the project, designing your research to
be reproducible from the start makes it much easier to change things
later on.

Dynamic reproducible documents in particular can make changing things
much easier. Changes made to one part of a research project have a way
of cascading through the other parts. For example, adding a new variable
to a largely completed analysis requires gathering new data and merging
it with existing data sets. If you used data imputation or matching
methods you may need to rerun these models. You then have to update your
main statistical analyses, and recreate the tables and graphs you used
to present the results. Adding a new variable essentially forces you to
reproduce large portions of your research. If when you started the
project you used tools that make it easier for others to reproduce your
research, you also made it easier to reproduce the work yourself. You
will have taken steps to have a "better relationship with your
future self" [@bowers2011 2].

#### Higher research impact {-}

Reproducible research is more likely to be useful for other researchers
than non-reproducible research. Useful research is cited more frequently
[@donoho2002; @piwowar2007; @vandewalle2012]. Research that is fully
reproducible contains more information, i.e. more reasons to use and
cite it, than presentation documents merely showing findings.
Independent researchers may use the reproducible data or code to look at
other, often unanticipated, questions. When they use your work for a new
purpose they will (should) cite your work. Because of this, Vandewalle
et al. even argue that "the goal of reproducible research is to have
more impact with our research" [-@vandewalle2007 1253].

A reason researchers often avoid making their research fully
reproducible is that they are afraid other people will use their data
and code to compete with them. I'll let Donoho et al. address this one:

> *True. But competition means that strangers will read your papers, try
> to learn from them, cite them, and try to do even better. If you
> prefer obscurity, why are you publishing?* [-@donoho2009 16]

## Who Should Read This Book?

This book is intended primarily for researchers who want to use a
systematic workflow that encourages reproducibility as well as practical
state-of-the-art computational tools to put this workflow into practice.
These people include professional researchers, upper-level
undergraduate, and graduate students working on computational
data-driven projects. Hopefully, editors at academic publishers will
also find the book useful for improving their ability to evaluate and
edit reproducible research.

The more researchers that use the tools of reproducibility the better.
So I include enough information in the book for people who have very
limited experience with these tools, including limited experience with
R, LaTeX, and Markdown. They will be able to start incorporating
reproducible research tools into their workflow right away. The book
will also be helpful for people who already have general experience
using technologies such as R and LaTeX, but would like to know how to
tie them together for reproducible research.

### Academic researchers

Hopefully so far in this chapter I've convinced you that reproducible
research has benefits for you as a member of the scientific community
and personally as a computational researcher. This book is intended to
be a practical guide for how to actually make your research
reproducible. Even if you already use tools such as R and LaTeX you may
not be leveraging their full potential. This book will teach you useful
ways to get the most out of them as part of a reproducible research
workflow.

### Students

Upper-level undergraduate and graduate students conducting original
computational research should make their research reproducible for the
same reasons that professional researchers should. Forcing yourself to
clearly document the steps you took will also encourage you to think
more clearly about what you are doing and reinforce what you are
learning. It will hopefully give you a greater appreciation of research
accountability and integrity early in your career [@barr2012; @ball2012
183].

Even if you don't have extensive experience with computer languages,
this book will teach you specific habits and tools that you can use
throughout your student research and hopefully your careers. Learning
these things earlier will save you considerable time and effort later.

### Instructors

When instructors incorporate the tools of reproducible research into
their assignments they not only build students' understanding of
research best practice, but are also better able to evaluate and provide
meaningful feedback on students' work [@ball2012 183]. This book
provides a resource that you can use with students to put
reproducibility into practice.

If you are teaching computational courses, you may also benefit from
making your lecture material dynamically reproducible. Your slides will
be easier to update for the same reasons that it is easier to update
research. Making the methods you used to create the material available
to students will give them more information. Clearly documenting how you
created lecture material can also pass information on to future
instructors.

### Editors

Beyond a lack of reproducible research skills among researchers, an
impediment to actually creating reproducible research is a lack of
infrastructure to publish it [@peng2011]. Hopefully, this book will be
useful for editors at academic publishers who want to be better at
evaluating reproducible research, editing it, and developing systems to
make it more widely available. The journal *Biostatistics* is a good
example of a publication that is encouraging (actually requiring)
reproducible research. From 2009 the journal has had an editor for
reproducibility that ensures replication files are available and that
results can be replicated using these files [@peng2009]. The more
editors there are with the skills to work with reproducible research the
more likely it is that researchers will do it.

### Private sector researchers

Researchers in the private sector may or may not want to make their work
easily reproducible outside of their organization. However, that does
not mean that significant benefits cannot be gained from using the
methods of reproducible research.

Even if a company has only one person doing research, they benefit from using reproducible research methods. Just with academic research this person actually does have a collaborator: their future self. As discussed above, reproducible research makes this collaboration easier.

Companies with more than one researcher do (or likely should) act as a research
community, even if public reproducibility
is ruled out to guard proprietary information.[^chapter1_7] Making your research
reproducible to members of your organization can spread valuable
information about how analyses were done and data was collected. This
will help build your organization's knowledge and avoid effort
duplication. Just as a lack of reproducibility hinders the spread of
information in the scientific community, it can hinder it inside of a
private organization. Using the sort of dynamic automated processes run
with clearly documented source code we will learn in this book can also
help create robust data analysis methods that help your organization
avoid errors that may come from cutting-and-pasting data across
spreadsheets.[^chapter1_8]

The tools of reproducible research covered in this book enable you
to create professional standardized reports that can be easily updated
or changed when new information is available. In particular, you will
learn how to create batch reports based on quantitative data.

## The Tools of Reproducible Research

This book will teach you the tools you need to make your research highly
reproducible. Reproducible research involves two broad sets of tools.
The first is a **reproducible research environment** that includes the
statistical tools you need to run your analyses as well as "the ability
to automatically track the provenance of data, analyses, and results and
to package them (or pointers to persistent versions of them) for
redistribution". The second set of tools is a **reproducible research
publisher**, which prepares dynamic documents for presenting results and
is easily linked to the reproducible research environment [@mesirov2010
415].

In this book we will focus on learning how to use the widely available
and highly flexible reproducible research environment--R/RStudio
[@rlanguage; @rstudiocite].[^chapter1_9] R/RStudio can be linked to numerous
reproducible research publishers such as LaTeX and Markdown with Yihui
Xie's *knitr* package [-@R-knitr] or the related *rmarkdown* package
[@R-rmarkdown]. The main tools covered in this book include:

-   **R**: a programming language primarily for statistics and graphics.
    It can also be useful for data gathering and creating presentation
    documents.

-   ***knitr* and *rmarkdown***: related R packages for literate
    programming. They allow you to combine your statistical analysis and
    the presentation of the results into one document. They work with R
    and a number of other languages such as Bash, Python, and Ruby.

-   **Markup languages**: instructions for how to format a presentation
    document. In this book we cover LaTeX, Markdown, and a little HTML.

-   **RStudio**: an integrated developer environment (IDE) for R that
    tightly combines R, *knitr*, *rmarkdown*, and markup languages.

-   **Cloud storage & versioning**: Services such as Dropbox and
    Git/GitHub that can store data, code, and presentation files, save
    previous versions of these files, and make this information widely
    available.

-   **Unix-like shell programs**: These tools are useful for working
    with large research projects.[^chapter1_10] They also allow us to use
    command-line tools including GNU Make for compiling projects and
    Pandoc, a program useful for converting documents from one markup
    language to another.

### Why Use R, *knitr*/*rmarkdown*, and RStudio for Reproducible Research?

#### Why R? {-}

Why use a statistical programming language like R for reproducible
research? R has a very active development community that is constantly
expanding what it is capable of. As we will see in this book, R enables
researchers across a wide range of disciplines to gather data and run
statistical analyses. Using the *knitr* or *rmarkdown* package, you can
connect your R-based analyses to presentation documents created with
markup languages such as LaTeX and Markdown. This allows you to
dynamically and reproducibly present results in articles, slideshows,
and webpages.

The way you interact with R has benefits for reproducible research. In
general you interact with R (or any other programming and markup
language) by explicitly writing down your steps as source code. This
promotes reproducibility more than your typical interactions with
Graphical User Interface (GUI) programs like SPSS[^chapter1_11] and Microsoft
Word. When you write R code and embed it in presentation documents
created using markup languages, you are forced to explicitly state the
steps you took to do your research. When you do research by clicking
through drop-down menus in GUI programs, your steps are lost, or at
least documenting them requires considerable extra effort. Also it is
generally more difficult to dynamically embed your analysis in
presentation documents created by GUI word processing programs in a way
that will be accessible to other researchers both now and in the future.
I'll come back to these points in Chapter \@ref(GettingStartedRR).

#### Why knitr and rmarkdown? {-}

Literate programming is a crucial part of reproducible quantitative
research.[^chapter1_12] Being able to directly link your analyses, your results,
and the code you used to produce the results makes tracing your steps
much easier. There are many different literate programming tools for a
number of different programming languages.[^chapter1_13] Previously, one of the
most common tools for researchers using R and the LaTeX markup language
was *Sweave* [@leisch2002]. The packages I am going to focus on in this
book are newer and have more capabilities. They are called *knitr* and
*rmarkdown*. Why are we going to use these tools in this book and not
*Sweave* or some other tool?

The simple answer is that they are more capable than *Sweave*. Both
*knitr* and *rmarkdown* can work with markup languages other than LaTeX
including Markdown and HTML. *rmarkdown* can even output Microsoft Word
documents. They can work with programming languages other than R. They
highlight R code in presentation documents making it easier for your
readers to follow.[^chapter1_14] They give you better control over the inclusion
of graphics and can cache code chunks, i.e. save the output for later.
*knitr* has the ability to understand *Sweave*-like syntax, so it will
be easy to convert backwards to *Sweave* if you want to.[^chapter1_15] You also
have the choice to use much simpler and more straightforward syntax with
*knitr* and *rmarkdown*.

*knitr* and *rmarkdown* have broadly similar capabilities and syntax.
They both are literate programming tools that can produce presentation
documents from multiple markup languages. They have almost identical
syntax when used in Markdown. Their main difference is that they take
different approaches to creating presentation documents. *knitr*
documents must be written using the markup language associated with the
desired output. For example, with *knitr*, LaTeX must be used to create
PDF output documents and Markdown or HTML must be used to create
webpages. *rmarkdown* builds directly on *knitr*, the key difference
being that it uses the straightforward Markdown markup language to
generate PDF, HTML, and MS Word documents.[^chapter1_16]

Because you write with the simple Markdown syntax, *rmarkdown* is
generally easier to use. It has the advantage of being able to take the
same markup document and output multiple types of presentation
documents. Nonetheless, for complex documents like books and long
articles or work that requires custom formatting, *knitr* LaTeX is often
preferable and extremely flexible, though the syntax is more
complicated.

#### Why RStudio? {-}

Why use the RStudio integrated development environment for reproducible
research? R by itself has the capabilities necessary to gather data,
analyze it, and, with a little help from *knitr*/*rmarkdown* and markup
languages, present results in a way that is highly reproducible. RStudio
allows you to do all of these things, but simplifies many of them and
allows you to navigate through them more easily. It also is a happy
medium between R's text-based interface and a pure GUI.

Not only does RStudio do many of the things that R can do but more
easily, it is also a very good standalone editor for writing documents
with LaTeX and Markdown. For LaTeX documents it can, for example, insert
frequently used commands like `\section{}` for numbered sections (see
Chapter \@ref(LatexChapter)).[^chapter1_17] There are many LaTeX editors available,
both open source and paid. But RStudio is currently the best program for
creating reproducible LaTeX and Markdown documents. It has full syntax
highlighting. Its syntax highlighting can even distinguish between R
code and markup commands in the same document. It can spell check LaTeX
and Markdown documents. It handles *knitr*/*rmarkdown* code chunks
beautifully (see Chapter \@ref(GettingStartedRKnitr)).

Finally, RStudio not only has tight integration with various markup
languages, it also has capabilities for using other tools such as C++,
CSS, JavaScript, Python, and a few other programming languages. It is closely
integrated with the version control programs Git and SVN. Both of these
programs allow you to keep track of the changes you make to your
documents (see Chapter \@ref(Storing)). This is important for reproducible research since
version control programs can document many of your research steps. It
also has a built-in ability to make HTML slideshows from
*knitr*/*rmarkdown* documents. Basically, RStudio makes it easy to
create and navigate through complex reproducible research documents.

## Installing the main software {#InstallR}

Before you read this book you should install the main software. All of
the software programs covered in this book are open source and can be
easily downloaded for free. They are available for Windows, Mac, and
Linux operating systems. They should run well on most modern computers.

You should install R before installing RStudio. You can download the
programs from the following websites:

-   **R**: <https://www.r-project.org/>,

-   **RStudio Desktop (Open Source License)**:
    <https://www.rstudio.com/products/rstudio/download/>.

The webpages for downloading these programs have comprehensive information
on how to install them. Please refer to those pages for more
information.

After installing R and RStudio you will probably also want to install a
number of user-written packages that are covered in this book. To
install all of these user-written packages, please this chapter's Appendix.

### Installing markup languages {#InstallMarkup}

You will need to install the R package *rmarkdown* [@R-rmarkdown]\index{R package!rmarkdown} to turn your markdown documents into polished output that can be presented (e.g. as a website or PDF). To do this in R use:

```{r rmarkdown-install, eval=FALSE}
install.packages("rmarkdown")
```

If you plan to render your RMarkdown documents from the console without RStudio you will need to install Pandoc.\index{Pandoc} For instructions see Pandoc's download page: <https://pandoc.org/installing.html>.

If you want to create LaTeX (PDF) documents you can install a TeX
distribution.[^chapter1_18] The simplest way to get all of the LaTeX capabilities you will need for this book is to use the *tinytex*\index{R package!markdown} [@R-tinytex] R package:

```{r tinytex-install, eval=FALSE}
install.packages('tinytex')
tinytex::install_tinytex()
```
If you want a full LaTeX distribution see <http://www.latex-project.org/ftp.html> for installation information.

### GNU Make

If you are using a Linux computer you already have GNU
Make \@ref(InstallMake) installed.[^chapter1_19]
Mac users will need to install the command-line developer tools. There
are two ways to do this. One is go to the App Store and download Xcode
(it's free). Once Xcode is installed, install command-line tools, which
you will find by opening Xcode then clicking on `Preference`
`Downloads`. However, Xcode is a very large download and you only need
the command-line tools for Make. To install just the command-line tools,
open the Terminal and try to run Make by typing `make` and hitting
return. A box should appear asking you if you want to install the
command-line developer tools. Click `Install`. Windows users will have
Make installed if they have already installed *Rtools* (see this Chapter's Appendix). Mac
and Windows users will need to install this software not only so that
GNU Make runs properly, but also so that other command-line tools work
well.

### Other Tools

We will discuss other tools such as Git that can be a useful part of a
reproducible research workflow. Installation instructions for these
tools will be discussed below.

## Book Overview {#OtherBooks}

The purpose of this book is to give you the tools that you will need to
do reproducible research with R and RStudio. This book describes a
workflow for reproducible research primarily using R and RStudio. It is
designed to give you the necessary tools to use this workflow for your
own research. It is not designed to be a complete reference for R,
RStudio, *knitr*/*rmarkdown*, Git, or any other program that is a part
of this workflow. Instead it shows you how these tools can fit together
to make your research more reproducible. To get the most out of these
individual programs I will along the way point you to other resources
that cover these programs in more detail.

To that end, I can recommend a number of resources that cover more of
the nitty-gritty:

-   Michael J. Crawley's [-@crawley2013] encyclopaedic R book,
    appropriately titled ***The R Book***, published by Wiley.

-   Hadley Whickham [-@whickham2014book] has a great new book out from
    Chapman and Hall on ***Advanced R***.

-   Yihui Xie's [-@xie2018] book ***R Markdown: The Definitive Guide***,
    published by Chapman and Hall, is needless to say the definitive guide on
    R Markdown syntax. It's a good complement
    to this book's generally more research project--level focus.

-   Cathy O'Neil and Rachel Schutt [-@oneil2013] give a great
    introduction the field of data science generally in ***Doing Data
    Science***, published by O'Reilly Media Inc.

-   For many real-world examples of reproducible research in action see
    Kitzes et al [-@kitzes2018] collection of case studies
    ***The Practice of Reproducible Research***.

-   For an excellent introduction to the command-line in Linux and Mac,
    see William E. Shotts Jr.'s [-@shottsjr2012] book ***The Linux
    Command-line: A Complete Introduction*** also published by No Starch
    Press. It is also helpful for Windows users running PowerShell (see
    Chapter \@ref(DirectoriesChapter)). Sean Kross' [-@kross2018] ***The Unix
    Workbench*** is also a great freely available online introduction to the topic.

-   The RStudio website (<http://www.rstudio.com/ide/docs/>) has a
    number of useful tutorials on how to use *knitr* with LaTeX and
    Markdown. They also have very good documentation for *rmarkdown* at
    <https://rmarkdown.rstudio.com/>.

That being said, my goal is for this book to be *self-sufficient*. A
reader without a detailed understanding of these programs will be able
to understand and use the commands and procedures I cover in this book.
While learning how to use R and the other programs I personally often
encountered illustrative examples that included commands, variables, and
other things that were not well explained in the texts that I was
reading. This caused me to waste many hours trying to figure out, for
example, what the `$` is used for (preview: it's the component selector,
see Section \@ref(ComponentSelect). I hope to save you from this wasted time
by either providing a brief explanation of possibly frustrating and
mysterious things and/or pointing you in the direction of good
explanations.

### How to read this book

This book gives you a workflow. It has a beginning, middle, and end. So,
unlike a reference book, it can and should be read linearly as it takes
you through an empirical research processes from an empty folder to a
completed set of documents that reproducibly showcase your findings.

That being said, readers with more experience using tools like R or
LaTeX may want to skip over the nitty-gritty parts of the book that
describe how to manipulate data frames or compile LaTeX documents into
PDFs. Please feel free to skip these sections.

#### More-experienced R users {-}

If you are an experienced R user you may want to skip over the first
section of Chapter
\@ref(GettingStartedRKnitr): Getting Started with R, RStudio, and
*knitr*/*rmarkdown*. But don't skip over the whole chapter. The latter
parts contain important information on the *knitr*/*rmarkdown* packages.
If you are experienced with R data manipulation you may also want to
skip all of Chapter \@ref(DataClean).

#### More-experienced LaTeX users {-}

If you are familiar with LaTeX you might want to skip the first part of
Chapter \@ref(LatexChapter). The second part may be useful as it includes
information on how to dynamically create BibTeX bibliographies with
*knitr* and how to include *knitr* output in a Beamer slideshow.

#### Less-experienced LaTeX/Markdown users {-}

If you do not have experience with LaTeX or Markdown you may benefit
from reading, or at least skimming, the introductory chapters on these
top topics (chapters \@ref(LatexChapter) and \@ref(MarkdownChapter)) before
reading Part III.

### Reproduce this book

This book practices what it preaches. It can be reproduced. I wrote the
book using the programs and methods that I describe. Full documentation
and source files can be found at the book's GitHub repository. Feel free
to read and even use (within reason and with attribution, of course) the
book's source code. You can find it at:
<https://github.com/christophergandrud/Rep-Res-Book>. This is especially
useful if you want to know how to do something in the book that I don't
directly cover in the text.

If you notice any errors or places where the book can be improved please
report them on the book's GitHub Issues page:
<https://github.com/christophergandrud/Rep-Res-Bookissues>. Corrections
will be posted at:
<http://christophergandrud.GitHub.io/RepResR-RStudio/errata.htm>.

### Contents overview

The book is broken into four parts. The first part (chapters
\@ref(GettingStartedRR),
\@ref(GettingStartedRKnitr), and \@ref(DirectoriesChapter)) gives an overview of the reproducible
research workflow as well as the general computer skills that you'll
need to use this workflow. Each of the next three parts of the book
guides you through the specific skills you will need for each part of
the reproducible research process. Part two (chapters
\@ref(Storing), \@ref(DataGather), and \@ref(DataClean))
covers the data gathering and file storage process. The third part
(chapters \@ref(StatsModel), \@ref(TablesChapter), and \@ref(FiguresChapter))
teaches you how to dynamically incorporate
your statistical analysis, results figures, and tables into your
presentation documents. The final part (chapters \@ref(LatexChapter), \@ref(LargeDocs),
and \@ref(MarkdownChapter)) covers how to create reproducible
presentation documents including LaTeX articles, books, slideshows, and
batch reports as well as Markdown webpages and slideshows.


## Appendix: Additional R Setup {-}

Some setup is required to reproduce this book. Here are key R packages you should consider installing and specific instructions for Windows and Linux users.

### R Packages {-}

In this book I discuss how to use a number of user-written R packages for reproducible research. Many of these packages are not included in the default R installation. They need to be installed separately.

\index{R!packages|(}

**Note:** in general you should aim to minimize the number of packages that your research depends on. Doing so will lessen the possibility that your code will ``break'' when a package is updated. This book depends on relatively many packages because of its special and unusual purpose of illustrating a variety of tools that you can use for reproducible research.

To install key user-written packages discussed in this book, copy the following code and paste it into your R console:

```{r package_install, results='hide'}
# Packages to install
pkg_to_install <- c("brew", "bookdown", "rio", "xfun")


# Check if the packages are installed, if not install them
lapply(
    pkg_to_install,
    function(pkg) {
        if (system.file(package = pkg) == "") {
            install.packages(pkg,
                repos = "http://cran.us.r-project.org"
            )
        }
    }
)
```

Note that I specified a US based R Project CRAN "mirror"\index{CRAN!mirror} to download the packages from.^[CRAN stands for the Comprehensive R Archive Network.] There are many others to choose from. See: <https://cran.r-project.org/mirrors.html>.

The *xfun* package [@R-xfun]\index{xfun} contains a function called `pkg_attach2()`. When supplied with a vector of package names like those in `pkg_to_install` above, will install all non-installed packages. `p_load()` from the *pacman* package [@R-pacman] works in a similar way. These functions are much less verbose than the example above, but they do require the user to install the package separately before `pkg_attach2()` or `p_load()` can be used. The example above relies only on functions available in the basic **R** installation.

\index{R!packages|(}

### Special issues {-}

You may need to install ImageMagick <https://www.imagemagick.org/script/index.php>\index{ImageMagick} compile the book from source. 

\index{Windows|(}

If you are using Windows, you will also need to install *Rtools*.\index{Rtools} You can install *Rtools* from: <http://cran.r-project.org/bin/windows/Rtools/>.\label{RtoolsDownload} Please use the recommended installation to ensure that your system PATH\index{PATH} is set up correctly. Otherwise your computer will not know where the tools are. Alternatively, use the `install.Rtools()` function from the *installr* [@galili2018]\index{installr)} package to install it.

\index{Windows|(}

\index{Linux|(}

On Linux you will need to install the *RCurl* [@R-RCurl]\index{RCurl} package separately. Use your 
Terminal\index{Terminal} to install these packages with the following (or similar depending on your system) code:

```{sh, eval=FALSE}
apt-get update

apt-get install libcurl4-gnutls-dev
apt-get install r-cran-rcurl-
```

\index{Linux|(}

[^chapter1_1_1]: @rokem2018 [3-4] note that some disciplines, e.g. computing
    machinery and meteorology, give "replicable" and "reproducible" the exact
    opposite meanings from they way they are used in this book and many other
    disciplines such as biology, economics, and epidemiology.

[^chapter1_1]: This is close to what [@lykken1968] calls "operational
    replication".

[^chapter1_2]: The really reproducible computational research originates
    in the 1980s and early 1990s with Jon Claerbout and the
    Stanford Exploration Project
    [@fomel2009; @donoho2009]. Further seminal advances were made by
    Jonathan B. Buckheit and David L. Donoho who created the Wavelab
    library of MATLAB routines for their research on wavelets in the
    mid-1990s [@buckheit1995].

[^chapter1_3]: Reproducibility is important for both quantitative and qualitative
    research [@king1994]. Nonetheless, we will focus mainly on on
    methods for reproducibility in quantitative computational research.

[^chapter1_4]: Much of the reproducible computational research and literate
    programming literatures have traditionally used the term "weave" to
    describe the process of combining source code and presentation
    documents [see @knuth1992 101]. In the R community weave is usually
    used to describe the combination of source code and LaTeX documents.
    The term "knit" reflects the vocabulary of the *knitr* R package
    (knit + R). It is used more generally to describe weaving with a
    variety of markup languages. The term is used by RStudio if you are
    using the *rmarkdown* package, which is similar to *knitr*. We also
    cover the *rmarkdown* package in this book. Because of this, I use
    the term knit rather than weave in this book.

[^chapter1_5]: See the American Physical Society's website at
    <http://www.aps.org/policy/statements/99_6.cfm>. See also
    [@fomel2009].

[^chapter1_6]: Of course, it's important to keep in mind that reproducibility is
    "neither necessary nor sufficient to prevent mistakes"
    [@stodden2009b].

[^chapter1_7]: There are ways to enable some public reproducibility without
    revealing confidential information. See [@vandewalle2007] for a
    discussion of one approach.

[^chapter1_8]: See this post by David Smith about how the J.P. Morgan "London
    Whale" problem may have been prevented with the type of processes
    covered in this book:
    <http://blog.revolutionanalytics.com/2013/02/did-an-excel-error-bring-down-the-london-whale.html>
    (posted 11 February 2013).

[^chapter1_9]: The book was created with R version and developer builds of
    RStudio version 0.99.370.

[^chapter1_10]: In this book I cover the Bash shell for Linux and Mac as well as
    Windows PowerShell.

[^chapter1_11]: I know you can write scripts in statistical programs like SPSS,
    but doing so is not encouraged by the program's interface and you
    often have to learn multiple languages for writing scripts that run
    analyses, create graphics, and deal with matrices.

[^chapter1_12]: Donald Knuth coined the term literate programming in the 1970s to
    refer to a source file that could be both run by a computer and
    "woven" with a formatted presentation document [@knuth1992].

[^chapter1_13]: A very interesting tool that is worth taking a look at for the
    Python programming language is HTML Notebooks created with Jupyter.
    For more details see <http://jupyter.org/>. We will also discuss these in more detail in Section \@ref(JupyterIntro).

[^chapter1_14]: Syntax highlighting uses different colors and fonts to
    distinguish different types of text.

[^chapter1_15]: Note that the Sweave-style syntax is not identical to actual
    *Sweave* syntax. See Yihui Xie's discussion of the differences
    between the two at: <http://yihui.name/knitr/demo/sweave/>. *knitr*
    has a function (`Sweave2knitr`) for converting *Sweave* to *knitr*
    syntax.

[^chapter1_16]: It does this by relying on a tool called Pandoc [@pandoc2014].
\index{Pandoc}

[^chapter1_17]: If you are more comfortable with a what-you-see-is-what-you-get
    (WYSIWYG) word processor like Microsoft Word, you might be
    interested in exploring Lyx. It is a WYSIWYG-like LaTeX editor that
    works with *knitr*. It doesn't work with the other markup languages
    covered in this book. For more information see:
    <https://www.lyx.org/>. I give some brief information on using Lyx
    with *knitr* in Chapter 3's Appendix.

[^chapter1_18]: LaTeX is is really a set of macros for the TeX typesetting
    system. It is included in all major TeX distributions.

[^chapter1_19]: To verify this, open the Terminal and type: `make –version` (I
    used version 3.81 for this book). This should output details about
    the current version of Make installed on your computer.

<!--chapter:end:03-introduction.Rmd-->

# Getting Started with Reproducible Research {#GettingStartedRR}

Researchers often start thinking about making their work reproducible
near the end of the research process when they write up their results or
maybe even later when a journal requires their data and code be made
available for publication. Or maybe even later when another researcher
asks if they can use the data from a published article to reproduce the
findings. By then there may be numerous versions of the data set and
records of the analyses stored across multiple folders on the
researcher's computers. It can be difficult and time consuming to sift
through these files to create an accurate account of how the results
were reached. Waiting until near the end of the research process to
start thinking about reproducibility can lead to incomplete
documentation that does not give an accurate account of how findings
were made. Focusing on reproducibility from the beginning of the process
and continuing to follow a few simple guidelines throughout your
research can help you avoid these problems. Remember "reproducibility is
not an afterthought–it is something that must be built-into the project
from the beginning" [@donoho2010 386].

This chapter first gives you a brief overview of the reproducible
research process: a workflow for reproducible research. Then it covers
some of the key guidelines that can help make your research more
reproducible.

## The Big Picture: A Workflow for Reproducible Research

The three basic stages of a typical computational empirical research
project are:

-   data gathering,

-   data analysis,

-   results presentation.

Each stage is part of the reproducible research workflow covered in this
book. Tools for reproducibly gathering data are covered in Part II. Part
III teaches tools for tying the data we gathered to our statistical
analyses and presenting the results with tables and figures. Part IV
discusses how to tie these findings into a variety of documents you can
use to advertise your findings.

Instead of starting to use the individual tools of reproducible research
as soon as you learn them, I recommend briefly stepping back and
considering how the stages of reproducible research *tie* together.
This will make your workflow more coherent from the beginning
and save you a lot of backtracking later on. Figure \@ref(fig:WorkflowTies)
illustrates the workflow. Notice that most of the arrows connecting the
workflow's parts point in both directions, indicating that you should
always be thinking about how to make it easier to go backwards through
your research, i.e. reproduce it, as well as forwards.

Around the edges of the figure are some of the functions you will learn
to make it easier to go forwards and backwards through the process.
These functions tie your research together. For example, you can use
API-based R packages to gather data from the internet. You can use R's
`merge()` function to combine data gathered from different sources into one
data set. The `getURL()` function from R's *RCurl* package [@R-RCurl] and
the `read.table()` function in base R or the much more versatile `import()` 
function from the *rio* package [@R-rio]\index{rio} can be used to bring this data set into
your statistical analyses. The *knitr* or *rmarkdown* package then
ties your analyses into your presentation documents. This includes the
code you used, the figures you created, and, with the help of tools such
as the `kable()` function in the *knitr* package, tables of results. You
can even tie multiple presentation documents together. For example, you
can access the same figure for use in a LaTeX article and a
Markdown-created website with the `includegraphics` and `![]()`
functions, respectively. This helps you maintain a consistent
presentation of results across multiple document types. We'll cover
these functions in detail throughout the book. See Table
\@ref(TableTieFunctions) for a brief but more complete overview of the main
*tie functions*.

```{r WorkflowTies, engine = "tikz", fig.cap = "Example Workflow and a Selection of Functions to Tie It Together", cache=TRUE, echo=FALSE, fig.ext=if (knitr:::is_latex_output()) 'pdf' else 'png'}
\usetikzlibrary{decorations.pathmorphing}

\definecolor{Blue}{HTML}{7BCCC4}
\definecolor{LiteBlue}{HTML}{A8DDB5}
\definecolor{DarkBlue}{HTML}{08589E}

\definecolor{GrayLine}{HTML}{BDBDBD}

% Set node styles
%% Workflow stage nodes
\tikzstyle{Stage} = [draw=Blue,
                     %fill=Blue,
                     rectangle,
                     text width=7em,
                     inner sep=0.5cm,
                     font=\small]

% Raw Data nodes
\tikzstyle{RawData} = [draw=LiteBlue,
                       %fill=LiteBlue,
                       decorate,
                       decoration={random steps,
                                   segment length=2pt,
                                   amplitude=2pt},
                       inner sep=0.25cm,
                       font=\scriptsize]

% Separator line style
\tikzstyle{sepline} = [draw,
                        very thick,
                        color=GrayLine]

% Link function nodes
\tikzstyle{Links} = [draw=none,
                          text width=6em,
                          text=DarkBlue,
                          font=\footnotesize]

% Begin tikz picture
\begin{tikzpicture}

    % Raw Data Nodes
    \node (Data1) at (-3, 7) [RawData]{Raw Data};
    \node (Data2) at (-3, 5) [RawData]{Raw Data};
    \node (Data3) at (-3, 3) [RawData]{Raw Data};

    % Workflow stage nodes
    \node (DataGather) at (0.5, 5) [Stage, text width= 6em]{Data Gather};
    \node (Analysis) at (5.5, 5) [Stage, text width= 4em]{Analysis};
    \node (Presentation1) at (9, 8) [Stage]{LaTeX Book, \\ Article, \& \\ Slideshow \\ Presentations};
    \node (Presentation2) at (9, 2.5) [Stage]{Markdown/ \\ HTML Website \\ Presentations};

    % Lines
    \draw [->, very thick] (Data1) -- (DataGather);
    \draw [->, very thick] (Data2) -- (DataGather);
    \draw [->, very thick] (Data3) -- (DataGather);
    \draw [<->, very thick] (DataGather) -- (Analysis);
    \draw [<->, very thick] (Analysis) -- (Presentation1);
    \draw [<->, very thick] (Analysis) -- (Presentation2);

    \draw [<->, very thick] (Presentation1) -- (Presentation2);

    \path [sepline] (-3.5, 0.75) -- (11, 0.75);
    \path [sepline] (11.5, 9) -- (11.5, 1.5);

    % Link function nodes

    \node (pres) at (13, 5) [Links]{{\emph{knitr}} \\ \texttt{input} \\ \texttt{include} \\ \texttt{includegraphics} \\ Pandoc \\ \texttt{![]()}};
    \node (knitr) at (7.5, -1) [Links]{ {\emph{knitr}} \\ \emph{rmarkdown} \\ \texttt{source} \\ \texttt{source\_url} \\ \texttt{kable} \\ \texttt{print(xtable())} \\ \texttt{texreg} };
    \node (readData) at (3, -1) [Links]{\texttt{import} \\ \texttt{read.table} \\ \texttt{getURL} };

    \node (importData) at (-1, -1.3) [Links]{ \texttt{Make} \\ \texttt{download.file} \\ \texttt{read.table} \\ \texttt{import} \\ \texttt{merge}\\ \texttt{getURL} \\ API-based packages };


\end{tikzpicture}
```

### Reproducible theory

An important part of the research process that I do not discuss in this
book is theoretical stage. Ideally, if you are using a deductive
research design, the bulk of this work will precede and guide the data
gathering and analysis stages. Just because I don't cover this stage of
the research process doesn't mean that theory building can't and
shouldn't be reproducible. It can in fact be "the easiest part to make
reproducible" [@vandewalle2007 1254]. Quotes and paraphrases from
previous works in the literature obviously need to be fully cited so
that others can verify that they accurately reflect the source material.
For mathematically based theory, clear and complete descriptions of the
proofs should be given.

Though I don't actively cover theory replication in depth in this book,
I do touch on some of the ways to incorporate proofs and citations into
your presentation documents. These tools are covered in Part IV.

## Practical Tips for Reproducible Research

Before we start learning the details of the reproducible research
workflow with R and RStudio, it's useful to cover a few broad tips that
will help you organize your research process and put these skills in
perspective. The tips are:

1.  Document everything!

2.  Everything is a (text) file.

3.  All files should be human readable.

4.  Explicitly tie your files together.

5.  Have a plan to organize, store, and make your files available.

Using these tips will help make your computational research really
reproducible.

### Document everything!

In order to reproduce your research, others must be able to know what
you did. You have to tell them what you did by documenting as much of
your research process as possible. Ideally, you should tell your readers
how you gathered your data, analyzed it, and presented the results.
Documenting everything is the key to reproducible research and lies
behind all of the other tips in this chapter and tools you will learn
throughout the book.

#### Document your R session info {- #SessionInfoHow}

Before discussing the other tips it's important to learn a key part of
documenting with R. You should *record your session info*. Many things
in R have stayed the same since it was introduced in the early 1990s.
This makes it easy for future researchers to recreate what was done in
the past. However, things can change from one version of R to another
and especially from one version of an R package to another. Also, the
way R functions and how R packages are handled can vary across different
operating systems, so it's important to note what system you used.
Finally, you may have R set to load packages by default (see Section
\@ref(Packages) for information about packages). These packages might be
necessary to run your code, but other people might not know what
packages and what versions of the packages were loaded from just looking
at your source code. The `sessionInfo()` function in R prints a record of
all of these things. The information from the session I used to create
this book is:

```{r Ch2SessionInfoPlain, size='tiny', echo=TRUE, tidy=TRUE}
# Print R session info
sessionInfo()
```

Chapter \@ref(DirectoriesChapter) gives specific details about how to
create files with dynamically included session information. If you use
non-R tools you should also record what versions of these tools you
used.

### Everything is a (text) file

Your documentation is stored in files that include data, analysis code,
the write-up of results, and explanations of these files (e.g. data set
codebooks, session info files, and so on). Ideally, you should use the
simplest file format possible to store this information. Usually the
simplest file format is the humble, but versatile, text file.[^chapter2_1]

Text files are extremely nimble. They can hold your data in, for
example, comma-separated values () format. They can contain your
analysis code in files. And they can be the basis for your presentations
as markup documents like or , for LaTeX and Markdown files,
respectively. All of these files can be opened by any program that can
read text files.

One reason reproducible research is best stored in text files is that
this helps *future-proof* your research. Other file formats, like
those used by Microsoft Word (`.docx`) or Excel (`.xlsx`), change
regularly and may not be compatible with future versions of these
programs. Text files, on the other hand, can be opened by a very wide
range of currently existing programs and, more likely than not, future
ones as well. Even if future researchers do not have R or a LaTeX
distribution, they will still be able to open your text files and, aided
by frequent comments (see below), be able to understand how you
conducted your research [@bowers2011 3].

Text files are also very easy to search and manipulate with a wide range
of programs–such as R and RStudio–that can find and replace text
characters as well as merge and separate files. Finally, text files are
easy to version and changes can be tracked using programs such as Git
(see Chapter \@ref(Storing)).

#### Learn from the text file: keep it simple {-}

Text files are simple. Their simplicitly increases the probability of baseline usefulness in the future to researchers who will reproduce our work. We can extend the logic of the simple text file to all of the tools we use: keep it simple. Avoid adding dependencies you don't need to actually gather your data, analyze it, and present the results. For example, I have been tempted to make my presentation slides look nicer with new fonts. I was later burned when I wanted to make minor changes to slides a year after I first presented them (and a day before teaching an upcoming class) only to find that the custom fonts were no longer available. This broke my slides and forced me to spend considerable time reworking writing my source documents. If I, the creator of the slides, found this time consuming and annoying, imagine how an outside researcher would find it.

### All files should be human readable

Treat all of your research files as if someone who has not worked on the
project will, in the future, try to understand them. Computer code is a
way of communicating with the computer. It is ‘machine readable' in that
the computer is able to use it to understand what you want to do.[^chapter2_2]
However, there is a very good chance that other people (or you six
months in the future) will not understand what you were telling the
computer. So, you need to make all of your files ‘human readable'. To
make them human readable, you should comment on your code with the goal
of communicating its design and purpose [@wilson2012]. With this in mind
it is a good idea to *comment frequently* [@bowers2011 3] and
*format your code using a style guide* [@nagler1995]. For especially
important pieces of code you should use *literate programming*–where
the source code and the presentation text describing its design and
purpose appear in the same document. Doing this will make it very clear
to others how you accomplished a piece of research.

#### Commenting {-}

In R, everything on a line after a hash character––(also known as
number, pound, or sharp) is ignored by R, but is readable to people who
open the file. The hash character is a comment declaration character.
You can use the to place comments telling other people what you are
doing. Here are some examples:

```{r Ch2CommentHash}
# A complete comment line
2 + 2 # A comment after R code
```

On the first line the (hash) is placed at the very beginning, so the
entire line is treated as a comment. On the second line the is placed
after the simple equation `2 + 2`. R runs the equation and finds the
answer , but it ignores all of the words after the hash.

Different languages have different comment declaration characters. In
LaTeX everything after the percent sign is treated as a comment, and in
Markdown/HTML comments are placed inside of . The hash character is used
for comment declaration in command-line shell scripts.

Nagler [-@nagler1995 491] gives some advice on when and how to use
comments:

-   write a comment before a block of code describing what the code
    does,

-   comment on any line of code that is ambiguous.

In this book I follow these guidelines when displaying code. Nagler also
suggests that all of your source code files should begin with a comment
header. *At the least* the header should include:

-   a description of what the file does,

-   the date it was last updated,

-   the name of the file's creator and any contributors.

You may also want to include other information in the header such as
what files it depends on, what output files it produces, what version of
the programming language you are using, sources that may have influenced
the code, and how the code is licensed. Here is an example of a minimal
file header for an R source code file that creates the third figure in
an article titled ‘My Article':

```{r Ch2CommentHeader, echo=TRUE, tidy=FALSE}
############################
# R Source code file used to create Figure 3 in My 'Article'
# Created by Christopher Gandrud
# MIT License
############################
```

Feel free to use things like the long series of hash marks above and
below the header, white space, and indentations to make your comments
more readable.

#### Style guides {-}

In natural language writing you don't necessarily have to follow a style
guide. People could probably figure out what you are trying to say, but
it is a lot easier for your readers if you use consistent rules. The
same is true when writing computer code. It's good to follow consistent
rules for formatting your code so that it's easier for you and others to
understand.

There are a number of R style guides. Most of them are similar to the
Google R Style Guide.[^chapter2_3] Hadley Wickham also has a nicely presented R
style guide.[^chapter2_4] You may want to use the *styler* [@R-styler]\index{styler}
package to automatically reformat your code so that it is easier to
read.

#### Literate programming {-}

For particularly important pieces of research code it may be useful to
not only comment on the source file, but also display code in
presentation text. For example, you may want to include key parts of the
code you used for your main statistical models and an explanation of
this code in an appendix following your article. This is commonly
referred to as literate programming [@knuth1992].

### Explicitly tie your files together

If everything is just a text file, then research projects can be thought
of as individual text files that have a relationship with one another.
They are tied together. A data file is used as input for an analysis
file. The results of an analysis are shown and discussed in a markup
file that is used to create a PDF document. Researchers often do not
explicitly document the relationships between files that they used in
their research. For example, the results of an analysis–a table or
figure–may be copied and pasted into a presentation document. It can be
very difficult for future researchers to trace the table or figure back
to a particular statistical model and a particular data set without
clear documentation. Therefore, it is important to make the links
between your files explicit.

Tie functions are the most dynamic way to explicitly link your files
together. These functions instruct the computer program you are using to
use information from another file. In Table \@ref(TableTieFunctions) I have
compiled a selection of key tie functions you will learn how to use in
this book. We'll discuss many more, but these are some of the most
important.

### Have a plan to organize, store, and make your files available

Finally, in order for independent researchers to reproduce your work,
they need to be able access the files that instruct them how to do this.
Files also need to be organized so that independent researchers can
figure out how they fit together. So, from the beginning of your
research process you should have a plan for organizing your files and a
way to make them accessible.

One rule of thumb for organizing your research in files is to limit the
amount of content any one file has. Files that contain many different
operations can be very difficult to navigate, even if they have detailed
comments. For example, it would be very difficult to find any particular
operation in a file that contained the code used to gather the data, run
all of the statistical models, and create the results figures and
tables. If you have a hard time finding things in a file you created,
think of the difficulties independent researchers will have!

Because we have so many ways to link files together, there is really no
need to lump many different operations into one file. So, we can make
our files modular. One source code file should be used to complete one
or just a few tasks. Breaking your operations into discrete parts will
also make it easier for you and others to find errors [@nagler1995 490].

Chapter \@ref(DirectoriesChapter) discusses file organization in much more
detail. Chapter \@ref(Storing) teaches you a number of ways to make your
files accessible through the cloud computing services like GitHub.

\begin{table}
    \caption{A Selection of Functions/Packages/Programs for Tying Together Your Research Files}
    \label{TableTieFunctions}
    \vspace{0.3cm}
    {\footnotesize{
    \begin{tabular}{p{2.5cm} c p{5.25cm} p{2cm}}
        \hline
        Function/Package/ Program & Language & Description & Chapters Discussed \\[0.3cm]
        \hline \hline
        {\emph{knitr}} & R & R package with commands for tying analysis code into presentation documents including those written in LaTeX and Markdown. & \hfill Throughout \\[0.25cm]
        \emph{rmarkdown} & R & R package that builds on \emph{knitr}. It allows you to use Markdown to output to HTML, PDFs compiled with LaTeX or Microsoft Word. & \hfill Throughout \\[0.25cm]
        {\tt{download.file}} & R & Downloads a file from the internet. & \hfill\ref{DataGather} \\[0.25cm]
        {\tt{read.table}} & R & Reads a table into R. You can use this to import a plain-text file formatted data into R. & \hfill\ref{DataGather} \\[0.25cm]
        {\tt{read.csv}} & R & Same as \texttt{read.table} with default arguments set to import \texttt{.csv} formatted data files. & \hfill\ref{DataGather} \\[0.25cm]
        {\tt{import}} & R & Reads a table stored locally or on the internet into R. You can use it to import a wide variety of plain-text data formats into R from secure (https) URLs. & \hfill\ref{DataGather} \\[0.25cm]
        API-based packages & R & Various packages use APIs to gather data from the internet. & \hfill\ref{DataGather} \\[0.25cm]
        {\tt{merge}} & R & Merges together data frames. & \hfill\ref{DataClean} \\[0.25cm]
        {\tt{source}} & R & Runs an R source code file. & \hfill\ref{StatsModel} \\[0.25cm]
        {\tt{source\_url}} & R & From the {\emph{devtools}} package. Runs an R source code file from a secure ({\tt{https}}) url like those used by GitHub. & \hfill\ref{StatsModel} \\[0.25cm]
        {\tt{kable}} & R & Creates tables from data frames that can be rendered using Markdown or LaTeX. & \hfill\ref{TablesChapter} \\[0.25cm]
        {\tt{toLaTeX}} & R & Converts R objects to LaTeX. & \hfill\ref{GettingStartedRR} \\[0.25cm]
        {\tt{input}} & LaTeX & Includes LaTeX files inside of other LaTeX files. & \hfill\ref{LargeDocs} \\[0.25cm]
        {\tt{include}} & LaTeX & Similar to {\tt{input}}, but puts page breaks on either side of the included text. Usually it is used for including chapters. & \hfill\ref{LargeDocs} \\[0.25cm]
        {\tt{includegraphics}} & LaTeX & Inserts a figure into a LaTeX document. & \hfill\ref{FiguresChapter} \\[0.25cm]
        \texttt{![]()} & Markdown & Inserts a figure into a Markdown document. & \hfill\ref{MarkdownChapter} \\  [0.25cm]
        Pandoc & shell & A shell program for converting files from one markup language to another. Allows you to tie presentation documents together. & \hfill\ref{LargeDocs} \& \ref{MarkdownChapter} \\[0.25cm]
        Make & shell & A shell program for automatically building many files at the same time. & \hfill\ref{DataGather} \\[0.25cm]
        \hline
    \end{tabular}
    }}
\end{table}

[^chapter2_1]: Plain text files are usually given the file extension `.txt`.
    Depending on the size of your data set it may not be feasible to
    store it as a text file. Nonetheless, text files can still be used
    for analysis code and presentation files.

[^chapter2_2]: Of course, if the computer does not understand it will usually
    give an error message.

[^chapter2_3]: See:
    <http://google-styleguide.googlecode.com/svn/trunk/google-r-style.html>.

[^chapter2_4]: You can find it at <http://adv-r.had.co.nz/Style.html>.

<!--chapter:end:04-getting-started.Rmd-->

# Getting Started with R, RStudio, and knitr/rmarkdown {#GettingStartedRKnitr}

If you have rarely or never used R before, the first section of this
chapter gives you enough information to be able to get started and
understand the R code I use throughout the book. For more detailed
introductions on how to use R please refer to the resources mentioned
in Chapter \@ref(Intro) (Section \@ref(OtherBooks)). Experienced R users might
want to skip the first section. 

In the second section I'll give a brief
overview of RStudio. I highlight the key features of the main RStudio
panel (what appears when you open RStudio) and some of its key features
for reproducible research. Finally, I discuss the basics of the
*knitr* and *rmarkdown* packages, how to use them in R, and how
they are integrated into RStudio.

## Using R: The Basics

To get you started with reproducible research, we'll cover some very
basic R syntax-the rules for talking to R. I cover key parts of the R
language including:

-   objects & assignment,

-   component selection,

-   functions,

-   arguments,

-   the workspace and history,

-   packages.

Before discussing each of these in detail, let's open R and look
around.[^chapter3_1] When you open the R GUI program by clicking on the R icon
you should get a window that looks something like Figure
\@ref(fig:RBlankMain).[^chapter3_2] This window is the **R
console**. Below the start up information-information about
what version of R you are using, license details, and so on-you should
see a `>` (greater-than sign). This prompt is where you enter R
code.[^chapter3_3] To run R code that you have typed after the prompt, press the
`Return` or `Enter` key. 
Now that we have a new R session open we can get started.

```{r RBlankMain, fig.cap="R Console at Startup", echo=FALSE, out.height="50%"}
knitr::include_graphics("images/chapter_3/BlankRConsole.png")
```

### Objects {#Objects}

If you've read a description of the R language before, you will probably have seen it
referred to as an 'object-oriented language'. What are objects? Objects
are like the R language's nouns. They are things, like a vector of
numbers, a data set, a word, a table of results from some analysis, and
so on. Saying that R is object-oriented means that R is focused on doing
actions to objects. We will talk about the actions-functions-later in this
section.[^chapter3_4] Now let's create a few objects.

#### Numeric & string objects {- #ObjectNames}

Objects can have a number of different types. Let's make two simple
objects. The first is a numeric-type object. The other is a character
object. 

We can choose almost any name we want for our
objects as long as it begins with an alphabetic character and does not
contain spaces.[^chapter3_5] Just because there are relatively few hard 
restrictions on object names, doesn't 
mean that you should name your object anything. 
Your code will be much easier to read if object 
names are short and meaningful. Give each object a 
unique name to avoid confusion and conflicts. For example, if you reuse an object 
names in an R session you could easily accidentally overwrite it.

Let's begin working with numeric objects by creating a new object called 
*number* with the number 10 in it. 
To put something into the object we use the assignment operator[^chapter3_6]
(`<-`).\index{<-}:

```{r Ch3NumericObject, echo=TRUE}
number <- 10
```

To see the contents of our object, type its name into the R console.

```{r Ch3NumberSee, echo=TRUE}
number
```

Let's briefly breakdown this output. `10` is clearly the contents of
*number*. The double hash (`##`) is included here to tell
you that this is output rather than R code.[^chapter3_7] If you run functions
in your R console, you will not get the double hash in your output.
Finally, `[1]` gives the position in the object that the number 10 is on. Our object only 
has one position.

Creating an object with words and other characters-a character object-is
very similar. The only difference is that you enclose the character
string (letters in a word for example) inside of single or double
quotation marks (`''`, or `""`).[^chapter3_8] Let's create an object called *words*
containing the character string "Hello World":

```{r Ch3CharacterObject, echo=TRUE}
words <- "Hello World"
```

An object's type is important to keep in mind. It determines what we
can do to the object. For example, you cannot take the mean of a character
object like the *words* object:

```{r Ch3ClassError, echo=TRUE}
mean(words)
```

Trying to find the mean of our *words* object gives us a
warning message and returns the value `r mean(words)`: not applicable. You can also
think of `NA` as meaning "missing". To find out an object's type, use the `class()`
function.\index{R function!class} For example:

```{r Ch3ClassCommand, echo=TRUE}
class(words)
```

#### Vector & data frame objects {-}

So far we have only looked at objects with a single number or character
string.[^chapter3_9] Clearly we often want to use objects that have many strings
and numbers. In R these are usually data frame-type objects and are
roughly equivalent to the data structures you would be familiar with
from using a program such as Microsoft Excel. We will be using data
frames extensively throughout the book. Before looking at data frames it
is useful to first look at the simpler objects that make up data frames.
These are called vectors. Vectors are R's "workhorse" [@matloff2011].
Knowing how to use vectors will be especially helpful when you cleanup
raw data in Chapter \@ref(DataClean) and make tables in Chapter
\@ref(TablesChapter).[^chapter3_10]

#### Vectors {-}

Vectors are the "fundamental data type" in R [@matloff2011]. They are
simply an ordered group of numbers, character strings, and so on.[^chapter3_11]
It may be useful to think of most data in R as composed of
vectors. For example, data frames\index{data.frame} are basically collections
of vectors of the same length-i.e. they have the same number of rows-attached
together to form columns.

Let's create a simple numeric vector containing the numbers 2.8, 2, and
14.8. To do this we will use the `c()` (combine)\index{R function!combine}
function and separate the numbers with commas (`,`):

```{r Ch3numeric_vectoror, echo=TRUE}
numeric_vector <- c(2.8, 2, 14.8)

# Show numeric_vector's contents
numeric_vector
```

Vectors of character strings are created in a similar way. The only
major difference is that each character string is enclosed in quotation
marks like this:

```{r Ch3CharcterVector, echo=TRUE}
character_vector <- c("Albania", "Botswana", "Cambodia")

# Show character_vector's contents
character_vector
```

#### Matrices {-}

To give you a preview of what we are going to do when we start working
with real data sets, let's combine the two vectors
*numeric_vector* and *character_vector* into a new
object with the `cbind()` function. This function binds the two vectors
together side-by-side as columns.[^chapter3_12]\index{R function!cbind}

```{r Ch3cbind, echo=TRUE}
string_num_matrix <- cbind(character_vector, numeric_vector)

# Show string_num_matrix's contents
string_num_matrix
```

By binding these two objects together we've created a new matrix
object.[^chapter3_13] You can see that the numbers in the
*numeric_vector* column are between quotation marks. Matrices,
like vectors, can only have one data type, so R has converted the numbers to strings.

#### Data frames {-}

If we want to have an object with rows and columns and allow the columns
to contain data with different types, we need to use data frames. Let's
use the `data.frame` function to combine the *numeric_vector*
and *character_vector* objects.\index{R function!data.frame}

```{r Ch3dataframe, echo=TRUE, tidy=FALSE}
string_num_df <- data.frame(character_vector, numeric_vector)

# Display contents of string_num_df data frame
string_num_df
```

In this output, you can see the data frame's *names* attribute.[^chapter3_14] It is the column names. You can use the `names()` function\index{R function!names} to see any data frame's names:[^chapter3_15]

```{r Ch10Names, echo=TRUE}
names(string_num_df)
```

You will also notice that the first column of the data set has no name
and is a series of numbers. This is the *row.names* attribute. Data frame
rows can be given any name as long as each row name is unique. We can
use the `row.names()` function to set the row names from a vector. For
example,

```{r Ch3ReassignRowNames, echo=TRUE}
# Reassign row.names
row.names(string_num_df) <- c("First", "Second", "Third")

# Display new row.names
row.names(string_num_df)
```

You can see in this example how `row.names()` can also be used
to print the row names.[^chapter3_16] The *row.names* attribute does not behave
like a regular data frame column. You cannot, for example, include it as
a variable in a regression. You can use the `row.names()` function to
assign the *row.names* values to a regular column (for an example see
Section \@ref(RowNamesTidy)).

You will notice in the output for *string_num_df* that the strings in
the **character_vector** column are not in quotation marks. This does
not mean that they are now numeric data. To prove this, try to
find the mean of **character_vector** by running it through the `mean()`
function:

```{r Ch3CharcterVectorMean, echo=TRUE}
mean(string_num_df$character_vector)
```

#### Component selection {- #ComponentSelect}

The last bit of code we just saw will probably be confusing. Why do we have a dollar sign (`$`) between the name of our data frame object name and the `character_vector` variable? The dollar sign is called the component selector.\index{R!component selector}\index{R!\$, component selector} It's also sometimes called the element name operator. Either way, it extracts a part--component--of an object. In the previous example it extracted the **character_vector** column from the *string_num_df* so that it could be fed to 
the `mean()` function.

We can use the component selector to create new objects with parts of other objects. Imagine that we have *string_num_df* and want an object with only the information in the numbers column. Let's use the following code:

```{r Ch3CompSelect, echo=TRUE}
# Extract a numeric vector from string_num_df
numeric_extract <- string_num_df$numeric_vector

# Display contents of numeric_extract
numeric_extract
```

Knowing how to use the component selector will be especially useful when
we discuss making tables for presentation documents in Chapter
\@ref(TablesChapter).

#### `attach()`  and `with()` {-}

Using the component selector can create long repetitive code if you want
to select many components. You have to write the object name, a dollar
sign, and the component name every time you want to select a component.
You can streamline your code by using functions such as `attach()`\index{R function!attach} and
`with()`\index{R function!with}.

`attach()` attaches a database to R's search path.[^chapter3_17] R will
then search the database for variables you specify. You don't need to
use the component selector to tell R again to look in a particular data
frame after you have attached it. For example, let's attach the *cars*
data that comes with R. It has two variables, **speed** and
**dist**.[^chapter3_18]

```{r Ch3Attach, echo=TRUE}
# Attach cars to search path
attach(cars)

# Display speed
head(speed)

# Display dist
head(dist)
```

We used the `head()`\index{R function!head} function to see just the first few values of each
variable. 

Now that we are done working with the *cars* data set, we should `detach()`\index{R function!detach} it. Not doing so could confuse R later in our session.

```{r Ch3Detach, echo=TRUE}
# Detach cars
detach(cars)
```

A safer alternative to `attach()` is `with()`. It more clearly delineates when to draw from inside a particular object. For example, we can find the mean of *numeric_vector* `with()` the *string_num_df* data frame:

```{r Ch3With, echo=TRUE, tidy=FALSE}
with(string_num_df, {
        mean(numeric_vector)
    }
)
```

You can see that in the `with()` call the data frame object goes first
and then the `mean()` function[^chapter3_19] goes second in curly brackets (`{}`).

In this book I avoid using the `attach()` and `with()`
functions. Instead I use the component selector. Though it creates longer
code, I find that code written with the component selector is less ambiguous
It's always clear which object we are selecting a component
from. 

#### Subscripts {-}

Another way to select parts of an object is to use subscripts. You have
already seen subscripts in the output from our examples so far. They are
denoted with square braces (`[]`). We can use subscripts to select not
only columns from data frames but also rows and individual values. As we
began to see in some of the previous output, each part of a data frame
has an address captured by its row and column number. We can tell R to
find a part of an object by putting the row number/name, column
number/name, or both in square braces. The first part denotes the rows
and separated by a comma (`,`) are the columns.

To give you an idea of how this works let's use the *cars*
data set again. Use `head()` to get a sense of what this data looks like.

```{r Ch3HeadSwiss, echo=TRUE}
head(cars)
```

We can see a data frame with information on various cars' speeds
(**speed**) and stopping distances (**dist**). If we want to select only
the third through seventh rows we can use the following subscript
function call:

```{r Ch3FirstSeventhRows, echo=TRUE}
cars[3:7, ]
```

The colon (`:`) creates a sequence of whole numbers from 3 to 7. To
select the fourth row of the **dist** column we can type:

```{r Ch3FourthSecond, echo=TRUE}
cars[4, 2]
```

An equivalent way to do this is:

```{r Ch3FourthDist, echo=TRUE}
cars[4, "dist"]
```

Finally, we can even include a vector of column names to select:

```{r Ch3FourthBoth, echo=TRUE}
cars[4, c("speed", "dist")]
```

### Functions {#FunctionsCommands}

If objects are the nouns of the R language, functions
are the verbs. They do things to objects. Let's use the `mean` function
as an example. This function takes the mean of a numeric vector object.
Remember our *numeric_vector* object from before:

```{r Shownumeric_vector, echo=TRUE}
numeric_vector
```

To find the mean of this object simply type:

```{r numeric_vector_mean, echo=TRUE}
mean(x = numeric_vector)
```

We use the assignment operator to place a function's output into an
object. For example:

```{r numeric_vector_meanAssign, echo=TRUE}
numeric_vector_mean <- mean(x = numeric_vector)
```

Notice that we typed the function's name then enclosed the object name in
parentheses immediately afterwards. This is the basic syntax that all
functions use, i.e. `FUNCTION(ARGUMENTS)`. Even if you don't want to explicitly
include an argument, *you still need to type the parentheses after the function*.[^chapter3_21a]

#### Arguments {-}

Arguments modify what functions do. In our most recent example we gave
the `mean` function one argument (`x = numeric_vector`) telling it that we
wanted to find the mean of *numeric_vector*. Arguments use the
`ARGUMENT_LABEL = VALUE` syntax.[^chapter3_21] In this case **x** is the argument
label.

To find all of the arguments that a function can accept, look at the
**Arguments** section of the function's help
file. To access the help file type: `?FUNCTION`.\index{R function!?} For example:

```{r Ch3HelpMean, echo=TRUE, eval=FALSE, tidy=FALSE}
?mean
```

The help file will also tell you the default values that the arguments
are set to. You do not need to explicitly set an argument if
you want to use its default value.

You do need to be fairly precise with the syntax for your argument's
values. Values for logical arguments must written as `TRUE` or
`FALSE`.[^chapter3_22] Arguments that accept character strings require quotation
marks.

Let's see how to use multiple arguments with the `round()`\index{R function!round} function. This
function rounds a vector of numbers. We can use the `digits` argument to
specify how many decimal places we want the numbers rounded to. To round
the object *numeric_vector_mean* to one decimal place type:

```{r Ch3Round, echo=TRUE}
round(x = numeric_vector_mean, digits = 1)
```

Note that *arguments are always separated by commas*.

Some arguments do not need to be explicitly labeled. For example, we
could write:

```{r Ch3ArgeNoLabel, echo=TRUE}
# Find mean of numeric_vector
mean(numeric_vector)
```

R will do its best to figure out what you want and will only give up
when it can't. This will generate an error message. However, to avoid
any misunderstandings between yourself and R, it is good practice to
label your argument values. This will also make your code easier for
other people to read, i.e. it will be more reproducible.

You can stack functions inside of arguments. For example, have R find the
mean of *numeric_vector* and round it to one decimal place:

```{r Ch3StackedArgs, echo=TRUE}
round(mean(numeric_vector), digits = 1)
```

Stacking functions inside of each other can create code that is
difficult to read. Another option that potentially makes more easily
understandable code is piping\index{pipe} using the pipe function (`%>%`) that you
can access from the *magrittr* [@R-magrittr]\index{R package!magrittr} or *dplyr* [@R-dplyr]\index{R package!dplyr} packages. The basic idea behind the pipe function is that the output of one function is set as the first argument of the next. For example, to find the mean of **numeric_vector** and then round it to one decimal place use:

```{r Ch3Pipe, echo=TRUE}
# Load magrittr package
library(magrittr)

# Find mean of numeric_vector and round to 1 decimal place
mean(numeric_vector) %>%
    round(digits = 1)
```

### The workspace & history

All of the objects you create become part of your workspace,
alternatively known as the current working environment. Use the `ls()`\index{R function!ls}
function to list all of the objects in your current workspace.[^chapter3_23]

```{r Ch3LS, echo=TRUE}
ls()
```

You can remove specific objects from the workspace using the `rm()`\index{R function!rm}
function. For example, to remove the `character_vector` and `words` objects
type:

```{r Ch3RM, echo=TRUE, eval=FALSE}
rm(character_vector, words)
```

To save the entire workspace into a binary-not plain-text-RData file use
`save.image()`.\index{R function!save.image} The main argument of
`save.image()` is the location and name of the file in which you want to
save the workspace. If you don't specify the file path it will be saved
into your current working directory (see Chapter \@ref(DirectoriesChapter)
for information on files paths and working directories). To
save the current workspace in a file called *workspace_2018-12-22.RData* in
the current working directory type:

```{r Ch3Workspace, echo=TRUE, eval=FALSE}
save.image(file = "workspace_2018-10-28.RData")
```

Use `load()`\index{R function!load} to load a saved workspace back into R:

```{r Ch3LoadWS, echo=TRUE, eval=FALSE}
load(file = "workspace_2018-10-28.RData")
```

You should generally avoid having R automatically save your workspace
when you quit and reload it when you start R again. Instead, when you
return to a project, rerun the source code files. This avoids
any complications caused when you use an object in your workspace that
is left over from running an older version of the source code.[^chapter3_24] In
general I also recommend against saving data in binary RData formatted
files if feasible. They are not text files they are not human readable and
are much less future-proof.

One of the few times when saving your workspace is  useful is when
it includes an object that was computationally difficult and took a long
time to create. In this case you can save only the large object with
`save()`.[^chapter3_25]\@ref(RSave)\index{R function!save}
For example, if we have a very large
object called *model_output* we can save it to a file called *model_output.RData* like
this:

```{r Ch3Comp, echo=TRUE, eval=FALSE}
save(model_output, file = "model_output.RData")
```

### R history {#RHistory}

When you execute code in the R console it becomes part of your history. To see
the most recent functions in your history use the `history()` function.\index{R function!history} You
can also use the up and down arrows on your keyboard when your cursor is
in the R console to scroll through your history.

### Global R options {#ROptions}

In R you can set global options with `options()`.\index{R function!options} This lets
you set how R runs and outputs functions through an entire R session. For
example, to have output rounded to one decimal place, set the `digits`
argument:

```{r Ch3Options, echo=TRUE, eval=FALSE}
options(digits = 1)
```

### Installing new packages and loading functions {#Packages}

Functions are stored in R packages. The functions we have used so far were
loaded automatically by default. One of the great things about R is the
many user-created packages[^chapter3_26] that expand the number of
functions we can use. To install functions that do not come with the basic
R installation you need to install the add-on packages that
contain them. To do this, use the `install.packages()`\index{R function!install.packages} function. By default this function downloads and installs the packages from the Comprehensive R Archive Network (CRAN).\index{CRAN}

When you install a package, you will likely be given a list
of "mirrors" from which you can download the package. Select the
mirror closest to you.

Once you have installed a package you need to load when you want to
use its functions. Use the `library()` function\index{R function!library}
to load a package.[^chapter3_27] For example,
the following code loads the popular *ggplot2* plotting package:

```{r Ch3Library, echo=TRUE, warning=FALSE, message=FALSE}
library(ggplot2)
```

Please note that for the examples in this book I only specify what
package a function is from if it is not loaded by default when you start
an R session.

Finally, if you want to make sure R uses a function from a specific
package you can use the double-colon operator (`::`). For example, to
make sure that we use the `qplot` function from the *ggplot2* package we
type:

```{r Ch3ColonOperator, echo=TRUE, eval=FALSE}
ggplot2::qplot(. . .)
```

Using the double-colon ensures
that R will use the function from the particular package you want and
makes it clear to a source code reader what package a function comes
from. If you use the double-colon, you don't need to
include `library()` beforehand. Note that it does not load all of the functions in the package, just the one you ask for. 

## Using RStudio

As I mentioned in Chapter \@ref(Intro), RStudio is an integrated
development environment for R. It provides a centralized and
well-organized place to do almost anything you want to do with R. As we
will see later in this chapter, it is especially well integrated with
literate programming tools for reproducible research. Right now let's
take a quick tour of the basic RStudio window.

#### The default window {-}

When you first open RStudio you should see a default window that looks
like Figure \@ref(fig:BlankMain). In this figure you see three window panes.
The large one on the left is the *Console*. This pane
functions exactly the same as the console discussed so far in this chapter. Other panes
include the *Environment/History/Connections* panes, in the upper
right-hand corner. The *Environment* pane shows you all of the objects
in your workspace and some of their characteristics, like how many
observations a data frame has. You can click on an object in this pane
to see its contents. This is especially useful for quickly looking at a
data set in much the same way that you can visually scan a Microsoft
Excel spreadsheet. The *History* pane records all of the functions you
have run. It also allows you to rerun code and insert it into a source
code file. The *Connections* pane allows you to manage connections to databases
such as an SQL server.\index{SQL}

```{r BlankMain, echo=FALSE, fig.cap="RStudio at Startup", out.width="100%"}
knitr::include_graphics("images/chapter_3/RStudioStartup.png")
```

In the lower right-hand corner you will see the
*Files/Plots/Packages/ Help/Viewer* panes. We will discuss
the *Files* pane in more detail in Chapter \@ref(DirectoriesChapter).
Basically, it allows you to navigate and organize your files. The *Plots*
pane is where figures you create in R appear. This pane allows you to
see all of the figures you have created in a session using the right and
left arrow icons. It also lets you save the figures in a variety of
formats. The *Packages* pane shows the packages you have installed,
allows you to load individual packages by clicking on the dialog box
next to them, access their help files (just click on the package name),
update the packages, and even install new packages. The *Help* pane
shows you help files. You can search for help files and search within
help files using this pane. Finally, the *Viewer* pane allows you to
view local web content like JavaScript graphics and Shiny apps.

#### The Source pane {-}

There is an important pane that does not show up when you open RStudio
for the first time. This is the *Source* pane. The *Source*
pane is where you create, edit, and run your source code files. It also
functions as an editor for your markup files. It is the center of
reproducible research in RStudio.

Let's first look at how to use the *Source* pane with regular R files.
We will then cover how it works with *knitr*/*rmarkdown* in
more detail in the next section.

R source code files have the file extension `.R`. When you create a new
source code document, RStudio will open a new *Source* pane. Do this by
going to the menu bar and clicking on `File` `New`. In the `New`
drop-down menu you have the option to create a variety of different
source code documents. Select the `R Script` option. You should now see
a new pane with a bar across the top that looks like
Figure \@ref(fig:TopBarFigs). To run the R code you have in your source code
file highlight it[^chapter3_28] and click the `Run` icon on the top bar. This
sends the code to the console where it is run. The icon to the right of
`Run` runs the code above where you have highlighted. The
`Source` icon next to this runs all of the code in the file using R's
`source` function. When you click on the last icon on the right (it has a series of stacked lines) you will get a navigable table of contents for your file; very useful for working 
with longer documents, especially markup documents.

```{r TopBarFigs, echo=FALSE, fig.cap="RStudio Source Code Pane Top Bar", out.width="100%"}
knitr::include_graphics("images/chapter_3/RSourceBar.png")
```

## Using *knitr* and *rmarkdown*: The basics

To get started with *knitr* and *rmarkdown* in R or RStudio
we need to learn some of the basic concepts and syntax. The concepts are
the same regardless of the markup language we are knitting R code with,
but much of the syntax varies by markup language. *rmarkdown* relies on
*knitr* and a utility called *Pandoc* to create many different types of
presentation documents (HTML, PDF, or MS Word) from one document written
largely using *knitr*'s R Markdown syntax.

### What *knitr* does

Let's take a quick, abstract look at what the *knitr* package does. As
I've mentioned, *knitr* ties together your presentation of results with
the creation of those results. The *knitr* process takes three steps
(see Figure \@ref(fig:KnitProcess)). First we create a knittable markup
document. This contains both the analysis code and the presentation
document's markup--the text and rules for how to format the text. *knitr*
then *knits*: i.e. it runs the analysis code and converts the output
into the markup language you are using according to the rules that you
tell it to use. It inserts the marked-up results into a document that
only contains markup for the presentation document. You *compile* this
markup document as you would if you hadn't used *knitr* into your final
PDF document or webpage presenting your results.

### What *rmarkdown* does {#rmardownHeader}

The *rmarkdown* package implements a variation on this process that
utilizes a program called Pandoc to create presentation documents in
multiple formats from an a knittable document written in Markdown. The
main difference between pure *knitr* markdown and *rmarkdown* documents
is the inclusion of a header specifying how you want to render the
document with Pandoc.[^chapter3_29]

The header is written in YAML.[^chapter3_30] The YAML header can include
information such as the document's title, author, whether or not to
include a table of contents, and a link to a BibTeX bibliography file.
YAML is a straightforward data format that organizes information in a
simple hierarchy. The header begins and ends with three dashes (`---`).
Information keys-like "title" and "author"-are separated from their
associated "values" by a colon (`:`). Sub-values of a hierarchy are
denoted by being placed on a new line and indented.[^chapter3_31] Here is a basic
*rmarkdown* header that indicates the document's title, author, date,
and that it will be turned into a PDF document (via LaTeX).

```{yaml, eval=FALSE}
---
title: "A Basic PDF Presentation Document"
author: "Christopher Gandrud"
date: "2018-10-28"
output: pdf_document:
    toc: true
—--
```

The title, author, and date, will be placed at the beginning of the
output document. The final line (`toc: true`) creates a table of
contents near the beginning of the PDF document when we knit it. We will
discuss more header options in Chapter \@ref(MarkdownChapter).

RStudio can automatically create a basic header for the type of output
document that you want when you open a new *rmarkdown* file. Simply
select `File` then `R Markdown…`. A window will appear that looks like
Figure \@ref(fig:rmarkdownWindow). In this window select the type of output document
you want to create and click `Ok`.

In addition to the header, *rmarkdown* differs from basic *knitr* files in that you
can include Pandoc syntax in your R Markdown document. This can be
useful for bibliographies as we will discuss in Chapter
\@ref(MarkdownChapter). Nonetheless, remember that apart from the
header and ability to include Pandoc syntax, at the simplest level
*rmarkdown* documents are *knitr* documents written in R Markdown
syntax. Importantly, they have the same code chunk syntax we will see
shortly.

```{r rmarkdownWindow, fig.cap="The New R Markdown Options Window", echo=FALSE, out.width="100%"}
knitr::include_graphics("images/chapter_3/newRMarkdown.png")
```

### File extensions

When you save a knittable file, use a file extension that indicates (a)
that it is knittable and (b) what markup language it is using. You can
use a number of file extensions for R Markdown files including: `.Rmd`
and `.Rmarkdown`.[^chapter3_32] LaTeX documents that include *knitr*
code chunks are generally called R Sweave files and have the file
extension `.Rnw`. This terminology is a little confusing.[^chapter3_33] It is a
holdover from *knitr*'s main literate programming
predecessor *Sweave*. Note that *rmarkdown* documents can compile to 
LaTeX PDF documents and support pretty much the full capabilities of LaTeX.
Because markdown is generally easier to write than raw LaTeX, `.Rnw` markup 
is much less commonly used. For example, for the third edition of this book 
I converted it from `.Rnw` to `.Rmd`.

```{r KnitProcess, fig.cap="*knitr*/*rmarkdown* Process", engine = "tikz", cache=TRUE, echo=FALSE, fig.ext=if (knitr:::is_latex_output()) 'pdf' else 'png'}
% Define colors for figure
%% Color palette (GnBU) chosen using ColorBrewer 2.0
%% See: http://colorbrewer2.org/
%% Not used in the print version
\definecolor{Blue}{HTML}{7BCCC4}
\definecolor{LiteBlue}{HTML}{A8DDB5}
\definecolor{DarkBlue}{HTML}{08589E}

\definecolor{GrayLine}{HTML}{BDBDBD}

% Set node styles
%% Workflow stage nodes
\tikzstyle{Docs} = [draw=Blue,
                     rectangle,
                     inner sep=0.3cm,
                     font=\small]

% Begin tikz picture
\begin{tikzpicture}

    \node(knit) at (2, 1.75) {{\emph{\textbf{Knit}}}};
    \node(compile) at (6, 1.75) {{\emph{\textbf{Compile}}}};

    % Document nodes
    \node (knittable) at (0, 0) [Docs, text width= 6em]{Knittable Document \\ (Markup + Code Chunks)};
    \node (Markup) at (4, 0) [Docs, text width= 6em]{Markup Only Document};
    \node (Presentation) at (8, 0) [Docs, text width = 6em]{Presentation Document};

    % .Rnw LaTeX Example
    \node(LaTeX) at (1, -2.5) {\textbf{\emph{knitr} LaTeX Example}};
    \node (Rnw) at (0, -3.5) [Docs, text width= 6em]{\emph{Paper.Rnw}};
    \node (tex) at (4, -3.5) [Docs, text width= 6em]{\emph{Paper.tex}};
    \node (pdf) at (8, -3.5) [Docs, text width = 6em]{\emph{Paper.pdf}};

    % Markdown to HTML Example
    \node(Markdown) at (2, -5) {\textbf{\emph{knitr}/\emph{rmarkdown} Markdown Example}};
    \node (Rmd) at (0, -6) [Docs, text width= 6em]{\emph{Website.Rmd}};
    \node (md) at (4, -6) [Docs, text width= 6em]{\emph{Website.md}};
    \node (html) at (8, -6) [Docs, text width = 6em]{\emph{Website.html}};

    % Lines
    \draw [->, very thick] (knittable) -- (Markup);
    \draw [->, very thick] (Markup) -- (Presentation);

    \draw [->, very thick] (Rnw) -- (tex);
    \draw [->, very thick] (tex) -- (pdf);

    \draw [->, very thick] (Rmd) -- (md);
    \draw [->, very thick] (md) -- (html);

\end{tikzpicture}
```


### Code chunks

Use code chunks to include knittable R code into your markup presentation documents.
Code chunk syntax differs depending on the
markup language we are using to write our documents. Let's see the
syntax for R Markdown and R LaTeX files. If you are unfamiliar with
basic LaTeX or Markdown syntax you might want to skim chapters
\@ref(LatexChapter) and \@ref(MarkdownChapter) to familiarize yourself with it
before reading this section.

#### R Markdown {- #RMarkdownChunkBasic}

In R Markdown files we begin a code chunk by writing the head:
` ```{r} `. A code chunk is closed-ended-simply with:
` ``` `. For example:

````markdown
`r ''````{r}
# Example of an R Markdown code chunk
string_num_matrix <- cbind(character_vector, numeric_vector)
```
````

The R Markdown code chunk syntax is exactly the same for files you
compile with *knitr* or *rmarkdown*.

#### R LaTeX (.`Rnw`) {-}

Code chunks are delimited in non-*rmarkdown* R LaTeX
documents in a way that emulates the long-established
*Sweave* syntax.[^chapter3_34] Sweave-style code chunks begin with the following head:
`<<>>=`. The code chunk is closed with an at sign (`@`).

```{sh, eval=FALSE}
<< >>=
string_num_matrix <- cbind(character_vector, numeric_vector)
@
```

#### Code chunk labels {-}

Each chunk has a label. When a code chunk creates a plot or the output
is cached-stored for future use-*knitr* uses the chunk
label for the new file's name. If you do not explicitly give the chunk a
label it will be assigned one like: `unnamed-chunk-1`.

To explicitly assign chunk labels in R Markdown documents, place the
label name inside of the braces after the `r`. If we wanted to use the, admittedly not descriptive, label `ex_label` we type:

````markdown
`r ''````{r ex_label}
# Example chunk label
```
````

The same general format applies to the two types of LaTeX chunks. In
Sweave-style chunks we type: `<<ex_label>>=`.
Try not to use spaces or periods in your
label names. Also remember that chunk labels *must* be unique.

#### Code chunk options

There are many times when we want to change how our code chunks are
knitted and presented. Maybe we only want to show the code and not the
results or perhaps we don't want to show the code at all but just a
figure that it produces. Maybe we want the figure to be formatted on a
page in a certain way. To make these changes and many others we can
specify code chunk options.

Like chunk labels, you specify options in the chunk head. Place them
after the chunk label, separated by a comma. Chunk options are written
following pretty much the same rules as regular R function arguments.
They have a similar `OPTION_LABEL=VALUE` structure as arguments. The
option values must be written in the same way that argument values are.
Character strings need to be inside of quotation marks. The logical
`TRUE` and `FALSE` operators cannot be written `"true"` and
`"false"`. For example, imagine we have a Markdown code chunk called
`ex_label`. If we want to run the code chunk, but
not show the code in the final presentation document, we can use the
option `echo=FALSE`.

````markdown
`r ''````{r ex_label, echo=FALSE}
string_num_matrix <- cbind(character_vector, numeric_vector) 
```
````

Note that all labels and code chunk options must be on the same line.
Options are separated by commas. The syntax for *knitr*
options is the same regardless of the markup language.

Throughout this book we will look at a number of different code chunk
options. Many of the chunk options we will use in this book are listed
in Table \@ref(ChunkOptionsTable). For the full list of
*knitr* options see the *knitr* chunk options
page maintained by *knitr*'s creator Yihui Xie:
<http://yihui.name/knitr/options>.

\begin{table}
  \caption{A Selection of {\emph{knitr}} Code Chunk Options}
  \begin{center}
  \label{ChunkOptionsTable}
  \begin{tabular}{l c p{6cm}}
    \hline
    Chunk Option Label & Type & Description \\[0.25cm] \hline\hline
    \texttt{cache} & Logical & Whether or not to save results from the code chunk in a cache database. Note: cached chunks are only run when they are changed. \\[0.25cm]
    \texttt{cache.vars} & Character Vector & Specify the variable names to save in the cache database. \\[0.25cm]
    \texttt{eval} & Logical & Whether or not to run the chunk. \\[0.25cm]
    \texttt{echo} & Logical & Whether or not to include the code in the presentation document. \\[0.25cm]
    \texttt{error} & Logical & Whether or not to include error messages. \\[0.25cm]
    \texttt{engine} & Character & Set the programming language for {\emph{knitr}} to evaluate the code chunk with. \\[0.25cm]
    \texttt{fig.align} & Character & Align figures. (Note: does not work with R Markdown documents.) \\[0.25cm]
    \texttt{fig.path} & Character & Set the directory where figures will be saved. \\[0.25cm]
    \texttt{include} & Logical & When \texttt{include=FALSE} the chunk is evaluated, but the results are not included in the presentation document. \\[0.25cm]
    \texttt{message} & Logical & Whether or not to include R messages. \\[0.25cm]
    \texttt{out.height} & Numeric & Set figures' heights in the presentation document. \\[0.25cm]
    \texttt{out.width} & Numeric & Set figures' widths in the presentation document. \\[0.25cm]
    \texttt{results} & Character & How to include results in the presentation document. \\[0.25cm]
    \texttt{tidy} & Logical & Whether or not to have \emph{knitr} format printed code chunks. \\[0.25cm]
    \texttt{warning} & Logical & Whether or not to include warnings. \\[0.25cm]
    \hline
  \end{tabular}
  \end{center}
  {\scriptsize{These Functions are discussed in more detail in Chapter \ref{StatsModel}.}}
\end{table}

### Global chunk options {#GlobalChunkOptions}

So far we have only looked at how to set local options in
*knitr* code chunks, i.e. options for only one specific
chunk. If we want an option to apply to all of the chunks in our
document we can set global chunk options. Options are 'global' in the
sense that they apply to the entire document. Setting global chunk
options helps us create documents that are formatted consistently
without having to repetitively specify the same option every time we
create a new code chunk. For example, rather than using the `fig.align='center'` option in each code chunk that creates a figure we can center align all figures in a document by setting the option globally.

To set a global option, first create a new code chunk at the beginning
of your document.[^chapter3_35] You will probably want to set the option `include=FALSE` so that *knitr* doesn't include the code in your presentation
document. Inside the code chunk use `opts_chunk$set`. You can set any chunk option as an
argument to `opts_chunk$set`. The option will be applied across your document, unless
you set a different local option.

Here is an example of how you can center align all of the figures in *rmarkdown* in a chunk placed near the beginning of the document:

````markdown
`r ''````{r set_global, include=FALSE}
# Center align all knitr generated figures
knitr::opts_chunk$set(fig.align='center')
```
````

If you want to use 'opts_chunk' in a document rendered with
*rmarkdown* you will need to either explicitly call it as in the example using the double colon or load the *knitr* package before calling `opts_chunk`.

### *knitr* package options

*knitr* package options affect how the package itself runs.
For example, the `progress` option can be set as either `TRUE` or `FALSE` [^chapter3_36] depending on whether or not you want a progress bar to be displayed when you knit a
code chunk. You can use `base.dir` to set the directory where you want all of your
figures to be saved (see Chapter \@ref(DirectoriesChapter)) or the `child.path` option
to specify where child documents are located (see Chapter \@ref(LargeDocs)).

You set package options in a similar way as global chunk options with `opts_knitr$set`.
For example, include this code at the beginning of a document to turn
off the progress bar when it is knitted:

### Hooks

You can also set hooks. Hooks come in two types: chunk hooks and output
hooks. Chunk hooks run a function before or after a code chunk. Output
hooks change how the raw output is formatted. I don't cover hooks in
much detail in this book. For more information on hooks, please see
Yihui Xie's webpage: <http://yihui.name/knitr/hooks>.

### *knitr*, *rmarkdown*, & RStudio

RStudio is highly integrated with *knitr*/*rmarkdown* and
the markup languages that they work with. RStudio is probably the easiest tool
for creating and compiling *knitr*/*rmarkdown*. Most of the
RStudio/*knitr*/*rmarkdown* features are accessed in the
*Source* pane. The *Source* pane's appearance and capabilities change
depending on the type of file you have open in it. RStudio uses a file's
extension and, if it is an *rmarkdown* document, its header, to
determine what type of file you have open.[^chapter3_37] We have already seen
some of the features the *Source* pane has for R source code files.
Let's now look at how to use *knitr* and *rmarkdown* with R
source code files as well as the markup formats we cover in this book: R
Markdown and R LaTeX.

#### Compiling R source code Notebooks {- #PublishRPubs}

If you want a quick well-formatted account of the code that you ran and
the results that you got you can use RStudio's "Compile Notebook"
capabilities. RStudio uses *rmarkdown* to create a standalone file
presenting your source code and results. It will include all of the code
from an R source file as well as the output. This can be useful for quickly presenting the steps you took to do an analysis. You can see an example
RStudio Notebook in Figure \@ref(fig:NotebookExample).

If you want to create a Notebook from an open R source code file simply
click the `Compile Notebook` icon
(![image](images/chapter_3/CompileNotebook.png)) in the
*Source* pane's top bar.[^chapter3_38] Then in the window that pops up select the
output type you would like (HTML, PDF or MS Word) and click the
`Compile` button. For this example I selected HTML. In Figure
\@ref(fig:NotebookExample) you can see near the top center right a small globe
icon next to the word "Publish". Clicking this allows you to publish
your Notebook to RPubs (<http://www.rpubs.com/>). RPubs is a site for
sharing your Notebooks over the internet. You can publish not only
Notebooks, but also any *rmarkdown* Markdown
document you compile in RStudio.

```{r NotebookExample, fig.cap="RStudio Notebook Example", echo=FALSE, out.width="100%"}
#### Include notebook example image ####
knitr::include_graphics("images/chapter_3/NotebookExample.png")
```

In this chapter's appendix we discuss interactive Jupyter notebooks.\index{Jupyter} They are popular in the data science and tech industries and use a somewhat different logic from *rmarkdown* notebooks. 

```{r SourcePaneRmarkdown, echo=FALSE, fig.cap="RStudio Source Pane for an RMarkdown File", out.width="100%"}
knitr::include_graphics("images/chapter_3/SourcePaneRmarkdown.png")
```

#### R Markdown {- #r-markdown}

Figure \@ref(fig:SourcePaneRmarkdown) is what the *Source* pane looks like when you have an R Markdown file open. You'll notice
the familiar `Run` button for running R code. It now includes a drop-down menu for running code chunks. It includes options like `Run Current Chunk`--i.e. run the chunk
where your cursor is located--`Run Next Chunk`, and `Run All` chunks. In this menu you can select `Insert Chunk` to insert the basic syntax required for a code chunk. You can navigate to a specific chunk using a drop-down menu on the bottom
left-hand side of the *Source* pane. This can be very
useful if you are working with a long document. To knit your file, click
the `Knit` icon on the left side of the *Source* pane's top bar.
If you click on the downward
arrow on the right of this icon you will be given the opportunity to knit the document to HTML, PDF, or, MS Word using *rmarkdown*.
Helpfully the R Markdown *Source* pane's top bar also includes the `ABC` spell check icon.

RStudio can properly highlight both the markup language
syntax and the R code in the *Source* pane. This makes your source code
much easier to read and navigate. RStudio can also fold code chunks.
This makes navigating through long documents, with long code chunks,
much easier. At line 1014 in Figure \@ref(fig:SourcePaneRmarkdown) you can see a
small downward facing arrow, If you were to click this arrow, the code
chunk would collapse to look like line 1021 in Figure
\@ref(fig:SourcePaneRmarkdown). To unfold the chunk, just click on the arrow again.

You may also notice that there is a code folding arrow on line 1015 in Figure
\@ref(fig:SourcePaneRmarkdown). This allows us to fold parts of the code chunk.
To enable this option, create a comment line with at least one hash
before the comment text and at least four after it like this:

```{r CommentFold, echo=TRUE}
#### An RStudio Foldable Comment ####
```

You will be able to fold all of the text after this comment up until the
next similarly formatted comment (or the end of the chunk).

#### R (Sweave) LaTeX {-}

Many of the *Source* pane options for R (`.Rnw) LaTeX files are the same as R Markdown
files, the key differences being that there is a `Compile PDF` icon instead of
`Knit`. Clicking this icon knits the file and creates a PDF file in
your R LaTeX file's directory. There is also a `Format` icon instead of
the question mark icon. This actually inserts LaTeX formatting functions
into your document for things such as section headings and bullet lists.
These functions can be very tedious to type out by hand otherwise.

By default RStudio may be set up to use *Sweave* for compiling LaTeX
documents. To use *knitr* instead of *Sweave* to knit
`.Rnw` files you should click on `Tools` in the RStudio menu bar then
click on `Global Options...`. Once the
**Options** window opens, click on the
`Sweave` button. Select `knitr` from the drop-down menu for "Weave Rnw
files using:". Finally, click `Apply`.[^chapter3_39]

In the `Sweave` options menu you can also set which LaTeX typesetting
engine to use. By default it is set to the more established engine
pdfLaTeX.\index{pdfLaTeX} Another option is XeLaTeX.\index{XeLaTeX} XeLaTeX has the ability to use many more characters than pdfLaTeX as it works with UTF-8 encoded input.\index{UTF-8} It can also use any font on your computer. XeLaTeX is especially useful
compared to pdfLaTeX if you are using characters that are not found in
standard English.

### *knitr* & R

As *knitr* is a regular R package, you can of course, knit
documents in R (or using the console in RStudio). All of the
*knitr* syntax in your markup document is the same as
before, but instead of clicking a or button use the function. To knit a
hypothetical Markdown file *example.Rmd* you first use the
`setwd` function to set the working directory (for more details see
Chapter \@ref(DirectoriesChapter)) to the folder where the
*example.Rmd* file is located. In this example it is
located in the Documents folder.[^chapter3_40]

```{r Ch3RawKnitSetwd, echo=TRUE, eval=FALSE, tidy=FALSE}
setwd("/Documents/")
```

Then you knit the file:

```{r Ch3RawKnit, echo=TRUE, eval=FALSE, tidy=FALSE}
knit(input = "example.Rmd", output = "example.md")
```

You use the same steps for all other knittable document types. Note that
if you do not specify the output file, *knitr* will
determine what the file name and extension should be. In this example it
would come up with the same name and location as we gave it.

In this example, using the `knit` function only creates a Markdown file
and not an HTML file, as clicking `Knit` in RStudio did. Likewise, if you use
on a file you will only end up with a basic LaTeX file and not a
compiled PDF. To convert the Markdown file into HTML you need to further
run the file through the function from the *markdown*
package, i.e.

```{r Ch3MDtoHTML, eval=FALSE, tidy=FALSE, echo=TRUE}
mardownToHTML(file = "example.md", output = "example.html")
```

This is a bit tedious. Luckily, there is a function in the
*knitr* package that combines `markdownToHTML` and `knit`.
It is called `knit2html`. You use it like this:

```{r Ch3RMDtoHTML, echo=TRUE, eval=FALSE, tidy=FALSE}
knit2html(file = "example.Rmd", output = "example.html")
```

If we want to compile a file in R we run it through the function in the
*tools* package. This package will run both LaTeX and
BibTeX to create a PDF with a bibliography (see Chapter \@ref(LatexChapter)
for more details on using BibTeX for bibliographies). Here is a example:

```{r CH3tex2pdf, echo=TRUE, eval=FALSE, tidy=FALSE}
# Load tools package
library(tools)

# Compile pdf
texi2pdf(file = "example.tex")
```

Just like with `knit2html`, you can simplify this process by using the
`knit2pdf` function to compile a PDF file from a `.Rnw` document.

### *rmarkdown* and R {#rmarkdownRender}

Just as *knitr* is an R package that you can run from the console, you
can also run *rmarkdown* from the console. Instead of the `knit`
function use `render`. Imagine that *Example.Rmd* now has an *rmarkdown*
header:

````yaml
---
title: "A Basic PDF Presentation Document"
author: "Christopher Gandrud"
date: "2018-10-28"
output:
    pdf_document:
        toc: true
    html_document:
    toc: false
—--
````

This header specifies how the file can be compiled to either PDF or
HTML. When compiled to PDF it will include a table of contents. When
compiled to HTML it won't. Now we use `render()`:\index{R function!render}

```{r Ch3RenderBasic, eval=FALSE, echo=TRUE}
render("example.Rmd")
```

This call will compile the document to a PDF in the working directory,
because PDF is listed as the first output format in the header. The
document will be called *example.pdf*. Alternatively, to compile the R
Markdown file to HTML use:

```{r Ch3RenderHTML, eval=FALSE, echo=TRUE}
render("example.Rmd", "html_document")
```

We could compile to both formats using:

```{r Ch3RenderBasicAll, eval=FALSE, echo=TRUE}
render("example.Rmd", "all")
```

or

```{r Ch3RenderBasicAltAll, eval=FALSE, echo=TRUE}
render("example.Rmd", c("pdf_document", "html_document"))
```

In all of these cases, `render` will create, but not keep the intermediate *.md* or
*.tex* document. You can have these documents saved by adding `keep_md`
or `keep_tex` to the header. For example:

````yaml
output:
    pdf_document:
        toc: true
        keep_tex: true
    html_document:
      keep_md: true
    toc: false
—--
````

Finally, if you want to output to one format with the default rendering
style, for example, the HTML document, use `html_document: default`.

### Chapter summary {#chapter-summary .unnumbered}

We've covered a lot of ground in this chapter, including R basics, how
to use RStudio, and *knitr*/*rmarkdown* syntax for multiple markup
languages. These tools, especially R and *knitr*/*rmarkdown*, are
fundamental to the reproducible research process we will learn in this
book. They enable us to create dynamic text-based files that record our
research steps in detail. In the next chapter we will look at how to
organize files created with these types of tools into reproducible
research projects.

## Appendix: Jupyter interactive notebooks {- #jupyter}

Jupyter notebooks are a commonly used alternative to R Markdown notebooks and *knitr* generally for displaying and discussing computational analyses. They are especially prevalent in the data science industry.  For example, I never used Jupyter notebooks during my academic life in the quantitative social sciences, but after moving to the tech industry I regularly write and read them. A reason for this is that they  are particularly useful for fast prototyping analyses. They are interactive. You run the code directly in the notebook and see the results printed in the notebook immediately. 

Jupyter is often associated with Python, but the name 'Jupyter' actually refers to three languages used in data science **Ju**lia,\index{Julia language} **Py**thon,\index{Python} and **R** and can be used with other languages as well. 

This book is clearly focused on R Markdown, but if you would like to explore launching Jupyter from R see the *IRkernel* package [@R-IRkernel]. Though personally I have been using launching Jupyter from Python or Julia, as the installation is more straightforward. In fact for the Python installation is a prerequisite for *IRkernel*. For more details see:

- Python installation instructions: <http://jupyter.org/install.html>,

- Julia installation instructions: <https://github.com/JuliaLang/IJulia.jl>.

#### Controversy

In mid-2019 there was a major controversy (well at least a topic heavily discussed on data science Twitter)\index{Twitter} about Jupyter notebooks. Joel Grus started the controversy by giving a talk at the main Jupyter conference--JupyterCon--called 'I Don't Like Notebooks'.[^jupyter_dont_like]

His critique was multi-pronged, but one that resonated with my strong interest in reproducibility (and personal experience using these notebooks) is that you can execute code in Jupyter notebooks in an arbitrary order. Using R Markdown terminology: you could execute the third code chunk before the second and then make changes to and rerun the second chunk without rerunning the third. This is troubling for reproducibility as it is difficult for a third person (or yourself a few minutes later) to know what order the code was executed in to get the displayed results. Jupyter notebooks do record the order in which code was executed within the same session, but this adds an additional layer of complexity to figuring out results. The order also becomes inconsistent when a notebook is relaunched.

#### R Markdown vs. Jupyter

A big reason that I personally prefer R Markdown over Jupyter is that it provides the 'best of both worlds'. RStudio allows you to interact with R Markdown documents in a very similar way to Jupyter notebooks (see Figure \@ref(fig:RMarkdownInteractive)). It allows you to interactively run code chunks in any order and immediately see the results in line with the markup. It also channels you towards running the code in order when you knit the document before you share it with others.

```{r RMarkdownInteractive, fig.cap="R Markdown Interactive Behavior Example in RStudio", echo=FALSE, out.width="100%"}
#### Include notebook example image ####
knitr::include_graphics("images/chapter_3/RmarkdownInteractive.png")
```
RmarkdownInteractive.png

## Appendix: knitr and Lyx {- #LyxAppendix}

You may be more comfortable using a what-you-see-is-what-you-get
(WYSIWYG) editor, similar to Microsoft Word. Lyx is a WYSIWYG LaTeX
editor that can be used with *knitr*. I don't cover Lyx in detail in
this book, but here is a little information to get you started.

#### Set Up {-}

To set up Lyx so that it can compile `.Rnw` files, click `Document` in
the menu bar then `Settings`. In the left-hand panel the second option
is `Modules`. Click on `Modules` and select `Rnw (knitr)`. Click `Add`
then `Ok`. Now, compile your LaTeX document in the normal Lyx way.

#### Code Chunks {-}

Enter code chunks into TeX Code blocks within your Lyx documents. To
create a new TeX Code block, select `Insert` from the menu bar then
`TeX Code`.

[^chapter3_1]: Please see Chapter \@ref(Intro) for instructions on how to install R.

[^chapter3_2]: This figure and almost all screenshots in this book were taken on
    a computer using the Mac OS 10.14 operating system.

[^chapter3_3]: If you are using a Unix-like system such as Linux Ubuntu or Mac OS
    10, you can also access R via an application called the Terminal. If
    you have installed R on your computer you can type `R` into the Terminal. 
    This will begin a new R session. You will know
    you are in a new R session because the same type of start up
    information as in Figure \@ref(fig:RBlankMain) will be printed in your
    Terminal.

[^chapter3_4]: Somewhat confusingly, functions are themselves
    objects. In this chapter I treat them as distinct from other object
    types to avoid confusion.

[^chapter3_5]: @whickham2014book argues that underscores (`_`) should be used 
    to separate words in object names to make the names easier to read. 
    For example: `health_data` rather than `healthdata`. 
    Underscores appear to now be the dominate naming convention in the R community. 
    Other conventions include using periods (`.`) or capital
    letters (referred to as CamelBack). For more
    information on R naming conventions see @baath2012.

[^chapter3_6]: The assignment operator is sometimes also referred to as the 'gets
    arrow'.

[^chapter3_7]: The double hash is generated automatically by
    *knitr*. Prepending the output with hashes makes it easier to copy and paste code
    into R from a document created by *knitr*/*rmarkdown* because R
    will ignore everything after a hash.

[^chapter3_8]: Single and double quotation marks are interchangeable in R for
    this purpose. In this book I always use double quotes, except for
    *knitr* code chunk options.

[^chapter3_9]: These might be called scalar objects, though in R scalars are just
    vectors with a length of 1.

[^chapter3_10]: If you want information about other types of R objects such as
    lists and matrices, Chapter 1 of Norman Matloff's [-@matloff2011]
    book is a really good place to look.

[^chapter3_11]: In a vector, every member of the group must be of the same type.
    If you want an ordered group of values with different types you can
    use lists.

[^chapter3_12]: If you want to combine objects as if they were rows of the same
    column(s), use the `rbind()` function.

[^chapter3_13]: Matrices are basically collections of vectors, each represented 
    as a column.

[^chapter3_14]: Matrices can also have a names attribute.

[^chapter3_15]: You can also use `names()` to assign names for the entire data
    frame. For example,
    `names(string_num_df) <- c(variable_1, variable_2)`

[^chapter3_16]: Note that this is really only useful for data frames with few
    rows.

[^chapter3_17]: You can see what is in your current search path with the `search`
    function. Just type `search()` into your R console.

[^chapter3_18]: For more information on this data set, type `?cars` into your R
    console.

[^chapter3_19]: Using R terminology, the second "argument" value-the code after
    the comma-of the **with** function is called an "expression", because
    it can contain more than one R function or statement. See Section
    \@ref(arguments) for a more comprehensive discussion of R function
    arguments.
    
[^chapter3_21a]: If you don't include the parentheses after the function name
    R will return the source code for the function just like when you enter an 
    object name into your console returns the contents. This is because in 
    R functions are actually also objects!

[^chapter3_21]: Note: you do not have to put spaces between the argument label
    and the equals sign or the equals sign and the value. However,
    having spaces can make your code easier to read.

[^chapter3_22]: They can be abbreviated `T` and `F`.

[^chapter3_23]: Note: your workspace will probably include different objects than
    this example. These are objects created to knit the book.

[^chapter3_24]: For example, imagine you create an object, then change the source
    code you used to create the object. However, there is a syntax error
    in the new version of the source code. The old object won't be
    overwritten and you will be mistakenly using the old object in
    future functions.

[^chapter3_25]: `save.image()` is just a special case of `save()`.

[^chapter3_26]: For the latest list see:
    <http://cran.r-project.org/web/packages/available_packages_by_name.html>.

[^chapter3_27]: You will probably see R packages referred to as "libraries",
    though this is a misnomer.

[^chapter3_28]: If you are only running one line of code, you don't need to
    highlight the code; you can simply put your cursor on that line.

[^chapter3_29]: Note that you can also create an *rmarkdown* document without a
    header. *rmarkdown* will just use the default settings when knitting.  

[^chapter3_30]: YAML is a recursive acronym that means "YAML Ain't Markup
    Language".

[^chapter3_31]: It doesn't matter how many spaces you use to indent, as long as
    all indentations have the same number of spaces.

[^chapter3_32]: R Markdown files that you compile with *knitr* or *rmarkdown*
    have the same `.Rmd` file extension.

[^chapter3_33]: The "nw" refers to noweb simple literate programming tool that
    Sweave builds on.

[^chapter3_34]: The syntax has its genesis in a literate programming tool called
    noweb @leisch2002 [@ramseynoweb].

[^chapter3_35]: In Markdown, you can put global chunk options at the very top of
    the document. In `.Rnw` documents they should be placed after the
    `\begin{document}` function (see Chapter \@ref(LatexChapter) for more
    information on how LaTeX documents are structured).

[^chapter3_36]: It's set as `TRUE` by default.

[^chapter3_37]: You can manually set how you want the *Source* pane to act by
    selecting the file type using the drop-down menu in the lower
    right-hand corner of the *Source* pane.

[^chapter3_38]: Alternatively, `File` `Compile Notebook...`

[^chapter3_39]: In the Mac version of RStudio, you can also access the `Options`
    window via `RStudio` `Preferences` in the menu bar.

[^chapter3_40]: Using the directory name is for Mac computers. Please use
    alternative syntax discussed in Chapter \@ref(DirectoriesChapter) on
    other types of systems.
    
[^jupyter_dont_like]: The presentation is available here: <https://docs.google.com/presentation/d/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI/preview?slide=id.g362da58057_0_1>. For a comprehensive discussion by Yihui Xie see: <https://yihui.name/en/2018/09/notebook-war/>.

<!--chapter:end:05-start-R.Rmd-->

# Getting Started with File Management {#DirectoriesChapter}

Careful file management is crucial for reproducible research. Remember
two of the guidelines from Chapter
\@ref(GettingStartedRR):

-   Explicitly tie your files together.

-   Have a plan to organize, store, and make your files available.

Apart from the times when you have an email exchange (or even meet in
person) with someone interested in reproducing your research, the main
information independent researchers have about the procedures is what
they access in files you make available: data files, analysis files, and
presentation files. If these files are well organized and the way they
are tied together is clear, replication will be much easier. File
management is also important for you as a researcher, because if your
files are well organized you will be able to more easily make changes,
benefit from work you have already done, and collaborate with others.

Using tools such as R, *knitr*/*rmarkdown*, and markup languages like
LaTeX requires fairly detailed knowledge of where files are stored in
your computer. Handling files to enable reproducibility may require you
to use command-line tools to access and organize your files. R and
Unix-like shell programs allow you to control files-creating, deleting,
relocating-in powerful and really reproducible ways. By typing these
commands you are documenting every step you take. This is a major
advantage over graphical user interface-type systems where you organize
files by clicking and dragging them with the cursor. However, text
commands require you to know your files' specific addresses-their file
paths.

In this chapter we discuss how a reproducible research project may be
organized and cover the basics of file path naming conventions in
Unix-like operating systems, such as Mac OS X and Linux, as well as
Windows. We then learn how to organize them with RStudio Projects.
Finally, we'll cover some basic R and Unix-like shell commands for
manipulating files as well as how to navigate through files in RStudio
in the *Files* pane. The skills you will learn in this chapter will be
heavily used in the next chapter (Chapter \@ref(Storing) and
throughout the book.

In this chapter we work with locally stored files, i.e. files stored on
your computer. In the next chapter we will discuss various ways to store
and access files remotely stored in the cloud.

## File Paths & Naming Conventions

All of the operating systems covered in this book organize files in
hierarchical directories, also known as file trees. To a large extent,
directories can be thought of as the folders you usually see on your
Windows or Mac desktop.[^chapter4_1] They are called hierarchical because
directories are located inside of other directories, as in Figure \@ref(fig:ExampleTree).

### Root directories

A root directory is the first level in a disk, such as a hard drive. It
is the root out of which the file tree 'grows'. All other directories
are subdirectories of the root directory.

On Windows computers you can have multiple root directories, one for
each storage device or partition of a storage device. The root directory
is given a drive letter assignment. If you use Windows regularly you
will most likely be familiar with `C:\` used to denote the C partition
of the hard drive. This is a root directory. On Unix-like systems,
including Macs and Linux computers, the root directory is simply denoted
by a forward slash (`/`) with nothing before it.

### Subdirectories & parent directories

You will probably not store all of your files in the root directory.
This would get very messy. Instead you will likely store your files in
subdirectories of the root directory. Inside of these subdirectories may
be further subdirectories and so on. Directories inside of other
directories are also referred to as child directories of a parent
directory.

On Windows computers separate subdirectories are indicated with a back
slash (`\`). For example, if we have a folder called *Data* inside of a
folder called *example-project* which is located in the C root directory
it has the address `C:\example-project\Data`.[^chapter4_2] When you type Windows
file paths into R you need to use two backslashes rather than one: e.g.
`C:\\example-project\\Data`. This is because the `\` is an escape
character in R.[^chapter4_3] Escape characters tell R to interpret the next
character or sequence of characters differently. For example, in Section \@ref(TSVEscape)
you'll see how `\t` can be interpreted by R as a tab rather than the
letter "t". Add another escape character to neutralize the escape
character so that R interprets it as a backslash. In other words, use an
escape character to escape the escape character. Another option for
writing Windows file names in R is to use one forward slash (`/`).

On Unix-like systems, including Mac computers, directories are indicated
with a forward slash (`/`). The file path of the *Data* file on a
Unix-like system would be: `/example-project/Data`. Remember that a
forward slash with nothing before it indicates the root directory. So
`/example-project/Data` has a different meaning than
`example-project/Data`. In the former, *example-project* is a subdirectory
of the root. In the latter, *example-project* is a subdirectory of the
current working directory (see below for details about working
directories). This is also true in Windows.

In this chapter I switch between the two file system naming conventions
to expose you to both. For the remainder of the book I use Unix-like
file paths. When you use relative paths, these will work across
operating systems in R. We'll get to relative paths in a moment.

### Working directories

When you use R, markup languages, and many of the other tools covered in
this book, it is important to keep in mind what your current working
directory is. The working directory is the directory where the program
automatically looks for files and other directories, unless you tell it
to look elsewhere. It is also where it will save files. Later in this
chapter we will cover commands for finding and changing the working
directory.

### Absolute vs. relative paths

For reproducible research, collaborative research, and even if you ever
change the computer you work on, it is a good idea to use relative
rather than absolute file paths. Absolute file paths give the entire
path of a given file or directory on a specific system. For example,
`/example-project/Data` is an absolute path as it specifies the path of
the *Data* child directory all the way back to the root directory.
However, if our current working directory is *example-project* and we
want to link to the *Data* child directory or a file in it, we don't
need the absolute path. We could simply use `Data/`, i.e. the path
relative to the working directory.

It is good practice to use relative paths when possible and organize
your files such that using relative paths is easy. This makes your code
less dependent on the particular file structure of a particular
computer. For example, imagine you use `C:\\example-project\\Data` in
your source code to link to the *Data* directory. Someone-a
collaborator, a researcher reproducing your work, or even you-then
tries to run the code on a different computer. The code will break if
they are, for instance, using a Unix-like system or have placed
*example-project* in a different partition of their hard drive. This can
be fixed relatively straightforwardly by changing the file path in the
source. However, this is tedious (often not well documented) and
unnecessary if you use relative file paths.

### Spaces in directory & file names

It is generally good practice to avoid putting spaces in your file and
directory names. For example, I called the example project parent
directory "example-project" rather than "Example Project". Spaces in file
and directory names can sometimes create problems for computer programs
trying to read the file path. The program may believe that the space
indicates that the path name has ended. To make multi-word names easily
readable without using spaces, adopt a convention such as CamelBack. In
CamelBack new words are indicated with capital letters, while all other
letters are lower case. For example, "example-project".



## Organizing Your Research Project

Figure \@ref(fig:ExampleTree) gives an example of how the files in a simple
reproducible research project could be organized. The project's parent
directory is called *example-project*. Inside this directory are the
primary knittable documents (*Paper.Rnw* *Slideshow.Rnw*, and
*Website.Rmd*). In addition there is an *Analysis* sub-directory with
the R files to run the statistical analyses followed by a further *Data*
child directory.

The nested file structure allows you to use relative file paths. The
knittable documents can call *Analysis1.R* with the relative path
*Analysis/Analysis1.R*, which in turn could call a file in the *Data/*
subdirectory. If all of the directories were at the same level of the
file tree then you would need to use absolute file paths.

```{r ProjectMenu, fig.cap="An Example RStudio Project Menu", echo=FALSE, out.height="30%"}
knitr::include_graphics("images/chapter_4/ProjectMenu.png")
```

In addition to the main files and subdirectories in *example-project* you
will probably notice a file called *README.md*. The *README.md* file
gives an overview of all the files in the project. It should briefly
describe the project including things like its title, author(s), topic,
any copyright information, and so on. It should also indicate how the
folders in the project are organized and give instructions for how to
reproduce the project. The README file should be in the main project
folder-in our example this is called *example-project*-so that it is
easy to find. If you are storing your project as a GitHub repository
(see Chapter \@ref(Storing) and the file is called *README*, its contents will
automatically be displayed on the repository's main page. If the
*README* file is written using Markdown (e.g. *README.md*), it will also
be properly formatted. Figure \@ref(fig:BookRepository) shows an example of this.

It is good practice to dynamically include the system information for
the R session you used to create the project. To do this you can write
your README file with R Markdown. Simply include the `sessionInfo()`
command in a *knitr* code chunk in the R Markdown document. If you knit
this file immediately after knitting your presentation document, it will
record the information for that session.

You can also dynamically include session info in a LaTeX document. To do
this, use the command in a code chunk. The code chunk should have the
option `results='asis'`. The code is:

```{r Ch4SessionInfoLatex, eval=FALSE, echo=TRUE}
toLatex(sessionInfo())
```

## Setting Directories as RStudio Projects {#CreateRStudioProject}

If you are using RStudio, you may want to organize your files as
Projects. You can turn a normal directory into an
RStudio Project by clicking on `File` in the RStudio menu bar and
selecting `New Project…`. A new window will pop-up. Select the option
`Existing Directory`. Find the directory you want to turn into an
RStudio Project by clicking on the `Browse` button. Finally, select
`Create Project`. You will also notice in the Create Project pop-up
window that you can build new project directories and create a project
from a directory already under version control (we'll do this at the end
of Chapter \@ref(Storing). When you create a new project you will see that
RStudio has put a file with the extension `.Rproj` into the directory.

Making your research project directories RStudio Projects is useful for
a number of reasons:

-   The project is listed in RStudio's Project menu where it can be
    opened easily (see Figure \@ref(fig:ProjectMenu).

-   When you open the project in RStudio it automatically sets the
    working directory to the project's directory and loads the
    workspace, history, and source code files you were last working on.

-   You can set project specific options like whether PDF presentation
    documents should be compiled with *Sweave* or *knitr*.

-   When you close the project your R workspace and history are saved in
    the project directory if you want.

-   It helps you version control your files.

-   You can build your Project-run the files in a specific way-with
    makefiles.

-   Gives you an easy-to-use interface for managing the R packages that
    your project depends on.

We will look at many of these points in more detail in the next few
chapters.

## R File Manipulation Functions

R has a range of functions for handling and navigating through files.
Including these functions in your source code files allows you to more
easily replicate your actions.

##### `getwd` {-}

To find your current working directory use the `getwd()` function:

```{r Ch4Getwd, echo=TRUE}
getwd()
```

The example here shows you the current working directory that was used
while knitting this chapter.

##### `list.files` {-}

Use the `list.files()` function to see all of the files and subdirectories
in the current working directory. You can list the files in other
directories too by adding the directory path as an argument to the
command.

```{r Ch4ListFiles, echo=TRUE}
list.files()
```

You can see that the *Chapter4* folder has the file *chapter4.Rnw* (the
markup file used to create this chapter) and a child directory called
*images4* where I stored the original versions of the figures included
in this chapter.

##### `setwd` {-}

The `setwd()` function sets the current working directory. For example, if we are
on a Mac or other Unix-like computer we can set the working directory to
the *Analysis* directory in our Example Project (see Figure \@ref(fig:ExampleTree) like this:

````r
setwd("/example-projecgt/analysis/")
````

Now R will automatically look in the *Analysis* folder for files and
will save new files into this folder, unless we explicitly tell it to do
otherwise.

When working with a knittable document, setting the working directory
once in a code chunk changes the working directory for all subsequent
code chunks.

##### `root.dir` {-}

By default the root (or working) directory for all of the code chunks in
a knittable document is the directory where this document is located.
You can reset the directory by feeding a new file path to the `root.dir`
option. We can set this globally[^chapter4_4] for all of the chunks in the
document by including the following code in the document's first chunk.

````r
opts_knit$set(root.dir = "/example-project/analysis")
````

Here we set the */example-project/analysis* sub-directory as the root
directory for all of the chunks in our presentation document.

**Note:** In general it is preferable to use a nested file structure, as
we saw before, rather than specify `root.dir()`. A nested file structure
creates one less step for those trying to reproduce your work on a
different computer. They do not need to change the `root.dir()` file path.

##### `dir.create` {-}

Sometimes you may want to create a new directory. You can use the `dir.create` function to do this.[^chapter4_5] For example, to create a *example-project* file
in the root *C* directory on a Windows computer type:

````r
dir.create("C:\\example-project")
````

##### `file.create` {-}

Similarly, you can create a new blank file with the `file.create()`
function. To add a blank R source code file called *SourceCode.R* to the
*example-project* directory on the *C* drive use:

````r
file.create("C:\\example-project\\source-code.R")
````

##### `cat` {- #catR}

If you want to create a new file and put text into it use the `cat()`
(concatenate and print) function. For example, to create a new file in
the current working directory called *ExampleEcho.md* that includes the
text "Reproducible Research with R and RStudio" type:

````r
cat("Reproducible Research with R and RStudio", file = "example-cat.md")
````

In this example we created a Markdown formatted file by using the `.md`
file extension. We could, of course, change the file extension to `.R`
to set it as an R source code file, `.Rnw` to create a *knitr* LaTeX
file, and so on.

You can use `cat()` to print the contents of one or more objects to a
file. **Warning:** The `cat()` function will overwrite existing files with
the new contents. To add the text to existing files use the
`append = TRUE` argument.

````r
cat("More Text", file = "example-cat.md", append = TRUE)
````

##### `unlink` {-}

You can use the command to delete files and directories.

````r
unlink("C:\\example-project\\source-code.R")
````

**Warning:** the `unlink()` function permanently deletes files, so be very
careful using this command.

##### `file.rename` {-}

You can use the `file.rename()` to, obviously, rename a file. It can also
be used to move a file from one directory to another. For example,
imagine that we want to move the *example-cat.md* file from the directory
*example-project* to one called *markdown-files* that we already
created.[^chapter4_6]

````r
file.rename(from = "C:\\example-project\\example-cat.md",
            to = "C:\\markdown-files\\example-cat.md")
````

##### `file.copy` {-}

`file.rename()` fully moves a file from one directory to another. To
copy the file to another directory use the `file.copy()` function. It has
the same syntax as `file.rename()`:

````r
file.copy(from = "C:\\example-project\\example-cat.md",
            to = "C:\\markdown-files\\example-cat.md")
````

## Unix-like Shell Commands for File Management

Though this book is mostly focused on using R for reproducible research
it can be useful to use a Unix-like shell program to manipulate files in
large projects. Unix-like shell programs including Bash on Mac and Linux
and Windows PowerShell allow you to type commands to interact with your
computer's operating system.[^chapter4_7] We will especially return to shell
commands in the next chapter when we discuss Git version control and
makefiles for collecting data in Chapter \@ref(DataGather), as well as the command-line program[^chapter4_8] Pandoc \@ref(LargeDocs) and \@ref(MarkdownChapter)). We don't have enough space to fully
introduce shell programs or even all of the commands for manipulating
files. We are just going to cover some of the basic and most useful
commands for file management. For good introductions for Unix and Mac OS
10 computers see William E. Shotts Jr.'s [-@ShottsJr2012] book on the
Linux command-line. For Windows users, Microsoft maintains a tutorial on
Windows PowerShell at
<http://technet.microsoft.com/en-us/library/hh848793>. The commands
discussed in this chapter should work in both Unix-like shells and
Windows PowerShell.

It's important at this point to highlight a key difference between R and
Unix-like shell syntax. In shell commands you don't need to put
parentheses around your arguments. For example, if I want to change my
working directory to my Mac Desktop in a shell using the `cd` command I
simply type:[^chapter4_9]

````bash
cd /Users/Me/Desktop
````

In this example `Me` is my user name.

##### `cd` {-}

As we just saw, to change the working directory in the shell just use
the (change directory) command. Here is an example of changing the
directory in Windows PowerShell:

````bash
cd /Users/Me/Desktop
````

If you are in a child directory and want to change the working directory
to the previous working directory you were in, simply type:

````bash
cd -
````

If, for example, our current working directory is */User/Me/Desktop* and
we typed `cd` followed by a minus sign (`cd -`) then the working
directory would change to */User/Me*. Note this will not work in
PowerShell.

##### `pwd` {-}

To find your current working directory, use the `pwd` command (present
working directory). This is essentially the same as R's `getwd` command.

````shell
pwd

## /Users/Me/Desktop
````

##### `ls` {-}

The `ls` (list) command works very similarly to R's `list.files()`
function. It shows you what is in the current working directory.

````shell
ls

## chapter_4.Rmd images4
````

As we saw earlier, R also has an `ls` command. R's `ls()` function lists
items in the R workspace. The shell's `ls` command lists files and
directories in the working directory.

##### `mkdir` {-}

Use `mkdir` to create a new directory. For example, if I wanted to
create a directory in my Linux root directory called *NewDirectory* I
would type:

````shell
mkdir /new-directory
````

##### `echo` {-}

There are a number of ways to create new files in Unix-like shells. One
of the simplest ways is with the `echo` command. This command simply
prints its arguments. For example:

```{r Ch4Echo1, engine='sh', echo=TRUE}
echo Reproducible Research with R and RStudio
```

If you add the greater-than symbol (`>`) after the text you want to
print and then a file name, `echo` will create the file (if it doesn't
already exist) in the current working directory and then print the text
into the file.

```{r Ch4Echo2, eval=FALSE, engine='sh', echo=TRUE}
echo Reproducible Research with R and RStudio > example-echo.md
```

Using only one greater-than sign will completely erase the
*example-echo.md* file's contents and replace them with
`Reproducible Research with R and RStudio`. To add the text at the end
of an existing file, use two greater-than signs (`>>`).

```{r Ch4Echo3, eval=FALSE, engine='sh', echo=TRUE}
echo More text. >> example-echo.md
```

There is also a `cat` shell command. It works slightly differently than
the R version of the command and I don't cover it here.

##### `rm` {-}

The command is similar to R's command. It removes (deletes) files or
directories. Again, be careful when using this command, because it
permanently deletes the files or directories.

```{r Ch4rm, eval=FALSE, engine='sh', echo=TRUE}
rm example-echo.md
```

As we saw in Chapter \@ref(GettingStartedRKnitr), R also has an `rm()` function. It is
different because it removes objects from your R workspace rather than
files from your working directory.

##### `mv` {-}

To move a file from one directory to another with the shell, use the
`mv` (move) command. For example, to move the file *example-echo.md* from
*example-project* to *markdown-files* use the following code and imagine
both directories are in the root directory:[^chapter4_10]

```{r Ch4mv, eval=FALSE, engine='sh', echo=TRUE}
mv
/example-project/ExampleEcho.md /markdown-files
```

Note that the *markdown-files* directory must already exist, otherwise it
will simply rename the file. So this command is similar to the R function
`file.rename()`.

##### `cp` {-}

The `mv` command completely moves a file from one directory to another.
To copy a version of the file to a new directory use the `cp` command.
The syntax is similar to `mv`:

```{r Ch4cp, eval=FALSE, engine='sh', echo=TRUE}
cp /example-project/ExampleEcho.md /markdown-files
```

##### `system()` (R funtion) {- #systemRcommand}

You can run shell commands from within R using R's `system()` function. For
example, to run the `echo` command from within R type:

````r
system("echo Text to Add > ExampleEcho.md")
````

## File Navigation in RStudio

The RStudio *Files* pane allows us to navigate our file tree and do some
basic file manipulations. The left panel of Figure \@ref(fig:FilesPane)
shows us what this pane looks like. The pane allows us to navigate to
specific files and folders and delete and rename files. To select a
folder as the working directory tick the dialog box next to the file
then click the `More` button and select `Set As Working Directory`.
Under the `More` button you will also find
options to `Move` and `Copy` files (see the right pane of Figure \@ref(fig:FilesPane)).

The *Files* pane is a GUI, so our actions in the *Files* pane are not as
easily reproducible as the commands we learned earlier in this chapter.

### Chapter summary {-}

In this chapter we've learned how to organize our research files to
enable dynamic replication. This included not only how they can be
ordered in a computer's file system, but also the file path naming
conventions-the addresses-that computers use to locate files. Once we
know how these addresses work we can use R and shell commands to refer
to and manipulate our files. This skill is particularly useful because
it allows us to place code in text-based files to manipulate our project
files in highly reproducible ways. In the next few chapters we will
begin to put these skills in practice when we learn how to store our
files and create data files in reproducible ways.

[^chapter4_1]: To simplify things, I use the terms 'directory' and 'folder'
    interchangeably in this book.

[^chapter4_2]: For more information on Windows file path names see this helpful
    website:
    <http://msdn.microsoft.com/en-us/library/windows/desktop/aa365247(v=vs.85).aspx>

[^chapter4_3]: As we will see in Part IV, it is also a LaTeX and Markdown escape
    character.

[^chapter4_4]: See the discussion of global chunk options in Chapter
    [\[GettingStartedRKnitr\]](#GettingStartedRKnitr){reference-type="ref"
    reference="GettingStartedRKnitr"}, page .

[^chapter4_5]: Note: you will need the correct system permissions to be able to
    do this.

[^chapter4_6]: The `file.rename` command won't create new directories. To move a
    file to a new directory you will need to create the directory first
    with `dir.create`.

[^chapter4_7]: You can access Bash via the Terminal program on Mac OS 10 and
    Linux computers. It is the default shell on Mac and Linux, so it
    loads automatically when you open the Terminal. Windows PowerShell
    comes installed with Windows.

[^chapter4_8]: A command-line program is just a program you run from a shell.

[^chapter4_9]: Many shell code examples in other sources include the shell
    prompt, like the `$` in Bash or `>` in PowerShell. These are like
    R's `>` prompt. I don't include the prompt in code examples in this
    book because you don't type them.

[^chapter4_10]: If they were not in the root directory we would not place a
    forward slash at the beginning.

<!--chapter:end:06-file-management.Rmd-->

# About the Author {-}

Christopher Gandrud is Economics Lead at Zalando SE building and evaluating large scale decision-making systems. He was previously a research fellow at the Institute for Quantitative Social Science, Harvard University developing statistical software and applications for the social and physical sciences. He has also held posts at City, University of London, the Hertie School of Governance, Yonsei University, and the London School of Economics where in 2012 he completed a PhD in quantitative political science. 

<!--chapter:end:98-author.Rmd-->

`r if (knitr:::is_html_output()) '# References {-}'`

```{r include=FALSE}
# Additional packages to cite
pkg_additional <- c(
    .packages(),
    "bookdown", "dplyr", "formatR", "IRkernel", "knitr", "pacman", "RCurl", 
    "rmarkdown", "styler", "tinytex", "xml"
)

# Check if the packages are installed, if not install
lapply(pkg_additional,
    function(pkg) {
        if (system.file(package = pkg) == "")
            install.packages(pkg,
                repos = "http://cran.us.r-project.org")
})

# pkg_to_install is created in 00-setup.Rmd
pkg_to_cite <- c(pkg_to_install, pkg_additional)

# generate a BibTeX database automatically for some R packages
knitr::write_bib(pkg_to_cite, 'packages.bib')
```

<!--chapter:end:99-references.Rmd-->

