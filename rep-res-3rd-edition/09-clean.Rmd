# Preparing Data for Analysis {#DataClean}

Once we have gathered the raw data that we want to include in our
statistical analyses we generally need to clean it up so that it can be
merged into a single data set that we can easily use for statistical analysis. 
In this chapter we will learn how to
create the data gather and merging files we saw in the last chapter. TThis includes recoding and transforming
variables in the data set so that the data sets can be easily merged. This will also be useful
information in later chapters as well. If you are very familiar with
data transformations in R you may want to skip to the next chapter.

## Cleaning Data for Merging

In order to successfully merge two or more data frames we need to make
sure that they are in the same format. Let's look at some of the
important formatting issues and how to reformat your data frames so that
they can be easily merged.

### Get a handle on your data

Before doing anything to your data it is a good idea to take a look at
it and see what needs to be done. Taking a little time to become
acquainted with your data will help you avoid many error messages and
much frustration.

You could type a data frame object's name into the R console. This will
print the entire data frame in your console. For data frames with more
than a few variables and observations this is very impractical. We have
already seen a number of functions that are useful for looking at parts
of your data. As we saw in Chapter \@ref(GettingStartedRKnitr), the `names()`\index{R function!names} function shows you the
variable names in a data frame object. The `head()`\index{R function!tail} function shows the
names plus the first few observations in a data frame. `tail()`\index{R function!tail} shows
the last few.

Use the `dim()`\index{R function!names} (dimensions) function to quickly see the number of
observations and variables (the number of rows and columns) in a data
frame object. For example, let's use the *fert_cons_data* object we
created in Chapter \@ref(DataGather) to test out `dim()`:

```{r Ch7dim}
dim(fert_cons_data)
```

The first number is the number of rows in the data frame (`r nrow(fert_cons_data)`) and the
second is the number of columns (`r ncol(fert_cons_data)`). You can also use the `nrow()`\index{R function!nrow} function
to find just the number of rows and `ncol()`\index{R function!ncol} to see only the columns.

The `summary()`\index{R function!summary} function is especially helpful for seeing basic descriptive
statistics for all of the variables in a data frame and also the
variables' types. Here is an example:

```{r Ch7SummaryExamp}
summary(fert_cons_data)
```

We can immediately see that the variables **iso2c** and **country** are
character strings. Because `summary()` is able to calculate means,
medians, and so on for **AG.CON.FERT.ZS** and **year**, we know they are
numeric. Have a look over the summary to see if there is anything
unexpected like lots of missing values (**NA's**) or unusual maximum and
minimum values. You can of course, run `summary()` on a particular
variable by using the component selector (`$`):

```{r Ch7SummarizeCompSelect}
# Summarize fertilizer consumption variable from fert_cons_data
summary(fert_cons_data$AG.CON.FERT.ZS)
```

We'll come back to why knowing this type of information is important for merging and data analysis later in this chapter.

Another important function for quickly summarizing a data frame is `table()`.\index{R function!table} This creates a contingency table\index{contingency table} with counts of the number of observations per combination of factor variables.

You can view a portion of a data frame object with `View()`\index{R function!View} This will open a new window that lets you see a selection of the data frame. If you are using RStudio, you can click on the data frame in the *Environment* tab\index{RStudio!Environment tab} and you will get something similar. Note that neither of these viewers are interactive in that you can't use them to manipulate the data. They are only data viewers. To be able to see similar windows that you can interactively edit, use the `fix()`\index{R function!fix} function in the same way that you use `View()`. This can be useful for small edits, but remember that the edits are not reproducible.

### Tibbles {-}

Most of these data summary capabilities come "for free" when you use an alternate type of data frame called a "tibble" [@R-tibble] For example,\index{R function!tibble}

```{r Ch7Tibble}
# Create example tibble data frame
tbl_ex <- tibble::tibble(numbers = 1:26, letters = letters)

tbl_ex
```

We see the condensed output, the data dimmensions, and the variable types with the first 10 entries. 

Tibbles are the data structure favored by the tidy data/tidyverse R data paradigm [@wickham2014article]. We will work with other packages of the Tidyverse--e.g. dplyr and ggplot2--in later chapters. Note that these packages often also work with traditional data frames as well (or will convert data frames to tibbles).

## Reshaping data

\index{R!reshaping data}

Obviously it is usually a good idea if your data sets are kept in data frame type objects. See Chapter \@ref(GettingStartedRKnitr} (Section \@ref(data.frame}) for how to convert objects into data frames with the `data.frame()` function.\index{R function!data.frame}\index{R!data frame} Not only do data sets (generally) need to be stored in data frame objects, they also need to have the same layout before they can be merged. Most R statistical analysis tools assume that your data is in "long" format\index{long formatted data}.[^long_format] This usually means that data frame columns are variables and rows are specific observations (see Table \@ref(ExampleLong}).

\begin{table}[h!]
    \caption{Long Formatted Data Example}
    \label{ExampleLong}
    \begin{tabular}{l c}
        \\[0.15cm]
        \hline
        Subject & Variable1 \\
        \hline \\[0.1cm]
        Subject1 & \\[0.25cm]
        Subject2 & \\[0.25cm]
        Subject3 & \\[0.25cm]
        \ldots & \\[0.25cm]
        \hline
    \end{tabular}
\end{table}

In this chapter we will mostly use examples of time-series cross-sectional data (TSCS)\index{time-series cross-sectional}\index{TSCS} that we want to have in long-format. Long formatted TSCS data is simply a data frame where rows identify observations of a particular subject at particular points in time and there are multiple observations per subject (see Table \@ref(ExampleTSCSLong)). In this chapter our TSCS data is specifically going to be countries that are observed in multiple years.


 \begin{table}[h!]
    \caption{Long Formatted Time-Series Cross-Sectional Data Example}
    \label{ExampleTSCSLong}
    \begin{tabular}{l c c}
        \\[0.15cm]
        \hline
        Subject & Time & Variable1 \\
        \hline \\[0.1cm]
        Subject1 & 1 & \\[0.25cm]
        Subject1 & 2 & \\[0.25cm]
        Subject1 & 3 & \\[0.25cm]
        Subject2 & 1 & \\[0.25cm]
        Subject2 & 2 & \\[0.25cm]
        Subject2 & 3 & \\[0.25cm]
        \ldots & & \\[0.25cm]
        \hline
    \end{tabular}
\end{table}

If one of our raw data sets is not in this format then we will need to reshape or, using Wickham's [-@wickham2014article] terminology, ''tidy'' it.\index{reshape data}\index{tidy data} Some data sets are in ''wide'' format,\index{wide formatted data} where one of the columns in what would be long formatted data is widened to cover multiple columns. This is confusing to visualize without an example. Table \@ref(ExampleWide} shows how Table \@ref(ExampleTSCSLong} looks when we widen the time variable.

\begin{table}[h!]
    \caption{Wide Formatted Data Example}
    \label{ExampleWide}
    \begin{tabular}{l c c c}
        \\[0.15cm]
        \hline
        Subject & Time1 & Time2 & Time3 \\
        \hline \\[0.1cm]
        Subject1 & & & \\[0.25cm]
        Subject2 & & & \\[0.25cm]
        \ldots & & & \\[0.25cm]
        \hline
    \end{tabular}
\end{table}

Tidying data is often the cause of much confusion and frustration. Though probably never easy, there are a number of useful R functions for changing data from wide format to long and vice versa. These include the matrix transpose function (`t`)\footnote{See this example by Rob Kabacoff: \url{http://www.statmethods.net/management/reshape.html}. Note also that because the matrix transpose function is denoted with \texttt{t}, you should not give any object the name *t*.}\index{matrix transpose} and the \texttt{reshape}\index{R function!reshape} function, both are loaded in R by default. *tidyr* [@R-tidyr] is a very helpful package for reshaping data.\index{tidyr} This provides more general tools for reshaping data and is worth investing some time to learn well. In this section we will look at \emph{tidyr}'s \texttt{gather} function and use it to reshape a TSCS data frame from wide to long format. We will also encounter this function again in Chapter \@ref(FiguresChapter} when we want to transform data so that it can be graphed.

For illustration let's imagine that the fertilizer consumption data we previously downloaded from the World Bank is in wide, rather than long, format and is in a data frame object called \emph{SpreadFert}. It looks like this:\footnote{See the chapter's Appendix (page \pageref{WideAppendix}) for the code I used to reshape the data from long to wide format.}

```{r Ch7Loadfert_cons_data, include=FALSE}

```

```{Ch7WideCreate, include=FALSE}
# Reshape Wide
SpreadFert <- spread(fert_cons_data, year, AG.CON.FERT.ZS)

# Order by country
SpreadFert <- arrange(SpreadFert, country)
```

```{Ch7ShowWideFert}
# Show the first 5 columns
head(SpreadFert[, 1:5])
```

\noindent We can use the \texttt{gather}\index{gather}\index{R function!gather}\label{GatherReshape} function to reshape this data from wide to long format. The term ``gather'' is intended to evoke an image of the many wide columns being gathered together.\footnote{The opposite \texttt{spread} function\index{R function!spread} is supposed to evoke an image of spreading out the data from long to wide format. See Chapter Appendix for an example using the \texttt{spread} function.}

Let's think about how we want to tidy the data. We want to create two new columns from the many columns that are now labeled by year. Let's call the new columns \textbf{Year} and \textbf{Fert}. The \textbf{Year} column will clearly contain the year of each observation and \textbf{Fert} will contain the fertilizer consumption. \textbf{Year} will be what \texttt{gather} calls the ``key'' and \textbf{Fert} is the ``value''. In our \emph{SpreadFert} data we don't want the \textbf{iso2c} and \textbf{country} variables to be gathered. These variables identify the data set's subjects. So we can tell \texttt{gather} that we only want columns three through nine gathered. The third column is the first one we want to gather and the ninth--the final column in the data set--is the last.

```{Ch7GatherFert, tidy=FALSE}
# Gather SpreadFert
GatheredFert <- gather(SpreadFert, Year, Fert, 3:9)

# Show GatheredFert
head(GatheredFert)
```

\subsection{Renaming variables}\index{R!renaming variables}

Frequently, in the data cleaning process we want to change the names of our variables. This will make our data easier to understand and may even be necessary to properly combine data sets (see below). In the previous example, for instance, our \emph{GatheredFert} data frame has two variables--\textbf{Year} and \textbf{Fert}. Imagine, for the sake of demonstration, that we want to rename them \textbf{year} and \textbf{FertilizerConsumption}. Renaming data frame variables is straightforward with the \texttt{rename}\index{R function!rename}\index{rename variable} function in the \emph{dplyr} package \citep{R-dplyr}. To rename both \textbf{variable} and \textbf{value} with the \texttt{rename} function type:

```{Ch7Rename, tidy=FALSE}
GatheredFert <- rename(GatheredFert,
                    year = Year,
                    FertilizerConsumption = Fert)

# Show GatheredFert
head(GatheredFert)
```

\subsection{Ordering data}\index{R!ordering data}

You may have noticed that as a result of gathering \emph{SpreadFert} the data is now ordered by year rather than country name. Typically, TSCS data is sorted by country then year, or more generally: subject-time. Though not required for merging in R,\footnote{Unlike in other statistical programs.} some statistical analyses assume that the data is ordered in a specific way. Well-ordered data is also easier for people to read.

We can order observations in our data set using the \texttt{order} function.\index{R function!order}\index{sort}\index{order} For example, to order \emph{GatheredFert} by country-year we type:

```{Ch7Order, tidy=FALSE}
# Order GatheredFert by country-year
GatheredFert <- GatheredFert[order(GatheredFert$country,
GatheredFert$year), ]

# Show GatheredFert
head(GatheredFert)
```

\emph{dplyr} has a function called \texttt{arrange}\index{R function!arrange} that can also be useful for ordering your data. \noindent \texttt{arrange}'s syntax is much cleaner and easier to remember for data frames than the operation we did with \texttt{order}. To arrange the \emph{GatheredFert} data as in the previous example, but with \texttt{arrange} use:

```{Ch7Arrange}
GatheredFert <- arrange(GatheredFert, country, year)
```

To arrange a variable in descending order, simply place it in the \texttt{desc} function from \emph{dplyr}, e.g. \verb|arrange(GatheredFert, country, desc(year))|.\index{R function!desc}

\subsection{Subsetting data}\index{R!subsetting data}

Sometimes you may want to use only a subset of a data frame. For example, the density plot in Figure \@ref(FertilizerConsumptionDens} shows us that the \emph{GatheredFert} data has a few very extreme values. We can use the \texttt{subset}\index{subset}\index{R function!subset} function to examine these outliers,\index{outliers} for example, countries that have fertilizer consumption greater-than 1000 kilograms per hectare.

\begin{figure}
    \caption{Density Plot of Fertilizer Consumption (kilograms per hectare of arable land)}
    \label{FertilizerConsumptionDens}
```{Ch7FertDist, echo=FALSE, warning=FALSE, fig.width=3, fig.height=3}
# Create density plot of GatheredFert

# Load ggplot2
library(ggplot2)

# Create histogram
ggplot(data = GatheredFert, aes(FertilizerConsumption)) +
        geom_density() +
        xlab("\n Fertilizer Consumption") + ylab("Density\n") +
        theme_bw()
```
    {\scriptsize{See the chapter's Appendix for the source code to create this figure.}}
\end{figure}

```{Ch7SubsetOutliers, tidy=FALSE}
# Create outlier data frame
FertOutliers <- subset(x = GatheredFert,
                      FertilizerConsumption > 1000)

# Show FertOutliers
head(FertOutliers)
```

\noindent If we want to drop these outliers from our data set we can use \texttt{subset} again.

```{Ch7SubsetNoOutliers, tidy=FALSE}
GatheredFertSub <- subset(x = GatheredFert,
                        FertilizerConsumption <= 1000)
                        ```

In this data example, non-country units like ``Arab World'' are included. We might want to drop these units with the \texttt{subset} function as well. For example:

```{Ch7DropString, tidy=FALSE}
# Drop Arab World type from GatheredFertSub
GatheredFertSub <- subset(x = GatheredFertSub,
                          country != "Arab World")
                        ```

We can also use `subset` to remove observations with missing values (`NA`) for **FertilizerConsumption**.

```{Ch7IsNotNA, tidy=FALSE}
# Remove observations of FertilizerConsumption
# with missing values
GatheredFertSub <- subset(x = GatheredFertSub,
                        !is.na(FertilizerConsumption))

# Summarize FertilizerConsumption
summary(GatheredFertSub$FertilizerConsumption)
```

l l Operator & Meaning\
\
`<` & less-than\
`>` & greater-than\
`==` & equal to\
`<=` & less-than or equal to\
`>=` & greater-than or equal to\
`!=` & not equal to\
`a | b ` & a or b\
`a & b` & a & b\
`isTRUE(a)` & determine if a is TRUE\
\
`is.na` & missing\
`!is.na` & not missing\
`duplicated` & duplicated observation\
`!duplicated` & not a duplicated observation\

Let's step back one second. I've introduced a number of new logical
operators and a new function in the four subsetting examples. The first
example included a very simple one, the greater-than sign (`>`). The
second example included the less-than or equal to operator: `<=`. The
third example included the not equal operator: `!=`. In R, exclamation
points (`!`) generally denote 'not'. We used this again in the final
example in combination with the `is.na` function. This function indicates
if an element is missing, so `!is.na` means "not missing". For a list of
R's logical operators, see Table \@ref(table:LogicalOp).
You can use these operators and functions when subsetting data and
throughout R.

### Recoding string/numeric variables

You may want to recode your variables. In particular, when you merge
data sets together you need to have **identical** identification values
that R can use to match each observation on. If in one data set
observations for the Republic of Korea are referred to as "Korea, Rep."
and in another they are labeled "South Korea", R will not know to merge
them. We need to recode values in the variables that we want to match
our data sets on. For example, in *GatheredFertSub* the southern Korean
country is labeled "Korea, Rep.". To recode it to "South Korea" we type:

```{r Ch7RecodeString, tidy=FALSE} 
# Recode country == "Korea, Rep." to "South Korea"
GatheredFertSub$country[GatheredFertSub$country == "Korea, Rep."] <- "South Korea"
```

This code assigns "South Korea" to all values of the **country**
variable that equal "Korea, Rep.".[^1] You can use a similar technique
to recode numeric variables as well. The only difference is that you
omit the quotation marks. We will look at how to code factor variables
later.

### Creating new variables from old

As part of your data cleanup process (or later during statistical
analysis) you may want to create new variables based on existing
variables. For example, we could create a new variable that is the
natural logarithm of **FertilizerConsumption**. To do this we run the
variable through the `log` function and assign a new variable that we'll
call **logFertConsumption**.

```{r Ch7LogFertComsump, tidy=FALSE}
GatheredFertSub$logFertConsumption <- log(GatheredFertSub$FertilizerConsumption )

summary(GatheredFertSub$logFertConsumption)
```

Notice that when we summarize the new log transformed variable that we have a minimum (and mean) value
of `-Inf`.\index{infinity}\index{R!inf} This indicates that by logging the variable we have created
observations with the value negative infinity. R calculates the natural
logarithm of zero as negative infinity.[^2] We probably don't want
negative infinity values. There are a few ways to deal with this. We
could drop all observations of **FertilizerConsumption** with the value
zero before log transforming it. Another common solution is recoding
zeros as some small nonnegative number like 0.001. For example:

```{r Ch7LogFertComsumpAgain, tidy=FALSE} 
# Recode zeros in Fertilizer Consumption 
GatheredFertSub$FertilizerConsumption[GatheredFertSub$FertilizerConsumption == 0] <- 0.001

# Natural log transform Fertilizer Consumption
GatheredFertSub$logFertConsumption <- log(
GatheredFertSub$FertilizerConsumption )

# Summarize the log transformed variable
summary(GatheredFertSub$logFertConsumption)
```

Note that this example is included to demonstrate R syntax rather than
to prescribe a certain transformation of skewed data with zeros. The
choice of which transformation to make should ultimately be made based
on the data, model, and context. See [@Hyndman2010] for more information
on various alternatives including Box-Cox [@box1964analysis] and inverse
hyperbolic sine transformations [@burbidge1988].

  Number   Label         Value of **FertilizerConsumption**
  -------- ------------- ------------------------------------

  1        low           $< 18$
  2        medium low    $\ge 18$ & $< 81$
  3        medium high   $\ge 81$ & $< 158$
  4        high          $\ge 158$

  : Example Factor Levels[]{label="ExampleFactorRecode"}

##### Creating factor variables

We can create factor variables from numeric or string variables. For
example, we may want to turn the continuous numeric
**FertilizerConsumption** variable into an ordered categorical (i.e.
factor) variable. Imagine that we want to create a factor variable
called **FertConsGroup** with four levels called 'low', 'medium low',
'medium high', and 'high'. To do this let's first create a new numeric
variable based on the values listed in Table \@ref(table:ExampleFactorRecode). Now let's use a procedure that is
similar to the variable recoding we did earlier:[^3]

```{r Ch7FactorNumeric, tidy=FALSE} 
#### Create numeric factor levels variable 
#### # Attach GatheredFertSub data frame
attach(GatheredFertSub)

# Created new FertConsGroup variable based on # FertilizerConsumption
GatheredFertSub$FertConsGroup[FertilizerConsumption < 18] <- 1
GatheredFertSub$FertConsGroup[FertilizerConsumption >= 18 &
FertilizerConsumption < 81] <- 2
GatheredFertSub$FertConsGroup[FertilizerConsumption >= 81 &
FertilizerConsumption < 158] <- 3
GatheredFertSub$FertConsGroup[FertilizerConsumption >= 158] <- 4
GatheredFertSub$FertConsGroup[is.na(FertilizerConsumption)] <- NA

# Detach data frame 
detach(GatheredFertSub)

summary(GatheredFertSub$FertConsGroup)
```

You'll notice that we don't have a factor variable yet; our new variable
is numeric. We can use the `factor` function to convert *FertConsGroup*
into a factor variable with the labels we want.

```{r Ch7ChangetoFactor, tidy=FALSE} 
# Create vector of factor level labels
FCLabels <- c("low", "medium low", "medium high", "high")

# Convert FertConsGroup to a factor 
GatheredFertSub$FertConsGroup <- factor(GatheredFertSub$FertConsGroup, labels = FCLabels)


summary(GatheredFertSub$FertConsGroup)
```

We first created a character vector with the factor-level labels and
then applied using `factor`'s `labels` argument. Using `summary` with a
factor variable gives us its level labels as well as the number of
observations per level.

The `cut` function provides a less code-intensive way of creating
factors from numeric ones and labeling factor levels. For example:

```{r Ch7Cut, tidy=FALSE} 
# Create a factor variable with the cut function 
FertFactor <- cut(GatheredFertSub$FertilizerConsumption,
                  breaks = c(-0.01, 17.99, 80.99, 157.99, 999.99), 
                  labels = c("low", "medium low", "medium high", "high"))

summary(FertFactor)
```

The `labels` argument lets us specify the factor levels' names. The
`breaks` argument lets us specify what values separate the factor
levels. Note that we set the first break as `-0.01`, not because any
country had negative fertilizer consumption, but because the intervals
created by `break` exclude the left value and include the right
value.[^4] If we had used `0` then all of the observations where a
country used effectively no fertilizer would be excluded from the "low"
category.

### Changing variable types

Sometimes a variable will have the wrong type. For example, a numeric
variable may be incorrectly made a character string when a data set is
imported from Excel. You can change variables' types with a number of
functions. We already saw how to convert a numeric variable to a factor
variable with the `factor` function. Unsurprisingly, to convert a
variable to a character use `character` and `numeric` to convert it to a
numeric type variable. We can place `as.` before these functions (e.g.
`as.factor`) as a way of coercing a change in type.

**Warning:** Though these functions have straightforward names, a word of
caution is necessary. Always try to understand why a variable is not of
the type you would expect. Oftentimes variables have unexpected types
because they are coded (or miscoded) in a way that you didn't
anticipate. Changing the variables' types, especially when using `as.`,
can introduce new errors. Make sure that the conversion made the changes
you expected.

## Merging Data Sets

In the previous section we learned crucial skills for cleaning up data
sets. When your data sets are (a) in the same format and (b) have
variables with identically matching ID values, you can merge your data
sets together. In this section we'll look at two different ways to merge
data sets: binding and the `merge` function. We'll also look at ways to
address a common issue when merging data: duplicated observations and
columns.

### Binding

As we saw in Chapter \@ref(GettingStartedRKnitr), if your data sets are in the same
order--rows in all of the data sets represent the same observation of
the same subject--then you can simply use the `cbind` function to bind
columns from the data sets together. This situation is unusual when
merging real-world data. If your data sets are not in exactly the same
order you will create a data set with nonsensical rows that combine data
from multiple observations. Therefore, you should avoid using `cbind`
for merging most real-world data.

If you have data sets with the exact same columns and variable types and
you just want to attach one under the other you can use the `rbind`
function. It binds the rows in one object to the rows in another.[^5] It
has the same syntax as `cbind` (see page ). Again, you should be
cautious when using this function, though it is more difficult to
accidentally create a nonsensical data set with `rbind`. R will give you
an error if it cannot match your objects' columns.

### Merging data frames

Generally, the safest and most effective way to merge two data sets
together is with the `merge()` function.\index{R function!merge} Imagine that we want to merge our
*GatheredFertSub* data frame with two other data frames we created in
Chapter \@ref(DataGather): *FinRegulatorData* and *DispropData*. The
simplest way to do this is to use the merge function twice, i.e.:

```{r Ch7AddIsoCodes, include=FALSE} 
## Add iso2c codes to FinRegulatorData and DispropData 
## as ID variables for merging

# Load countrycode 
library(countrycode)

# FinRegulatorData 
FinRegulatorData$iso2c <- countrycode(FinRegulatorData$country, 
                                      origin = "country.name",
                                      destination = "iso2c")
```

```{r Ch7MergeSimple, tidy=FALSE} 
# Merge FinRegulatorData and DispropData 
MergedData1 <- merge(x = FinRegulatorData, y = DispropData,
                     by = "iso2c", all = TRUE)

# Merge combined data set with and GatheredFertSub 
MergedData1 <- merge(x = MergedData1, y = GatheredFertSub, by = "iso2c", all = TRUE)

names(MergedData1)
```

Let's go through this code. The `x` and `y` arguments simply specify
which data frames we want to merge. The `by` argument specifies what
variable in the two frames identify the observations so that we can
match them. In this example we are merging by countries' ISO country
two-letter codes.[^6] We set the argument `all = TRUE` so that we keep
all of the observations from both of the data frames. If the argument is
set to `FALSE` only observations that are common to both data frames
will be included in the merged data frame. The others will not be
included.

You might have noticed that this isn't actually the merge that we want
to accomplish with these data frames. Remember that observations are not
simply identified in this time-series cross-section data by one country
name or other country code variable. Instead they are identified by both
country and year variables. To merge data frames based on the overlap of
two variables (e.g. match Afghanistan-2004 in one data frame with
Afghanistan-2004 in the other) we need to add the `union` function to
`merge`'s `by` argument. Here is a full example:[^7]

```{r Ch7MergeFull, tidy=FALSE}
# Merge FinRegulatorData and DispropData
MergedData2 <- merge(FinRegulatorData, DispropData, union("iso2c", "year"), 
                     all = TRUE)

# Merge combined data frame with GatheredFertSub 
MergedData2 <- merge(MergedData2, GatheredFertSub, union("iso2c", "year"), 
                     all = TRUE)

names(MergedData2)
```

After merging data frames it is always a good idea to look at the result
and make sure it is what you expected. Some post-merging cleanup may be
required to get the data frame ready for statistical analysis.

##### Big data

Before discussing post-merge cleanup it is important to highlight ways
to handle large data sets. The `merge` function and many of the other
data frame manipulation functions covered so far in this chapter may not
perform well with very large data sets. If you are using very large data
sets it might be worth investing time learning how to use either the
*dplyr* or *data.table* packages [@R-data.table]. They have many
capabilities for working efficiently with large data sets. Another
approach is to learn SQL[^8] or another special purpose data handling
language.[^9] Once you know how these languages work, you can
incorporate them into your R workflow with R packages like *dplyr*.[^10]

### Duplicate values

Duplicate observations are one thing to look out for after (and before)
merging. You can use the `duplicated` function to check for duplicates.
Use the function in conjunction with subscripts to remove duplicate
observations. For example, let's create a new object called
*DataDuplicates* from the iso2c-years that are duplicated in
*MergedData2*. Remember that **iso2c** and **year** are in the first and
second columns of the data frame.

```{r Ch7Duplicated, tidy=FALSE} 
# Created a data frame of duplicated country-years 
DataDuplicates <- MergedData2[duplicated( MergedData2[,1:2]), ]

# Show the number of rows in DataDuplicates 
nrow(DataDuplicates)
```

In this data frame there are duplicated iso2c-year observations. We know
this because `nrow` tells us that the data frame with the duplicated
values has rows, i.e. observations.

To create a data set without duplicated observations (if there are
duplicates) we just add an exclamation point (`!`) before
`duplicated`--i.e. not duplicated--in the above code.

```{r Ch7NotDuplicated} 
# Created a data frame of unique country-years 
DataNotDuplicates <- MergedData2[!duplicated(MergedData2[, 1:2]), ]
```

Note that if you do have duplicated values in your data set and you run
a similar procedure on it, it will drop duplicated values that have a
lower order in the data frame. To keep the lowest ordered value and drop
duplicates higher in the data set, use `duplicated`'s `fromLast`
argument like this: `fromLast = TRUE`.

**Warning:** look over your data set and the source code that created
the data set to try to understand why duplicates occurred. There may be
a fundamental problem in the way you are handling your data that
resulted in the duplicated observations.

### Duplicate columns

Another common post-merge cleanup issue is duplicate columns, i.e.
variables. These are variables from the two data frames with the same
name that were not included in `merge`'s `by` argument. For example, in
our previous merged data examples there are three country name
variables: **country.x**, **country.y**, and **country** to signify
which data frame they are from.[^11]

You should of course, decide what to do with these variables on a
case-by-case basis. But if you decide to drop one of the variables and
rename the other, you can use subscripts (as we saw in Chapter

\ref(GettingStartedRKnitr). The *dplyr* package [@R-dplyr] has a
useful function called `select` that can also remove variables from data
frames. To remove variables simply write a minus sign (`-`) and then the
variable name without quotes. For example, imagine that we want to keep
**country.x** and drop the other variables.[^12] Let's also remove the
**idn** variable:

```{r Ch7RemoveVars, tidy=FALSE} 
# Remove country.y, country, X, and idn 
FinalCleanedData <- dplyr::select(DataNotDuplicates, -country.y, 
                                  -country, -idn)

# Rename country.x = country FinalCleanedData <-
dplyr::rename(FinalCleanedData, country = country.x)
```

```{r Ch7ShowFinalCleanedDataNames} 
# Show FinalCleanedData variables
names(FinalCleanedData)
```

Alternatively, you can select specific variables to keep with the
`select` function by writing the variables' names without a minus sign.
**Note**: if you are merging many data sets it can sometimes be good to
cleanup duplicate columns between each `merge` call.

### Chapter summary {-}

This chapter has provided you with many tools for cleaning up your data
to get it ready for statistical analysis. Before moving on to the next
chapter to learn how to incorporate statistical analysis as part of a
reproducible workflow with *knitr*/*rmarkdown*, it's important to
reiterate that the function we've covered in this chapter should usually
be embedded in the types of data creation files we saw in Chapter
\@ref(DataGather). These files can then be tied together with a
makefile into a process that should be able to relatively easily take
very raw data and clean it up for use in your analyses. Embedding these
functions in data creation source code files, rather than just typing the
functions into your R console or manually changing data in Excel, will
make your research much more reproducible. It will also make it easier
to backtrack and find mistakes that you may have made while transforming
the data. Including new or updated data when it becomes available will
also be much easier if you use a series of segmented data creation
source code files that are tied together with a makefile.

# Appendix {-#WideAppendix}

R code for turning *FertConsumData* into year-wide format:

```{r Ch7WideCreateShow, eval=FALSE, tidy=FALSE} # Load WDI and tidyr
package library(WDI) library(tidyr)

# Gather fertilizer consumption data from WDI fert_cons_data <-
WDI(indicator = "AG.CON.FERT.ZS")

# Spread fert_cons_data to year wide format SpreadFert <-
spread(fert_cons_data, year, AG.CON.FERT.ZS)

# Order SpreadFert by country SpreadFert <- arrange(SpreadFert,
country)
```

R code for creating iso2c country codes with the *countrycode*
package:[\[CountryCodeExample]]{#CountryCodeExample
label="CountryCodeExample"}

```{r Ch7CountryCodeShow, eval=FALSE, tidy=FALSE} 
# Load countrycode package 
library(countrycode)

# FinRegulatorData FinRegulatorData$iso2c <-
countrycode(FinRegulatorData$country, origin = "country.name",
destination = "iso2c")
```

R code for creating Figure
[\[FertilizerConsumptionDens]](#FertilizerConsumptionDens){reference-type="ref"
reference="FertilizerConsumptionDens"}:

```{r Chr7FigDensity, eval=FALSE} 
# Load ggplot2
library(ggplot2)

# Set plot theme to "minimal"
theme_set(theme_minimal())

# Create density plot 
ggplot(data = GatheredFert, aes(FertilizerConsumption)) + 
      geom_density() + 
      xlab("Fertilizer Consumption") + ylab("Density") + 
      theme_bw()
```

REMOVE

[^long_format]: For an excellent discussion of ideal data formats see [@wickham2014article].

[^1]: The *countrycode* package
```R-countrycode] is very helpful for
    creating standardized country identification variables.

[^2]: R denotes positive infinity with `Inf`.

[^3]: In this code I attached the data frame *GatheredFertSub* so that
    it is easier to read.

[^4]: In mathematical notation the "low" level includes all values in
    the interval $(-0.01,\:17.99]$.

[^5]: Some programming languages and statistical programs refer to this
    type of action as "appending" one data set to another.

[^6]: Please see this chapter's Appendix for details on how I created an
    ISO country two-letter code variable in the *FinRegulatorData* data
    frame.

[^7]: You can download a modified version of this example as part of the
    makefile exercise from Chapter
    [\[DataGather]](#DataGather){reference-type="ref"
    reference="DataGather"}: <http://bit.ly/YnMKBG>.

[^8]: Structured Query Language

[^9]: w3schools has an online SQL tutorial at:
    <http://www.w3schools.com/sql/default.asp>.

[^10]: See the *dplyr* vignette on using the package with SQL databases
    at
    <http://cran.r-project.org/web/packages/dplyr/vignettes/databases.html>.

[^11]: The former two were created in the first merge between
    *FinRegulatorData* and *DispropData*. When the second merge was
    completed there were no variables named **country** in the
    MergeData2 data frame, so **country** did not need to be renamed in
    the new merged data set.

[^12]: This version of the country variable is the most complete.
